{"meta":{"title":"Chivier's Blog","subtitle":null,"description":null,"author":"Chivier Humber","url":"https://chivier.github.io","root":"/"},"pages":[{"title":"About","date":"2019-04-22T06:18:36.000Z","updated":"2021-12-27T14:47:08.452Z","comments":true,"path":"Whoami/index.html","permalink":"https://chivier.github.io/Whoami/index.html","excerpt":"","text":"个人简介中国科学技术大学在读学生 现役中国科学技术大学鸿雁超算队教练 擅长语言：（按熟练度排序） C/C++ Rust Python Verilog Bash FORTRAN Latex Java JavaScript SQL AHK MATLAB Julia 技能： 代码分析 可以迅速理解代码框架，参与众多开源项目，开发经验丰富 数据可视化 传统数据分析工具均可熟练使用 如：SPSS、Excel、Stata 熟练使用各种作图工具：Latex、Edraw、Inkscape、Dia、Painta、Visio 熟练掌握交互式数据可视化：Echarts、Eviews 熟练使用常用科学软件：COMSOL、Tecplot 熟练使用常用数学软件：MATLAB、Mathematica、Maple 掌握3D建模和简单的动画设计：Maya、Blender、Unreal Engine、Meshroom 熟练使用 AutoCAD，建筑绘图 简单的图形图像处理和视频剪辑：PS、DaVinci Resolve、OBS、Krita、GIMP 非常熟练的 Latex 排版能力 非常熟练的 Linux/Unix 开发能力和基本运维，长期使用 Ubuntu，并作为 Gnome 开源社区开发者 各类应用开发，包含但不限于：Android App、 IOS App、 桌面端应用、 Web 应用。会使用 Vue、Angular 等常用框架 单片机开发 和 FPGA开发 较熟练掌握： Arduino、Xilinx Vivado 适应能力改造能力极强，对 Geany、VScode、Atom、Capslock+、Qbar、MATLAB、SourceTrail、Sublime、Brackets、Alfred、Wox 等工具均开发过插件，部分已上线 简单的数据挖掘 简单的调音和音频处理 会使用：Audacity、FL Studio 熟练安装各类系统，并在各种系统下均开发过非常好用的小工具 矩阵论、数论和近世代数小有研究 热力学、流体力学、量子力学领域有极高的热情 目前研究领域： High Performance Computing Compiler Designing Computational Fluid Mechanics 其他： 国家二级建筑师"},{"title":"Categories","date":"2019-05-15T01:53:13.000Z","updated":"2021-12-23T04:47:10.000Z","comments":true,"path":"categories/index.html","permalink":"https://chivier.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"2205-omp2tbb开发笔记","slug":"2022/2205-omp2tbb开发笔记","date":"2022-07-01T06:22:25.000Z","updated":"2022-07-01T06:24:10.804Z","comments":true,"path":"2022/07/01/2022/2205-omp2tbb开发笔记/","link":"","permalink":"https://chivier.github.io/2022/07/01/2022/2205-omp2tbb%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/","excerpt":"Version 0.0","text":"Version 0.0 omp2tbb2022-05-04 开发测试 整理 OpenMP 5.2 导语制作测试集合，用来测试各种导语的 LLVM-openmp 对应的导语。 首先位于上层的接口是： LLVM OMP Stmt LLVM OPENMPIR OMP CLAUSE Care?(Y/N) OMPParallelDirective pragma omp parallel Y OMPSimdDirective pragma omp simd Y OMPForDirective pragma omp for Y OMPForSimdDirective pragma omp for simd OMPSectionsDirective pragma omp sections Y OMPSectionDirective pragma omp section Y OMPSingleDirective pragma omp single Y OMPMasterDirective pragma omp master Y OMPCriticalDirective pragma omp critical Y OMPParallelForDirective pragma omp parallel for OMPParallelForSimdDirective pragma omp parallel for simd OMPParallelMasterDirective pragma omp parallel master OMPParallelSectionsDirective pragma omp parallel sections OMPTaskDirective pragma omp task OMPTaskyieldDirective pragma omp taskyield OMPBarrierDirective pragma omp barrier OMPTaskwaitDirective pragma omp taskwait OMPTaskgroupDirective pragma omp taskgroup OMPFlushDirective pragma omp flush OMPDepobjDirective pragma omp depobj OMPOrderedDirective pragma omp ordered OMPAtomicDirective pragma omp atomic OMPTargetDirective pragma omp target OMPTargetDataDirective pragma omp target data OMPTargetEnterDataDirective pragma omp target enter data OMPTargetExitDataDirective pragma omp target exit data OMPTargetParallelDirective pragma omp target parallel OMPTargetParallelForDirective pragma omp target parallel for OMPTeamsDirective pragma omp teams OMPCancellationPointDirective pragma omp cancellation point OMPCancelDirective pragma omp cancel OMPTaskLoopDirective pragma omp taskloop OMPTaskLoopSimdDirective pragma omp taskloop simd OMPMasterTaskLoopDirective pragma omp master taskloop OMPMasterTaskLoopSimdDirective pragma omp master taskloop simd OMPParallelMasterTaskLoopDirective pragma omp parallel master taskloop OMPParallelMasterTaskLoopSimdDirective pragma omp parallel master taskloop simd OMPDistributeDirective pragma omp distribute OMPTargetUpdateDirective pragma omp target update OMPDistributeParallelForDirective pragma omp distribute parallel for OMPDistributeParallelForSimdDirective pragma omp distribute parallel for simd OMPDistributeSimdDirective pragma omp distribute simd OMPTargetParallelForSimdDirective pragma omp target parallel for simd OMPTargetSimdDirective pragma omp target simd OMPTeamsDistributeDirective pragma omp teams distribute OMPTeamsDistributeSimdDirective pragma omp teams distribute simd OMPTeamsDistributeParallelForSimdDirective pragma omp teams distribute parallel for simd OMPTeamsDistributeParallelForDirective pragma omp teams distribute parallel for OMPTargetTeamsDirective pragma omp target teams OMPTargetTeamsDistributeDirective pragma omp target teams distribute OMPTargetTeamsDistributeParallelForDirective pragma omp target teams distribute parallel for OMPTargetTeamsDistributeParallelForSimdDirective pragma omp target teams distribute parallel for simd OMPTargetTeamsDistributeSimdDirective pragma omp target teams distribute simd OMPTileDirective pragma omp tile OMPUnrollDirective pragma omp unroll OMPScanDirective pragma omp scan OMPInteropDirective pragma omp interop OMPDispatchDirective pragma omp dispatch OMPMaskedDirective pragma omp masked OMPMetaDirective pragma omp metadirective OMPGenericLoopDirective pragma omp loop OMPTeamsGenericLoopDirective pragma omp teams loop OMPTargetTeamsGenericLoopDirective pragma omp target teams loop OMPParallelGenericLoopDirective pragma omp parallel loop OMPTargetParallelGenericLoopDirective pragma omp target parallel loop 作为最上层的识别层，之后下一层的是： LLVM Decl LLVM OpenMP Decl openmp decl Care?(Y/N) OMPAllocatorClause allocator OMPAlignClause align OMPAllocateClause allocate OMPIfClause if OMPFinalClause final OMPNumThreadsClause num_threads OMPSafelenClause safelen OMPSimdlenClause simdlen OMPSizesClause sizes OMPCollapseClause collapse OMPDefaultClause default OMPProcBindClause proc_bind OMPUnifiedAddressClause unified_address OMPUnifiedSharedMemoryClause unified_shared_memory OMPReverseOffloadClause reverse_offload OMPDynamicAllocatorsClause dynamic_allocators OMPAtomicDefaultMemOrderClause atomic_default_mem_order OMPScheduleClause schedule OMPOrderedClause ordered OMPNowaitClause nowait OMPUntiedClause untied OMPMergeableClause mergeable OMPReadClause read OMPWriteClause write OMPUpdateClause update OMPCaptureClause capture OMPCompareClause compare OMPSeqCstClause seq_cst OMPAcqRelClause acq_rel OMPAcquireClause acquire OMPReleaseClause release OMPRelaxedClause relaxed OMPPrivateClause private OMPFirstprivateClause firstprivate OMPLastprivateClause lastprivate OMPSharedClause shared OMPReductionClause reduction OMPTaskReductionClause task_reduction OMPInReductionClause in_reduction OMPLinearClause linear OMPAlignedClause aligned OMPCopyinClause copyin OMPCopyprivateClause copyprivate OMPFlushClause flush OMPDepobjClause depobj OMPDependClause depend OMPDeviceClause device OMPThreadsClause threads OMPSIMDClause simd OMPMapClause map OMPNumTeamsClause num_teams OMPThreadLimitClause thread_limit OMPPriorityClause priority OMPGrainsizeClause grainsize OMPNogroupClause nogroup OMPNumTasksClause num_tasks OMPHintClause hint OMPDistScheduleClause dist_schedule OMPDefaultmapClause defaultmap OMPToClause to OMPFromClause from OMPUseDevicePtrClause use_device_ptr OMPUseDeviceAddrClause use_device_addr OMPIsDevicePtrClause is_device_ptr OMPHasDeviceAddrClause has_device_ptr OMPNontemporalClause nontemporal OMPOrderClause order OMPInitClause init OMPUseClause use OMPDestroyClause destroy OMPNovariantsClause novariants OMPNocontextClause nocontext OMPDetachClause detach OMPInclusiveClause inclusive OMPExclusiveClause exclusive OMPUsesAllocatorsClause uses_allocators OMPAffinityClause affinity OMPFilterClause filter OMPBindClause bind 属实有点多，目前位置我们的目标是：对于 OpenMP 的代码块，我们识别出”最上层的逻辑块”，之后将其提取成为新的函数。对于包含了 OpenMP 的函数块，我们也将其提取成”新函数”。 我们给新的函数命名，之后进行我们的代码翻译工作。首先第一步工作是将并行代码串行化。 Development Step 1 构建可以识别 Stmt 的 Visitor 构建可以识别 OpenMP Directive 的 Visitor ✅ 2022-05-05 找出 OpenMP Directive 的范围，从而找出新的范围 ✅ 2022-05-05 记录：这里遇到一个非常大的坑点，使用 libclang 开发的工具需要加 – -fopenmp 才能启用编译选项 详细构建 Openmp 的树形结构 Development Step 0OpenMP Examples Build 顺着 openmp 官方的 example 文档构建 openmp 的并行例子。从而方便我们做之后的优化分析。 例子构建 测试时间工具部署 ✅ 2022-05-11 阅读 Structured Programming Models 分为两类: 构建 bottom 类别 从底层方案出发 构建 top 类别 从上层方案出发 目标： 充分发挥 omp5.2 的特性 使用 omp task 、parallel、for 方便之后进行检测和转化 熟悉 intel tbb 的具体操作和语法 思路!!产生了新的想法： 如果分析了数据访问的行为模式，分析一维/二维/三维的模式特征 整数泛函 NLP 分析表达式特征 为函数/openmp 代码快称重 是否有必要 inline 是否有必要并行 NLP？ 试一试，生成这个模式的 inline/noinline 代码 针对多重循环 针对随机离散的应用 ising model 2 维图片随机的处理 SPH Conway 生命游戏 已经成功构建 bottom cases。位于 https://github.com/Chivier/ompfuns Develop Step 1测试代码重写。找到一个合适的例子：upc2c","categories":[{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/categories/Develop/"},{"name":"Develop/Applications","slug":"Develop/Develop-Applications","permalink":"https://chivier.github.io/categories/Develop/Develop-Applications/"}],"tags":[{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/tags/Develop/"},{"name":"Develop/Applications","slug":"Develop-Applications","permalink":"https://chivier.github.io/tags/Develop-Applications/"}]},{"title":"2205-Lammps-EFF GPU version 开发笔记1","slug":"2022/2205-Lammps-EFF-GPU-version-开发笔记1","date":"2022-05-16T08:42:23.000Z","updated":"2022-05-16T08:42:54.057Z","comments":true,"path":"2022/05/16/2022/2205-Lammps-EFF-GPU-version-开发笔记1/","link":"","permalink":"https://chivier.github.io/2022/05/16/2022/2205-Lammps-EFF-GPU-version-%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B01/","excerpt":"对于 LAMMPS 的 EFF 模块进行整理分析，目标是开发出 GPU 版本。","text":"对于 LAMMPS 的 EFF 模块进行整理分析，目标是开发出 GPU 版本。 0 背景调研0.0 LAMMPS 项目结构和编译方法Lammps 官网提供了相关资料：ref1 经过和李森师兄进行商讨分析，希望尽可能多利用近年来 Lammps 在 GPU 平台上的优化和其他项目工具的辅助。选择版本为：lammps-stable_29Sep2021_update3 ref2 之后我们对如下的问题进行整理和分析： Lammps 的项目结构是怎样的，EFF 是什么 Lammps 的 GPU 版本如何编译，那些部分使用了 GPU 加速 Lammps 如何运行起来 如何使用 Cuda 对程序进行优化，其他的 Cuda 代码负责了什么功能 针对我们的算例，我们如何获取函数热点 能否摆脱 Lammps 框架，单独提取 EFF 部分使用 Cuda 进行编程操作 0.1 Lammps 编译首先我们根据官方手册的方法进行一些编译和测试 ref3 这里，官网提供了 Cmake 和 Make 两种编译方案，处于编译方法的简单性，我暂时选择了 CMake 进行编译和测试，效率较高，可以直接得到一个 GPU 版本的代码。不用认为指定对应的 cuda 环境变量。 EFF 是 LAMMPS 中的一个模块，主要是借助了 Lammps 的大规模计算框架的便利性，提升 Electron Force Field 的计算性能。ref4 1发现了 LAMMPS 中也使用了 VORONOI 算法，需要调研他的 VORONOI 和我的哪一个效率更高，进行对比测试。以及我提出的 VORONOI Entropy 可能在 LAMMPS 中作为一个平衡负载的重要指标。 编译命令： 12345678910mkdir build cd buildcmake ../cmake -DGUP_API=cuda \\ -DGPU_PREC=mixed \\ -DGPU_ARCH=sm_80 \\ -DPKG_EFF=yes \\ -DCMAKE_BUILD_TYPE=Debugmake -j48 0.2 GPU 版本编译和运行在李森师兄的指导下，成功的跑起了 LAMMPS 中的 example, 也成功的执行了张师兄给我的算例。 分析测试如下： 这里成功的启动了程序，也可以发现 mlx5_0 的卡槽，但是不能正常的使用 GPU。这里需要对程序进行更改。 这里无法成功启动 GPU。所以之后计算开始使用 CPU 和 mpi 进行。 此处可以正常进行计算，四列分别是：Step, Press, Temp, CPU 0.3 GPU 问题处理 11WARNING: There was an error initializing an OpenFabrics device. 之前主要报错信息位于此处： 问题原因 mpich 不支持 GPU 的并行，无法查询设备。 解决尝试 1更换 openmpi 的 GPU 编译方案。手动编译 openmpi 的 GPU 版本，方案参考：ref5 首先编译 gdrcopy ref6 编译命令: 12make prefix=$HOME/opt/gdrcopy/chver CUDA=/usr/local/cuda all installsudo ./insmod.sh 补充，如果此处 prefix 指定为自己的路径之后可以不需要 sudo 权限 结果失败，在 sanity test 中报错为: 1./sanity: error while loading shared libraries: libgdrapi.so.2: cannot open shared object file: No such file or directory 更新 PATH LD_LIBRARY_PATH 之后恢复正常。 下一步编译 UCX 参考版本：UCX1.12 12请务必使用最新版本，否则 ucx 和 Ampere 架构的 GPU 会因为 Cuda11 的 hook 问题无法兼容，导致各种段错误发生。手册中写的是 1.4 版本，但是 ucx 向下兼容，所以不会影响之后的工作。 由于测试机器是单卡，暂时砍掉 gdrcopy 的测试。推荐方案： 123456git clone git@github.com:openucx/ucx.gitgit checkout v1.12.1-rc4./autogen.sh./contrib/configure-release --prefix=$HOME/opt/ucx/chver --with-cuda=/usr/local/cudamake -j8make install 之后相应的更新环境，开始编译 openmpi 123./configure --with-cuda=/usr/local/cuda --with-ucx=/path/to/ucx-cuda-installmake -j48make install 现在返回测试，报错依然存在。 解决尝试 2分析问题还是在 openmpi 的 ib 驱动上，这里更换版本为 1.10 的 ucx。理由参考 Nvidia a100 进行 HPL 测试时使用的库版本: https://catalog.ngc.nvidia.com/orgs/nvidia/containers/hpc-benchmarks 首先自己编译 libcheck, 从 gdrcopy 重新开始：ref7 1sudo PKG_CONFIG_PATH=$HOME/opt/check/chver/lib/pkgconfig/ make prefix=$HOME/opt/gdrcopy/chver CUDA=/usr/local/cuda all install 如果这里使用 sudo 之后可以解决，重新使用： 1sudo PKG_CONFIG_PATH=$HOME/opt/check/chver/lib/pkgconfig/ make CUDA=/usr/local/cuda all install 之后在编译的时候 ld 可以找到 lgdrapi 了，非常顺利，这里巨大进步，进入 ucx 步骤，同上，无问题。 进入 openmpi 步骤，同上。报错同上。 解决尝试 3使用 intel mpi, 其余步骤一样，解决。 成功空占了 GPU 0.4 GPU 问题处理 2在多次尝试的时候发现了第二套解决方案，mpi 不使用 intel 的版本，但是编译的时候使用 makefile 进行编译。 ref:github-lammps-gpu 此方案可行，测试无误，虽然会报和之前一样的报错，即： 1WARNING: There was an error initializing an OpenFabrics device. 但是 GPU 确实可以成功启用。预计此方案在通信性能上会有一定的损失，但此损失可以接受。 1 模块分析1.1 EFF 代码逻辑测试工具准备 使用 Sourcetrail 建立代码逻辑 使用 gdb 进入调试 1.2 EFF 的模块初步分析首先，Lammps 是一个组件模式的应用，所有的部件都是通过 Lammps 的 main 对读入文件进行分析进行处理的。我们处理的方法是通过 ref: lammps-add-module 使用 pair_style 调用构建类。 至此，开发前提出的 6 个问题都得到了回答： Lammps 的项目结构是怎样的，EFF 是什么 模块化，每一个独立模块内部构建类 EFF 是 Lammps 计算 Electron Force Field Lammps 的 GPU 版本如何编译，那些部分使用了 GPU 加速 Lammp GPU 编译方法见 [[#0 3 GPU 问题处理 1]] , [[#0 2 GPU 版本编译和运行]] GPU 主要为： short-range long-range three-bosy 三种势能计算提供加速。作用有限。 ![[Pasted image 20220516144211.png]] Lammps 如何运行起来 mpirun + 对应参数实现 CPU 运行 mpirun -np 1 ../src/lmp_mpi -sf gpu -pk gpu 1 -in nvt.in 实现 GPU 运行 如何使用 Cuda 对程序进行优化，其他的 Cuda 代码负责了什么功能 将原来的 C 代码替换成 Cuda 代码，链接统一处理 参考 libgpu 的编译方法 针对我们的算例，我们如何获取函数热点 vtune 分析即可，因为 eff 不使用 GPU, 没有必要使用 gprof 能否摆脱 Lammps 框架，单独提取 EFF 部分使用 Cuda 进行编程操作 不可以，目前为止的输入文件中需要借助 lammps 处理的部分还是占据大部分的，不方便进行处理。 EFF 部分的 GPU 优化目前为止并没有流行的版本，可以考虑以此写文章 1.3 代码阅读 根据框架首先找到模块入口。结合调用关系，设置断点： 为 PairEffCut 设置即可。 可以进入断点进行测试。 下一步目标： 测试 EFF 模块的热点（进行中） 替换 EFF 的部分代码，测试插入 cuda 代码 References 1 https://www.lammps.org/ 2 https://codeload.github.com/lammps/lammps/tar.gz/refs/tags/stable_29Sep2021_update3 3 https://docs.lammps.org/Manual.html 4 https://www.lammps.org/movies.html#eff 5 https://www.open-mpi.org/faq/?category=buildcuda 6 https://github.com/NVIDIA/gdrcopy 7 https://github.com/libcheck/check#installing github-lammps-gpu https://github.com/Roy-Kid/lammpscn/issues/8 lammps-add-module https://docs.lammps.org/Modify_overview.html","categories":[{"name":"Develop/Applications","slug":"Develop-Applications","permalink":"https://chivier.github.io/categories/Develop-Applications/"},{"name":"Parallel/Cuda","slug":"Develop-Applications/Parallel-Cuda","permalink":"https://chivier.github.io/categories/Develop-Applications/Parallel-Cuda/"},{"name":"Develop/Applications/Lammps","slug":"Develop-Applications/Parallel-Cuda/Develop-Applications-Lammps","permalink":"https://chivier.github.io/categories/Develop-Applications/Parallel-Cuda/Develop-Applications-Lammps/"}],"tags":[{"name":"Develop/Applications","slug":"Develop-Applications","permalink":"https://chivier.github.io/tags/Develop-Applications/"},{"name":"Parallel/Cuda","slug":"Parallel-Cuda","permalink":"https://chivier.github.io/tags/Parallel-Cuda/"},{"name":"Develop/Applications/Lammps","slug":"Develop-Applications-Lammps","permalink":"https://chivier.github.io/tags/Develop-Applications-Lammps/"}]},{"title":"2205-MPI and timer","slug":"2022/2205-MPI-and-timer","date":"2022-05-13T06:31:37.000Z","updated":"2022-05-13T06:31:42.171Z","comments":true,"path":"2022/05/13/2022/2205-MPI-and-timer/","link":"","permalink":"https://chivier.github.io/2022/05/13/2022/2205-MPI-and-timer/","excerpt":"MPI 和 OpenMP 工作模式","text":"MPI 和 OpenMP 工作模式 OpenMP对于共享内存处理更优，但是没有通信的功能，所以MPI可以弥补这一缺点。 MPI快速上手基本概念关于进程和线程的说明我觉得英语的描述更为合适，可以非常清楚的说明这两个概念。 进程：A process is (traditionally) a program counter and address space. 线程：Processes may have multiple threads (program counters and associated stacks) sharing a single address space. MPI is for communication among processes, which have separate address spaces. 进程处理需要进行： 同步 数据通信 OpenMPI 和 MPICHYou can read following part later首先需要认识到这两者不是一个东西，在接口实现上有细微差异。MPICH应该是最新MPI标准的高质量参考实施，以及衍生实施以满足特殊用途需求的基础。OpenMPI在使用和网络通信方面实现更加普通。大部分时候两者都可以使用，但是如果是在有IB通信的机器上，MPICH不可用。 一般使用时，最大的差异是使用 Hydra 的时候会有差异。 OpenMPI的 Hostfile 格式为： 1234567891011# This is an example hostfile. Comments begin with ### The following node is a single processor machine:foo.example.com # The following node is a dual-processor machine:bar.example.com slots=2 # The following node is a quad-processor machine, and we absolutely# want to disallow over-subscribing it:yow.example.com slots=4 max-slots=4 MPICH的 Hostfile 格式为： 123donner:2 # The first 2 procs are scheduled to run herefoo:3 # The next 3 procs run on this hostshakey:2 # The last 2 procs run on this host 更细节的参考：MPICH HydraOpenMPI FAQ 学习的时候个人推荐MPICH进行学习和研究。 安装 MPICH下载1wget http://www.mpich.org/static/downloads/3.4.2/mpich-3.4.2.tar.gz 编译不做赘述 3对基本函数MPI Hello World12345678910111213141516171819202122232425int main(int argc, char** argv) &#123; // Initialize the MPI environment MPI_Init(NULL, NULL); // Get the number of processes int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); // Get the rank of the process int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); // Get the name of the processor char processor_name[MPI_MAX_PROCESSOR_NAME]; int name_len; MPI_Get_processor_name(processor_name, &amp;name_len); // Print off a hello world message printf(&quot;Hello world from processor %s, rank %d out of %d processors\\n&quot;, processor_name, world_rank, world_size); // Finalize the MPI environment. MPI_Finalize();&#125; 编译方法： 1mpicxx hello.cpp -o hello MPI_Init &amp; MPI_Finalize MPI_Init用于启动 MPI_Finalize用于结束 MPI_Comm_rank &amp; MPI_Comm_size MPI_Comm_rank 用于计算当前的rank MPI_Comm_size 用于当前通信器里面的总进程数 MPI_Send &amp; MPI_Recv MPI_Send 用于发送数据 MPI_Recv 用于接收数据 接口格式为： 12MPI_Send(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm) 和 12MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status) 对于一个最简单的收发例子如下: 1234567891011121314151617int main(int argc, char ** argv)&#123; int rank, data[100]; MPI_Init(&amp;argc, &amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); if (rank == 0) MPI_Send(data, 100, MPI_INT, 1, 0, MPI_COMM_WORLD); else if (rank == 1) MPI_Recv(data, 100, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); MPI_Finalize(); return 0;&#125; 这里我们指定了固定的数据收发模式，[RANK0]发送[RANK1]接收。更详细的说明在之后进行介绍，这里只作为入门例子。 MPI 通信数据类型一般数据类型(Tip: 下表是用来查的，不是用来背的) MPI datatype C datatype MPL_CHAR char (treated as printable character) MPI_SHORT signed short int MPL_INT signed int MPI_LONG signed long int MPI_LONG_LONG_INT signed long long int MPI_LONG_LONG (as a synonym) signed long long int MPI_SIGNED_CHAR signed char (treated as integral value) MPI_UNSIGNED_CHAR unsigned char (treated as integral value) MPI_UNSIGNED_SHORT unsigned short int MPI_UNSIGNED unsigned int MPI_UNSIGNED_LONG unsigned long int MPI_UNSIGNED_LONG_LONG unsigned long long int MPI_FLOAT float MPI_DOUBLE double MPI_LONG_DOUBLE long double MPL_WCHAR wchar_t (defined in &lt;stddef.h&gt;) (treated as printable character) MPI_C_BOOL Bool MPI_INT_T int8_t MPI_INT16_T int16_t MPI_INT32_T int32_t MPI_INT64_T int64_t MPI UINT8_T uint8_t MPI_UINT16_T uint16_t MPL_UINT32 T uint32_t MPI_UINT64_T uint64_t MPL_C_COMPLEX float_Complex MPI_C_FLOAT_COMPLEX (as a synonym) float Complex MPI_C_DOUBLE_COMPLEX double_Complex MPI_BYTE MPL_PACKED 对于 C++ 有一些拓展: MPl datatype C++ datatype MPI_CXX_BOOL bool MPI_CXX_FLOAT_COMPLEX std::complex&lt;float&gt; MPI_CXX_DOUBLE_COMPLEX std::complex&lt;double&gt; MPI_CXX_LONG_DOUBLE_COMPLEX std::complex&lt;long double&gt; 其中的 MPI_PACKED 和 MPI_BYTE 作为拓展消息类型。就是对数据进行压包后进行发送。 MPI_PACKED 数据类型MPI_PACKED数据类型是一个特殊封装的数据类型，一般用来实现传输地址空间不连续的数据项。 接口格式为： (由于接口文档上，OpenMPI做的更好，后面可能会参考OpenMPI的文档) MPI_PackMPI_UnpackMPI_Pack_size 一个例子： 123456789101112131415161718192021222324252627282930313233using namespace std;int main(int argc, char *argv[]) &#123; MPI_Init(&amp;argc, &amp;argv); int position; int i = 1; int j = 2; int a[2]; int myrank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank); if (myrank == 0) &#123; /* I am sending */ position = 0; int true_packed_size; MPI_Pack_size(2, MPI_INT, MPI_COMM_WORLD, &amp;true_packed_size); cout &lt;&lt; &quot;True packed size = &quot; &lt;&lt; true_packed_size &lt;&lt; endl; char *buffer = new char[true_packed_size]; cout &lt;&lt; &quot;Packing number i = &quot; &lt;&lt; i &lt;&lt; &quot;, pos = &quot; &lt;&lt; position &lt;&lt; endl; MPI_Pack(&amp;i, 1, MPI_INT, buffer, 1000, &amp;position, MPI_COMM_WORLD); cout &lt;&lt; &quot;Packing number j = &quot; &lt;&lt; j &lt;&lt; &quot;, pos = &quot; &lt;&lt; position &lt;&lt; endl; MPI_Pack(&amp;j, 1, MPI_INT, buffer, 1000, &amp;position, MPI_COMM_WORLD); cout &lt;&lt; &quot;Packing finished, pos = &quot; &lt;&lt; position &lt;&lt; endl; MPI_Send(buffer, position, MPI_PACKED, 1, 0, MPI_COMM_WORLD); delete[] buffer; &#125; else &#123; MPI_Recv(a, 2, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); cout &lt;&lt; &quot;a = &quot; &lt;&lt; a[0] &lt;&lt; &quot;, &quot; &lt;&lt; a[1] &lt;&lt; endl; &#125; MPI_Finalize();&#125; MPI 点对点通信阻塞通信和非阻塞通信阻塞通信主要特征是：如果假设进程A发送，进程B接收。在这一对收发任务完成之前，进程A会一致在发送接口处停住，而B会在接收接口处停住。 发送类别主要有以下四类： 标准模式 MPI_Send/MPI_Isend： 自由发送接收，不考虑其它进程状态 缓存模式 MPI_Bsend/MPI_Ibsend： 由用户显式提供缓存区，辅助通信 同步模式 MPI_Ssend/MPI_Issend： 通信双方先建立联系，再通信 就绪模式 MPI_Rsend/MPI_Irsend： 接受进程必须先于发送进程提出通信要求 一般使用的时候主要使用标准模式即可。 MPI 原语 阻塞 非阻塞 Standard Send MPI_Send MPI_Isend Buffered Send MPI_Bsend MPI_Ibsend Synchronous Send MPI_Ssend MPI_Issend Ready Send MPI_Rsend MPI_Irsend Receive MPI_Recv MPI_Irecv Completion Check MPI_Wait MPI_Test 流水/管线通信模式例子： 12345┌───────┐ ┌───────┐ ┌───────┐│ │ │ │ │ ││ x ├──&gt;│ y ├──&gt;│ z ││ │ │ │ │ │└───────┘ └───────┘ └───────┘ Example： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879using namespace std;int function_p(int w) &#123; return w + w;&#125;int function_q(int x) &#123; return x * x;&#125;int function_r(int y) &#123; return y - 2;&#125;int main(int argc, char *argv[]) &#123; MPI_Init(&amp;argc, &amp;argv); int world_size, my_rank; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank); if (my_rank == 0) &#123; int ans[10]; MPI_Request req[10]; for (int index = 0; index &lt; 10; ++index) &#123; int number = index; MPI_Isend(&amp;number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, &amp;req[index]); ans[index] = function_p(number); ans[index] = function_q(ans[index]); ans[index] = function_r(ans[index]); &#125; cout &lt;&lt; &quot;should be: &quot;; for (int index = 0; index &lt; 10; ++index) &#123; cout &lt;&lt; ans[index] &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; endl; &#125; else if (my_rank == 1) &#123; MPI_Request req; int number; int cnt = 0; while(1) &#123; MPI_Irecv(&amp;number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &amp;req); MPI_Wait(&amp;req, MPI_STATUS_IGNORE); number = function_p(number); MPI_Isend(&amp;number, 1, MPI_INT, 2, 0, MPI_COMM_WORLD, &amp;req); cnt++; if (cnt == 10) &#123;break; &#125; &#125; &#125; else if (my_rank == 2) &#123; MPI_Request req; int number; int cnt = 0; while(1) &#123; MPI_Irecv(&amp;number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, &amp;req); MPI_Wait(&amp;req, MPI_STATUS_IGNORE); number = function_q(number); MPI_Isend(&amp;number, 1, MPI_INT, 3, 0, MPI_COMM_WORLD, &amp;req); cnt++; if (cnt == 10) &#123;break; &#125; &#125; &#125; else if (my_rank == 3) &#123; MPI_Request req; int number[10]; int cnt = 0; while(1) &#123; MPI_Irecv(&amp;number[cnt], 1, MPI_INT, 2, 0, MPI_COMM_WORLD, &amp;req); MPI_Wait(&amp;req, MPI_STATUS_IGNORE); number[cnt] = function_r(number[cnt]); cnt++; if (cnt == 10) &#123;break; &#125; &#125; for (int index = 0; index &lt; 10; index++) cout &lt;&lt; number[index] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; &#125; MPI_Finalize();&#125; 双缓冲模式例子： 1234567┌─────────┐ ┌─────────────┐ ┌─────────┐│ x buf 0 ├──&gt;│ ├──&gt;│ y buf 0 │└─────────┘ │ │ └─────────┘ │ Y = F(X) │┌─────────┐ │ │ ┌─────────┐│ x buf 1 ├──&gt;│ ├──&gt;│ y buf 1 │└─────────┘ └─────────────┘ └─────────┘ 针对计算复杂度比较高的情况，第一轮次使用xbuf0和ybuf0，第二轮次使用xbuf1和ybuf1，两组缓冲轮流使用。 对位置消息探查主要函数有： MPI_Probe MPI_Iprobe MPI_Probe 的接口和 MPI_Recv 近似，他是不接受数据的 Recv下面这个例子辅助理解(From MPI-Tutorial)： 123456789101112131415161718192021222324252627282930int number_amount;if (world_rank == 0) &#123; const int MAX_NUMBERS = 100; int numbers[MAX_NUMBERS]; // Pick a random amount of integers to send to process one srand(time(NULL)); number_amount = (rand() / (float)RAND_MAX) * MAX_NUMBERS; // Send the random amount of integers to process one MPI_Send(numbers, number_amount, MPI_INT, 1, 0, MPI_COMM_WORLD); printf(&quot;0 sent %d numbers to 1\\n&quot;, number_amount);&#125; else if (world_rank == 1) &#123; MPI_Status status; // Probe for an incoming message from process zero MPI_Probe(0, 0, MPI_COMM_WORLD, &amp;status); // When probe returns, the status object has the size and other // attributes of the incoming message. Get the message size MPI_Get_count(&amp;status, MPI_INT, &amp;number_amount); // Allocate a buffer to hold the incoming numbers int* number_buf = (int*)malloc(sizeof(int) * number_amount); // Now receive the message with the allocated buffer MPI_Recv(number_buf, number_amount, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(&quot;1 dynamically received %d numbers from 0.\\n&quot;, number_amount); free(number_buf);&#125; MPI 通信域MPI 集群通信 类型 函数名 含义 通信 MPI_Bcast 一对多广播同样的消息 MPI_Gather 多对一收集各个进程的消息 MPI_Gatherv MPI_Gather的一般化 MPI_Allgather 全局收集 MPI_Allgatherv MPI_Allgather的一般化 MPI_Scatter 一对多散播不同的消息 MPI_Scatterv MPI_Scatter的一般化 MPI_Alltoall 多对多全局交换消息 MPI_Alltoallv MPI_Alltoall的一般化 聚集 MPI_Reduce 多对一归约 MPI_Allreduce MPI_Reduce的一般化 MPI_Reduce_scatter MPI_Reduce的一般化 MPI_Scan 扫描 同步 MPI_Barrier 路障同步 OpenMP快速上手实例实例之前为了说明各种实例的效果和性能，这里先补充一下关于计时的方法。 方法1：time1234567891011121314151617181920212223int main()&#123; time_t tm_now; time(&amp;tm_now); // 1970-1-1,00:00:00到现在的秒数 printf(&quot;now time is %ld second\\n&quot;, tm_now); // 转换成本地时间，精确到秒 struct tm *p_local_tm ; p_local_tm = localtime(&amp;tm_now) ; printf(&quot;now datetime: %04d-%02d-%02d %02d:%02d:%02d\\n&quot;, p_local_tm-&gt;tm_year+1900, p_local_tm-&gt;tm_mon+1, p_local_tm-&gt;tm_mday, p_local_tm-&gt;tm_hour, p_local_tm-&gt;tm_min, p_local_tm-&gt;tm_sec); return 0;&#125; 方法2：gettimeofday12345678910111213141516171819202122int main()&#123; struct timeval tm_now; // 获取当前时间戳(tv_sec, tv_usec) gettimeofday(&amp;tm_now,NULL); // 第二个参数是时区 // 转换成本地时间，精确到秒 struct tm *p_local_tm; p_local_tm = localtime(&amp;tm_now.tv_sec) ; printf(&quot;now datetime: %04d-%02d-%02d %02d:%02d:%02d.%06ld\\n&quot;, p_local_tm-&gt;tm_year+1900, p_local_tm-&gt;tm_mon+1, p_local_tm-&gt;tm_mday, p_local_tm-&gt;tm_hour, p_local_tm-&gt;tm_min, p_local_tm-&gt;tm_sec, tm_now.tv_usec); // 有微秒时间戳了 return 0;&#125; 方法3：clock_gettime1234567891011121314151617181920212223242526void print_timestamp(int use_monotonic)&#123; struct timespec tm_now; // 获取当前时间戳(tv_sec, tv_usec) if(use_monotonic) clock_gettime(CLOCK_MONOTONIC, &amp;tm_now); // 单调时间，屏蔽手动修改时间 else clock_gettime(CLOCK_REALTIME, &amp;tm_now); // 机器时间 // 转换成本地时间，精确到秒 struct tm *p_local_tm; p_local_tm = localtime(&amp;tm_now.tv_sec) ; printf(&quot;now datetime: %04d-%02d-%02d %02d:%02d:%02d.%09ld\\n&quot;, p_local_tm-&gt;tm_year+1900, p_local_tm-&gt;tm_mon+1, p_local_tm-&gt;tm_mday, p_local_tm-&gt;tm_hour, p_local_tm-&gt;tm_min, p_local_tm-&gt;tm_sec, tm_now.tv_nsec); // 纳秒时间&#125; 方法4：chrono库12345678auto start = std::chrono::system_clock::now();...auto end = std::chrono::system_clock::now();std::chrono::duration&lt;double&gt; elapsed_seconds = end - start;time1 = elapsed_seconds.count(); 方法5：rdtsc最精准也是最难用的方法 123456789101112uint64_t get_tsc() // Time Stamp Counter寄存器&#123; uint64_t x; __asm__ volatile(&quot;rdtsc&quot; : &quot;=A&quot;(x)); return x; uint64_t a, d; __asm__ volatile(&quot;rdtsc&quot; : &quot;=a&quot;(a), &quot;=d&quot;(d)); return (d &lt;&lt; 32) | a; uint32_t cc = 0; __asm__ volatile (&quot;mrc p15, 0, %0, c9, c13, 0&quot;:&quot;=r&quot; (cc)); return (uint64_t)cc; &#125; 使用限制： 机器需要有constant_tsc的特性，使用：cat /proc/cpu_info | grep constant_tsc命令可以确定是否有该特性 乱序执行核能会打乱时钟周期的测量，必要时需要制造“依赖指令”去避免乱序执行 必要时需要使用memory barrier cat /proc/cpuinfo | grep rdtscp 如果开启，可以使用rdtscp，更精准一点。使用方法基本一致： 1uint64_t get_tscp() &#123; uint64_t a, d; __asm__ volatile(&quot;rdtscp&quot; : &quot;=a&quot;(a), &quot;=d&quot;(d)); return (d &lt;&lt; 32) | a; &#125; 小结如果使用C++，那么使用chrono库是最好的选择，相信STL不会翻大车如果机器由constant tsc特性，那么可以使用rdtsc方法如果没有，那么使用gettimeofday时一个比较稳定的方法 实例1：不适用并行的例子刻意并行化，或者过低的并行层级往往会带来巨大的负优化。这里用一个求和的例子说明。采用如下方式对一个数组求和。 MPI实现方案","categories":[{"name":"Parallel","slug":"Parallel","permalink":"https://chivier.github.io/categories/Parallel/"},{"name":"Study","slug":"Parallel/Study","permalink":"https://chivier.github.io/categories/Parallel/Study/"},{"name":"Parallel/MPI","slug":"Parallel/Study/Parallel-MPI","permalink":"https://chivier.github.io/categories/Parallel/Study/Parallel-MPI/"}],"tags":[{"name":"Parallel","slug":"Parallel","permalink":"https://chivier.github.io/tags/Parallel/"},{"name":"Study","slug":"Study","permalink":"https://chivier.github.io/tags/Study/"},{"name":"Parallel/MPI","slug":"Parallel-MPI","permalink":"https://chivier.github.io/tags/Parallel-MPI/"}]},{"title":"2204-qinitial","slug":"2022/2204-qinitial","date":"2022-04-26T10:21:17.000Z","updated":"2022-04-26T10:22:48.632Z","comments":true,"path":"2022/04/26/2022/2204-qinitial/","link":"","permalink":"https://chivier.github.io/2022/04/26/2022/2204-qinitial/","excerpt":"安装小工具，gkd","text":"安装小工具，gkd https://github.com/Chivier/qinitial 编译器 gcc llvm intel compilers mpich rust python pyenv cmake 基本工具 git cmake zsh jupyter fzf ag search htop tmux clang-format vim basic LibrariesTODO References","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Tricks","slug":"Linux/Tricks","permalink":"https://chivier.github.io/categories/Linux/Tricks/"},{"name":"Tools","slug":"Linux/Tricks/Tools","permalink":"https://chivier.github.io/categories/Linux/Tricks/Tools/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Tools","slug":"Tools","permalink":"https://chivier.github.io/tags/Tools/"},{"name":"Tricks","slug":"Tricks","permalink":"https://chivier.github.io/tags/Tricks/"}]},{"title":"2203-OMP2CD重新实现","slug":"2022/2203-OMP2CD重新实现","date":"2022-04-17T05:00:07.000Z","updated":"2022-04-17T05:00:28.055Z","comments":true,"path":"2022/04/17/2022/2203-OMP2CD重新实现/","link":"","permalink":"https://chivier.github.io/2022/04/17/2022/2203-OMP2CD%E9%87%8D%E6%96%B0%E5%AE%9E%E7%8E%B0/","excerpt":"之所以会有这一片文章，是因为 LLVM OMP2CD 的项目中出现了一些不太符合实验数据的情况，其项目完整性和项目可用性存疑。在这里提出一些我的个人异议。并且基于此异议提出新的个人实现方案。","text":"之所以会有这一片文章，是因为 LLVM OMP2CD 的项目中出现了一些不太符合实验数据的情况，其项目完整性和项目可用性存疑。在这里提出一些我的个人异议。并且基于此异议提出新的个人实现方案。 由于一周前 LLVM14 正式发布稳定版本，因此之后的实现方案基于 LLVM14 进行。（好吧其实我个人之会 LLVM9 以前的项目框架，12 还在学习中，之后打算写一个 LLVM12 的学习笔记） 论文阅读首先看论文原文： https://dl.acm.org/doi/pdf/10.1145/3155288 走的是一个传统的 LLVM 框架： 首先是前端分析生成 AST 之后在 AST 基础上生成 Annotation 多粒度并行转换，Codelet：细，TP：粗 CDG 转换，Codelet Graph 代码生成 TP Rule： TP- 1: The declaration of a function, other than main(), that contains an omp executable directive. TP- 2: An omp region. Codelet Rule: CBB- 1: An omp executable directive. CBB- 2: A call to a function containing an omp executable directive. CBB- 3: The first statement in an omp region. CBB- 4: The first statement in a function, other than main(), containing an omp executable directive. CBB- 5: The first statement of a branch, provided any of the branch’s parent nodes are part of a CBB. CBB- 6: The implicit barrier of an omp region. CBB- 7: The statement following a CBB whose leader was created using rules CBB-1, CBB-2, or CBB-6. 翻译器逻辑整理维持代码运行的内容分布在两个部分里： extra-tools clang 12345678910111213141516171819202122./llvm/tools/clang/include/clang/AST/OpenMPClause.h:class OMPCodeletClause : public OMPClause &#123; ./llvm/tools/clang/include/clang/AST/OpenMPClause.h: OMPCodeletClause(SourceLocation StartLoc, SourceLocation End Loc) ./llvm/tools/clang/include/clang/AST/OpenMPClause.h: OMPCodeletClause() ./llvm/tools/clang/include/clang/AST/RecursiveASTVisitor.h:bool RecursiveASTVisitor&lt;Derived&gt;::VisitOMPCodeletClaus e(OMPCodeletClause *) &#123; ./llvm/tools/clang/include/clang/Basic/OpenMPKinds.def:OPENMP_CLAUSE(codelet, OMPCodeletClause) ./llvm/tools/clang/lib/AST/StmtProfile.cpp:void OMPClauseProfiler::VisitOMPCodeletClause(const OMPCodeletClause *) &#123;&#125; ./llvm/tools/clang/lib/AST/StmtPrinter.cpp:void OMPClausePrinter::VisitOMPCodeletClause(OMPCodeletClause*) &#123;&#125; ./llvm/tools/clang/lib/Sema/SemaOpenMP.cpp: return new (Context) OMPCodeletClause(StartLoc, EndLoc); ./llvm/tools/clang/lib/Sema/TreeTransform.h:TreeTransform&lt;Derived&gt;::TransformOMPCodeletClause(OMPCodeletClause *C) &#123; ./llvm/tools/clang/lib/Serialization/ASTWriterStmt.cpp:void OMPClauseWriter::VisitOMPCodeletClause(OMPCodeletClaus e *) &#123;&#125; ./llvm/tools/clang/lib/Serialization/ASTReaderStmt.cpp: C = new (Context) OMPCodeletClause(); ./llvm/tools/clang/lib/Serialization/ASTReaderStmt.cpp:void OMPClauseReader::VisitOMPCodeletClause(OMPCodeletClaus e *) &#123;&#125; ./llvm/tools/clang/tools/libclang/CIndex.cpp:void OMPClauseEnqueue::VisitOMPCodeletClause(const OMPCodeletClause * ) &#123;&#125; ./llvm/tools/clang/tools/extra/omp2cd/src/Compiler/ASTVisit.cpp: else if (dyn_cast&lt;OMPCodeletClause&gt;(clause )) &#123; 移植 llvm 14 已经完成： https://github.com/Chivier/chranslate 思路整理如果我们使用 LLVM 的框架，我们需要遍历 AST。 读取命令行参数 只处理两层以内的 omp 嵌套。 代码精读： 评价和思考这个论文的工作其实不复杂，可以说非常工程，首先先评价一下这个工作。这个工作虽然发了 TACO，但是惨淡的引用量反应了很多问题： 项目代码混乱，对于AST的行为描述上没有很好的继承clang的优势，而是自己打散重新建立，不仅麻烦，而且有一些逻辑上错误 项目在clang的代码部分这边有很多疏漏，应该继承一个出来，而不是直接在clang的基础上改代码，（作者应该不太懂设计模式的问题） 项目的可用性存疑，在 omp 嵌套的时候很多时候没法跑，这个应该是第一点导致的 这个和 llvm-3.9 的历史也有一定的关系，有一些部分 API 不是作者不想进行继承，而是作者没有办法进行继承。 官网说明： https://openmp.llvm.org/optimizations/OpenMPOpt.html 有一句： LLVM, since version 11 (12 Oct 2020), has an OpenMP-Aware optimization pass as well as the ability to perform “scalar optimizations” across OpenMP region boundaries.In-depth discussion of the topic can be found here. 说明 2020 年之前是不可能做成一个可以便捷拓展的项目的。 References","categories":[{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/categories/Compiler/"},{"name":"LLVM","slug":"Compiler/LLVM","permalink":"https://chivier.github.io/categories/Compiler/LLVM/"},{"name":"Dataflow","slug":"Compiler/LLVM/Dataflow","permalink":"https://chivier.github.io/categories/Compiler/LLVM/Dataflow/"},{"name":"DARTS","slug":"Compiler/LLVM/Dataflow/DARTS","permalink":"https://chivier.github.io/categories/Compiler/LLVM/Dataflow/DARTS/"}],"tags":[{"name":"LLVM","slug":"LLVM","permalink":"https://chivier.github.io/tags/LLVM/"},{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/tags/Compiler/"},{"name":"Dataflow","slug":"Dataflow","permalink":"https://chivier.github.io/tags/Dataflow/"},{"name":"DARTS","slug":"DARTS","permalink":"https://chivier.github.io/tags/DARTS/"}]},{"title":"2204-GPU程序优化方法","slug":"2022/2204-GPU程序优化方法","date":"2022-04-10T19:42:41.000Z","updated":"2022-04-10T19:43:03.061Z","comments":true,"path":"2022/04/11/2022/2204-GPU程序优化方法/","link":"","permalink":"https://chivier.github.io/2022/04/11/2022/2204-GPU%E7%A8%8B%E5%BA%8F%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/","excerpt":"在目前为止的科研和学习经历中，cuda 的使用已经成为了日程的一个通电和要点问题。这里总结一些我用过的优化方法，留作笔记。","text":"在目前为止的科研和学习经历中，cuda 的使用已经成为了日程的一个通电和要点问题。这里总结一些我用过的优化方法，留作笔记。 GPU 八门神器1 人多力量大这是一个“不算优化的优化”，如何在 cuda 中调用多张卡进行计算。 首先一个不是办法的办法： 使用 MPI 进行第一层级并行，通信到不同的机器上，在每一个机器上使用一张卡。（好吧我编不下去了，这个方法蠢了，单机多卡完全摆烂了） (不过本优化还有一个明显的特性：依赖内存带宽，这个是 PCIE4.0 机器目前的瓶颈之一，NVLink 某种意义上可以有效处理这一矛盾，但是他也只是一种瓶颈转移——把瓶颈转移到我们的经费上) 使用的时候和大部分的方法是相同的，但是不同之处是我们需要使用 cudaSetDevice 去手动设置使用的设备编号。参考 cudatest-18。 但是由于鲁棒性的需求，我们的 cudaSetDevice 在下标超出范围的时候还是可以正常使用的，一般编号超过范围的卡，我们会把卡的计算信息映射到最后一张卡上面。但是会返回 cudaError 的 bool 数值，详情参考 cudaSetDevice 的 API 手册。 下面是使用 cudatest19 把 8 个 1080 都用满的例子。 2 fast math &amp; 精度如果程序中的数学函数：三角函数、快速傅立叶变换、幂次、根号，等等。这些使用频率过高的时候，我们在 cuda 中可以从用 fast math 编译选项进行优化。一般会有 5~15%的效率提升。 nvcc -h 中可以读取 –use_fast_math 的具体内容和功能 3 wrap divergence之前说过： 12345现在的 GPU 架构中- 一个 GPU &#x3D; 多个 Streaming Multiprocessor (SM) + cache 组成- 一个 SM &#x3D; Streaming Processor（SP）+ cache 组成- SM 用于处理 block- SP 用于处理 thread 但是我们调度的时候不会精细调度每一个 thread, 我们会用 wrap（1 wrap = 32 threads）去考虑这个事情。所以如果出现分支的时候我们会发生所谓的 wrap divergence。（这个概念最早出现在 Cray 机器的 PDE 求解上，我以前一直以为 GPU 也会做分支预测，直到事情变得不太健康我才发现这个会消耗很多性能） 这里参考一个例子 20-wrapdivergence 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117using std::chrono::duration_cast;using std::chrono::milliseconds;using std::chrono::seconds;using std::chrono::system_clock;template &lt;class Func&gt;__global__ void kernel(int n, Func func) &#123; for (int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func(i); &#125;&#125;template &lt;class Func1, class Func2&gt;__global__ void kernel_split(int n, Func1 func1, Func2 func2) &#123; if (threadIdx.x &amp; 2 == 1) &#123; for(int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func1(i); &#125; &#125; else &#123; for(int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func2(i); &#125; &#125;&#125;template &lt;class Func1, class Func2&gt;__global__ void kernel_better(int n, Func1 func1, Func2 func2) &#123; for (int i = 0; i &lt; n; i += 2) &#123; func2(i); &#125; for (int i = 1; i &lt; n; i += 2) &#123; func1(i); &#125;&#125;int main() &#123; int n = 1 &lt;&lt; 26; int block_dim = 128; int grid_dim = (n - 1) / block_dim; cudaDeviceSynchronize(); auto begin_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); thrust::host_vector&lt;float&gt; x_host(n); thrust::host_vector&lt;float&gt; y_host(n); thrust::generate(x_host.begin(), x_host.end(), []&#123;return std::rand() / 3.0;&#125;); thrust::generate(y_host.begin(), y_host.end(), []&#123;return std::rand() / 11.0;&#125;); thrust::device_vector&lt;float&gt; x_dev(n); thrust::device_vector&lt;float&gt; y_dev(n); x_dev = x_host; y_dev = y_host; kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [x = x_dev.data(), y = y_dev.data()] __device__ (int index)&#123; if (index % 2 == 1) x[index] = x[index] + y[index]; else x[index] = x[index] - y[index]; &#125;); checkCudaErrors(cudaDeviceSynchronize()); x_host = x_dev; auto end_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); cudaDeviceSynchronize(); printf(&quot;%ld\\n&quot;, end_millis - begin_millis); cudaDeviceSynchronize(); begin_millis = end_millis; thrust::generate(x_host.begin(), x_host.end(), []&#123;return std::rand() / 3.0;&#125;); thrust::generate(y_host.begin(), y_host.end(), []&#123;return std::rand() / 11.0;&#125;); x_dev = x_host; y_dev = y_host; kernel_split&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [x = x_dev.data(), y = y_dev.data()] __device__ (int index) &#123; x[index] = x[index] + y[index]; &#125;, [x = x_dev.data(), y = y_dev.data()] __device__ (int index) &#123; x[index] = x[index] - y[index]; &#125;); checkCudaErrors(cudaDeviceSynchronize()); x_host = x_dev; end_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); cudaDeviceSynchronize(); printf(&quot;%ld\\n&quot;,end_millis - begin_millis); cudaDeviceSynchronize(); begin_millis = end_millis; thrust::generate(x_host.begin(), x_host.end(), []&#123;return std::rand() / 3.0;&#125;); thrust::generate(y_host.begin(), y_host.end(), []&#123;return std::rand() / 11.0;&#125;); x_dev = x_host; y_dev = y_host; kernel_better&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [x = x_dev.data(), y = y_dev.data()] __device__ (int index) &#123; x[index] = x[index] + y[index]; &#125;, [x = x_dev.data(), y = y_dev.data()] __device__ (int index) &#123; x[index] = x[index] - y[index]; &#125;); checkCudaErrors(cudaDeviceSynchronize()); x_host = x_dev; end_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); cudaDeviceSynchronize(); printf(&quot;%ld\\n&quot;,end_millis - begin_millis); return 0;&#125; 这个例子有 3 个函数，第一个是没有考虑分支分离的写法，kernel 函数每一次函数都有大量的分支。第二个例子是考虑了分支，我们将分支提取到函数体外层即可（这个例子奇偶数分离出来，但是一般的 x86 平台机器还是可以很好的分支预测的，但是 cuda 的分支预测不是那么强，这就是过于强大的 SIMD 的一种代价吧）第三个例子是没有考虑数据局部性例子 在 n = 1 &lt;&lt; 20 的时候，三个耗时是（毫秒）： 12344 41 9033 在 n = 1 &lt;&lt; 26 的时候，三个耗时是（毫秒）： 1232963 2623...(too long) 这里看到提前分支可以做出很多优化。但是不能为了编程方便忽视空间局部性的问题。在第 8 点中会详细介绍 GPU 内存的问题。 4 register spill &amp; local memory usage &amp; latency hiding4.1 Cuda Memory IntroLocal Memory 这里的意思其实是指 memory where registers and other thread data is spilled 之所以这么设计和 GPU 的架构有关，以 Fermi 架构为例： 图中我们看到我们的 LMEM 指的是 “SMEM 用尽，或者说也就是 SM 资源用尽的时候，额外使用的内存”，充分利用 L1 的存储空间可以发挥最大性能，但是如果我们没有使用好，就会造成 L1 和 L2 通信，正如下面这个链接所示 https://stackoverflow.com/questions/23876594/cuda-local-memory-register-spilling-overhead 从 L2/DRAM 中取数据或者写数据的代价是非常昂贵的。 在 Maxwell 和之后的架构中 L1 和 SMEM 合并 这里官方说了一下 LMEM 的使用场景，如果线程的场景比较复杂，我们就需要进行 register spill 从而达到避免寄存器冲突的目的。具体的 spill 策略未知，官方文档中也只有 heuristics 一词。但是这里也说明了 Spill 不是坏事，数组是通过 SM 的 Register 访问的，这个在上面 20-wrapdivergence 的例子里面有个很好的对比，我们用错了访存顺序，就会导致每一次访存都进行 register spill。 cuda 对数组的使用不是用寄存器的，这个细节问题在下面的这个问题旁敲侧击给了一个漂亮的答案： https://stackoverflow.com/questions/12167926/forcing-cuda-to-use-register-for-a-variable 4.2 Programmers’ Behaviors上述的架构对于我们编程人员有这些指导意义： 在 SM 上的 TB 越多越好，让 Thread Block 不停的跑我们的利用率就会高，在一个 thread 进行等待内存换入换出的时候，GPU 有一个叫 latency hiding 的策略，从而将使用效率变高。但是如果 Thread Block 太多，我们每一个 SM 能分配的寄存器就会变少，所以就会发生 Register Spill, 使用更高级的 L1、L2 Cache 去代替 Registers。所以 TB 不能太多，需要减少 Register Spill 的次数。 简而言之：Thread Block 越多越好，Register 少一些（少一些换入换出）更好。 下面使用一个例子说明。 https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#launch-bounds 基于 modernGPU 项目写了 launchbound mergesort 测试，在 21-目录里对不同的 launch bound 进行测试。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546using std::chrono::duration_cast;using std::chrono::milliseconds;using std::chrono::seconds;using std::chrono::system_clock;using namespace mgpu;int main(int argc, char** argv) &#123; standard_context_t context; cudaDeviceSynchronize(); auto begin_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); int count = 1000000; for(int it = 1; it &lt;= 50; ++it) &#123; mem_t&lt;int&gt; data = fill_random(0, 100000, count, false, context); mergesort(data.data(), count, less_t&lt;int&gt;(), context); std::vector&lt;int&gt; ref = from_mem(data); std::sort(ref.begin(), ref.end()); std::vector&lt;int&gt; sorted = from_mem(data); &#125; auto end_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); cudaDeviceSynchronize(); printf(&quot;%ld\\n&quot;, end_millis - begin_millis); cudaDeviceSynchronize(); begin_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); count = 1000000; for(int it = 1; it &lt;= 50; ++it) &#123; mem_t&lt;int&gt; data = fill_random(0, 100000, count, false, context); launchboundsort(data.data(), count, less_t&lt;int&gt;(), context); std::vector&lt;int&gt; ref = from_mem(data); std::sort(ref.begin(), ref.end()); std::vector&lt;int&gt; sorted = from_mem(data); &#125; end_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); cudaDeviceSynchronize(); printf(&quot;%ld\\n&quot;, end_millis - begin_millis); return 0;&#125; 4.3 shared memory这里其实是两个话题的合并，但是我们一般都会把他们一起使用： 循环分块 + 共享内存预取数据 这种在 Stencil Computing 中特别常见 我们这里举一个例子，2D Laplacian 离散算子，这个是一个非常常见的例子了，就是 $$\\begin{aligned}&amp;\\Delta f=\\frac{\\partial^{2} f}{\\partial x^{2}}+\\frac{\\partial^{2} f}{\\partial y^{2}} \\&amp;=f(x+1, y)+f(x-1, y)-2 f(x, y)+f(x, y+1)+f(x, y-1)-2 f(x, y) \\&amp;=f(x+1, y)+f(x-1, y)+f(x, y+1)+f(x, y-1)-4 f(x, y)\\end{aligned}$$ 那么我们如何用 cuda 实现呢？这里我写几个版本，22 stencil 里程序作为对比。 首先无处理： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950using std::chrono::duration_cast;using std::chrono::milliseconds;using std::chrono::seconds;using std::chrono::system_clock;__global__ void stencil(int row_num, int col_num, int *arr_data, int *result) &#123; auto index = blockIdx.x * blockDim.x + threadIdx.x; auto current_row = index / col_num; auto current_col = index % col_num; auto data0 = arr_data[index]; // up auto data1 = arr_data[(current_row + row_num - 1) % row_num * col_num + current_col]; // down auto data2 = arr_data[(current_row + 1) % row_num * col_num + current_col]; // left auto data3 = arr_data[current_row * col_num + (current_col + col_num - 1) % col_num ]; // right auto data4 = arr_data[current_row * col_num + (current_col + 1) % col_num]; result[index] = data1 + data2 + data3 + data4 - 4 * data0;&#125;int main() &#123; int row_num = 1 &lt;&lt; 14; int col_num = 1 &lt;&lt; 14; int *arr; int *result; cudaMallocManaged(&amp;arr, sizeof(int) * row_num * col_num); cudaMallocManaged(&amp;result, sizeof(int) * row_num * col_num); for (int index = 0; index &lt; row_num * col_num; ++index) &#123; arr[index] = rand() % 1024 - 512; &#125; cudaDeviceSynchronize(); auto begin_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); cudaDeviceSynchronize(); int total_numbers = row_num * col_num; int block_size = 1024; stencil&lt;&lt;&lt;total_numbers / block_size, block_size&gt;&gt;&gt;(row_num, col_num, arr, result); cudaDeviceSynchronize(); auto end_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); printf(&quot;%ld\\n&quot;, end_millis - begin_millis); cudaDeviceSynchronize(); return 0;&#125; 之后加上分块，效果拔群 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950using std::chrono::duration_cast;using std::chrono::milliseconds;using std::chrono::seconds;using std::chrono::system_clock;__global__ void stencil(int row_num, int col_num, int *arr_data, int *result) &#123; auto current_row = blockIdx.x * blockDim.x + threadIdx.x; auto current_col = blockIdx.y * blockDim.y + threadIdx.y; auto index = current_row * col_num + current_col; auto data0 = arr_data[index]; // up auto data1 = arr_data[(current_row + row_num - 1) % row_num * col_num + current_col]; // down auto data2 = arr_data[(current_row + 1) % row_num * col_num + current_col]; // left auto data3 = arr_data[current_row * col_num + (current_col + col_num - 1) % col_num ]; // right auto data4 = arr_data[current_row * col_num + (current_col + 1) % col_num]; result[index] = data1 + data2 + data3 + data4 - 4 * data0;&#125;int main() &#123; int row_num = 1 &lt;&lt; 14; int col_num = 1 &lt;&lt; 14; int *arr; int *result; cudaMallocManaged(&amp;arr, sizeof(int) * row_num * col_num); cudaMallocManaged(&amp;result, sizeof(int) * row_num * col_num); for (int index = 0; index &lt; row_num * col_num; ++index) &#123; arr[index] = rand() % 1024 - 512; &#125; cudaDeviceSynchronize(); auto begin_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); cudaDeviceSynchronize(); int total_numbers = row_num * col_num; int block_size = 1024; stencil&lt;&lt;&lt;dim3(row_num / 32, col_num / 32, 1), dim3(32, 32, 1)&gt;&gt;&gt;(row_num, col_num, arr, result); cudaDeviceSynchronize(); auto end_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); printf(&quot;%ld\\n&quot;, end_millis - begin_millis); cudaDeviceSynchronize(); return 0;&#125; 最后加上共享内存数据预取，这个工作边际效益递减，作用有限 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950using std::chrono::duration_cast;using std::chrono::milliseconds;using std::chrono::seconds;using std::chrono::system_clock;__global__ void stencil(int row_num, int col_num, int *arr_data, int *result) &#123; auto current_row = blockIdx.x * blockDim.x + threadIdx.x; auto current_col = blockIdx.y * blockDim.y + threadIdx.y; auto index = current_row * col_num + current_col; auto data0 = arr_data[index]; // up auto data1 = arr_data[(current_row + row_num - 1) % row_num * col_num + current_col]; // down auto data2 = arr_data[(current_row + 1) % row_num * col_num + current_col]; // left auto data3 = arr_data[current_row * col_num + (current_col + col_num - 1) % col_num ]; // right auto data4 = arr_data[current_row * col_num + (current_col + 1) % col_num]; result[index] = data1 + data2 + data3 + data4 - 4 * data0;&#125;int main() &#123; int row_num = 1 &lt;&lt; 14; int col_num = 1 &lt;&lt; 14; int *arr; int *result; cudaMallocManaged(&amp;arr, sizeof(int) * row_num * col_num); cudaMallocManaged(&amp;result, sizeof(int) * row_num * col_num); for (int index = 0; index &lt; row_num * col_num; ++index) &#123; arr[index] = rand() % 1024 - 512; &#125; cudaDeviceSynchronize(); auto begin_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); cudaDeviceSynchronize(); int total_numbers = row_num * col_num; int block_size = 1024; stencil&lt;&lt;&lt;dim3(row_num / 32, col_num / 32, 1), dim3(32, 32, 1)&gt;&gt;&gt;(row_num, col_num, arr, result); cudaDeviceSynchronize(); auto end_millis = duration_cast&lt;milliseconds&gt;(system_clock::now().time_since_epoch()).count(); printf(&quot;%ld\\n&quot;, end_millis - begin_millis); cudaDeviceSynchronize(); return 0;&#125; 5 unroll循环展开，至于目的不做冗余介绍，这里直接展示一下 unroll 用法。在 22 中第三个例子已经使用了，只需要 #pragma unroll 一句即可 6 zerocopy一个非常简单易用的 trick https://migocpp.wordpress.com/2018/06/08/cuda-memory-access-global-zero-copy-unified/ 简而言之，在 host 使用命令：cudaHostRegisterMapped之后用 cudaHostGetDevicePointer 进行映射最后解除绑定 cudaHostUnregister 即，如果我们数据只会在 GPU 产生和使用，我们不需要来回进行拷贝。 例子如下 12345678910111213141516// First, pin the memory (or cudaHostAlloc instead)cudaHostRegister(h_a, …, cudaHostRegisterMapped);cudaHostRegister(h_b, …, cudaHostRegisterMapped);cudaHostRegister(h_c, …, cudaHostRegisterMapped);cudaHostGetDevicePointer(&amp;a, h_a, 0);cudaHostGetDevicePointer(&amp;b, h_b, 0);cudaHostGetDevicePointer(&amp;c, h_c, 0);kernel&lt;&lt;&lt;...&gt;&gt;&gt;(a, b, c);cudaDeviceSynchronize();// unpin/release host memorycudaHostUnregister(h_a);cudaHostUnregister(h_b);cudaHostUnregister(h_c); 7 coalesced acccess和 4.3 小节中的例子一样，但是那个例子因为边界情况，有一些复杂，这里补充说明一下 问题的出现在于我们取的数据不是连续数据。 在图。(a) n 个长度为 m 的向量以线性方式存储。向量 j 的元素 i 用 v j i 表示，GPU 内核中的每个线程都分配给一个 m 长的向量。CUDA 中的线程组成一个块数组，GPU 中的每个线程都有一个唯一的 id，可以定义为 indx = bd * bx + tx，其中 bd 表示块维度，bx 表示块索引，tx 表示每个块中的线程索引。 垂直箭头表示平行线程访问每个向量的第一个分量，这种情况下，内存访问不是连续的。通过对这些地址之间的间隔进行归零(如上图所示的红色箭头) ，内存访问就得到了合并。 8 bank conflicthttps://blog.csdn.net/weixin_42730667/article/details/106171382 GPU 的共享内存，实际上是 32 块内存条通过并联组成的，每个时钟周期都可以读取一个 int。第 i 块内存，负责 addr % 32 == i 的数据。这样交错存储，可以保证随机访问时，访存能够尽量分摊到 32 个块。 如果在block内多个线程访问的地址落入到同一个bank内，那么就会访问同一个bank就会产生bank conflict，这些访问将是变成串行，在实际开发调式中非常主要bank conflict. 处理方法非常简单，我们不要把 shared memory 开辟的空间设置成 32 的倍数即可（线性同余方程，原理也很好理解） 也可以采用一个 API 的办法： 使用 cudaDeviceGetSharedMemConfig 手动修改 GPU 的 shared memory ，少用一点，不过这个办法看起来不如上面的划算，其实性能差不太多。因为上面的办法实际上也会有空间浪费。 思考和小结上述诸多技术都是不断学习总结的成果。我认为之后我们应该更多的关注日常软件的更新里的细节，其中 register spill 和 fast math 的问题其实是在 blender 的 issue 里面学习的，学习在于日常的积累和发现。 此外，我觉得用好 cuda 需要写更多的程序和例子。 下一步可以做的工作自从 LLVM 中加入了 cuda codegen 之后，我觉得可以考虑加入一些基于编译器前端的自动化的工作。 例如能否测试一个任务的复杂程度，从而评估一个合适的 launch bound。这个工作其实本来就应该交给编译器去完成，而不是让程序员自己数自己用的寄存器数目，自己考虑自己的 block 数目，这个怎么说都不太人性化。如果做的不好，可能会像 taichi 那样做成 flatten mode，会为了简化编程牺牲很多性能，做的过多可能会像 sycl 一样变得僵硬难用。这里能否建立一些合适的模型去评估可行性是一个值得思考的问题。 Reference https://numba.readthedocs.io/en/stable/cuda/fastmath.html https://docs.nvidia.com/cuda/cuda-math-api/group__CUDA__MATH__INTRINSIC__SINGLE.html https://developer.download.nvidia.com/CUDA/training/register_spilling.pdf https://stackoverflow.com/questions/12167926/forcing-cuda-to-use-register-for-a-variable https://www.carlpearson.net/pdf/2016nuggets.pdf https://stackoverflow.com/questions/21196685/function-as-argument-of-thrust-iterator-cuda https://www.sciencedirect.com/science/article/abs/pii/S016781911300094X https://www.nvidia.com/content/PDF/isc-2011/Brandvik.pdf https://migocpp.wordpress.com/2018/06/08/cuda-memory-access-global-zero-copy-unified/ https://blog.csdn.net/weixin_42730667/article/details/106171382 https://www.microway.com/hpc-tech-tips/gpu-shared-memory-performance-optimization/ https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html","categories":[{"name":"Cuda","slug":"Cuda","permalink":"https://chivier.github.io/categories/Cuda/"},{"name":"Parallel","slug":"Cuda/Parallel","permalink":"https://chivier.github.io/categories/Cuda/Parallel/"},{"name":"Develop","slug":"Cuda/Parallel/Develop","permalink":"https://chivier.github.io/categories/Cuda/Parallel/Develop/"}],"tags":[{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/tags/Develop/"},{"name":"Cuda","slug":"Cuda","permalink":"https://chivier.github.io/tags/Cuda/"},{"name":"Parallel","slug":"Parallel","permalink":"https://chivier.github.io/tags/Parallel/"}]},{"title":"2203-收藏夹整理系列1","slug":"2022/2203-收藏夹整理系列1","date":"2022-03-28T10:14:34.000Z","updated":"2022-03-28T10:18:12.127Z","comments":true,"path":"2022/03/28/2022/2203-收藏夹整理系列1/","link":"","permalink":"https://chivier.github.io/2022/03/28/2022/2203-%E6%94%B6%E8%97%8F%E5%A4%B9%E6%95%B4%E7%90%86%E7%B3%BB%E5%88%971/","excerpt":"这一系列的文章主要记录一下我从 Chrome 迁移到 Edge 的过程。","text":"这一系列的文章主要记录一下我从 Chrome 迁移到 Edge 的过程。 插件1Password密码管理工具，没有它活不下去。之前 Keepass 在 Linux 上总是会奇怪的崩溃，让我非常头疼。 Plasma IntegrationPlasma 桌面环境增强工具 Automa自动化神器 SingleFile网页下载神器 Latex Toolshttps://www.ctan.org/pkg/包下载，不多介绍了 https://www.overleaf.com/project/Overleaf https://tableconvert.com/csv-to-latexhttps://www.tablesgenerator.com/#表格转换，写作神器 https://www.overleaf.com/latex/templates模板大全 https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols符号大全 https://texample.net/tikz/examples/Tikz 做图 https://www.latexstudio.net/archives/51781.html好用的模板（算法和伪代码模块） Entertainmenthttps://store.steampowered.com/Steam https://skylines.paradoxwikis.com/Beginner%27s_guideSkylines Tutorial https://docs.screeps.com/introduction.html#Game-worldScreeps Tutorial https://steamcommunity.com/sharedfiles/filedetails/?id=2060888276Selfless Hero Answers http://flightgear.sourceforge.net/manual/FilghtGear Manual https://www.fanatical.com/en/Fanatical https://www.humblebundle.com/Humble Bundle NiceProjectshttps://github.com/danistefanovic/build-your-own-x教程合集 https://github.com/EbookFoundation/free-programming-books编程书籍合集 https://github.com/fengdu78/lihang-code统计学习方法代码 https://www.ioccc.org/IOCCC http://ai.stanford.edu/~asaxena/reconstruction3d/3D 重建 https://www.openvim.com/Vim 教程 https://llvm-tutorial-cn.readthedocs.io/en/latest/LLVM 开发新语言 https://vulkan-tutorial.com/Vulkan https://gitlab.kitware.com/paraview/paraviewParaview https://www.agner.org/optimize/软件优化教程 https://pbr-book.org/3ed-2018/contents物理渲染 https://yangwc.com/2019/07/04/FluidRendering/流体渲染","categories":[{"name":"Tools","slug":"Tools","permalink":"https://chivier.github.io/categories/Tools/"},{"name":"Develop","slug":"Tools/Develop","permalink":"https://chivier.github.io/categories/Tools/Develop/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"https://chivier.github.io/tags/Tools/"},{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/tags/Develop/"}]},{"title":"2203-voronoi朴素开发笔记","slug":"2022/2203-voronoi朴素开发笔记","date":"2022-03-28T06:13:31.000Z","updated":"2022-03-28T06:13:32.894Z","comments":true,"path":"2022/03/28/2022/2203-voronoi朴素开发笔记/","link":"","permalink":"https://chivier.github.io/2022/03/28/2022/2203-voronoi%E6%9C%B4%E7%B4%A0%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/","excerpt":"Version 0.0","text":"Version 0.0 voronoi朴素2022-03-19 开发测试Intro:测试需要，给出 N 个点，（有一个边界），生成 Voronoi 划分 设计阶段 1class = 点集合 + 边界 Development Step 1初步算法为： 对与每一个点，提取所有中垂面，进行几何交集切割凸包 距离：半径和极限，下一个中垂面距离超过半径，那么无法切割 子数据结构：凸包（点集合描述？中垂面描述？） 点集合描述done https://github.com/Chivier/votropy","categories":[{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/categories/Develop/"},{"name":"Graphics","slug":"Develop/Graphics","permalink":"https://chivier.github.io/categories/Develop/Graphics/"}],"tags":[{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/tags/Develop/"},{"name":"Graphics","slug":"Graphics","permalink":"https://chivier.github.io/tags/Graphics/"}]},{"title":"2203-并行体系结构笔记1","slug":"2022/2203-并行体系结构笔记1","date":"2022-03-28T06:10:53.000Z","updated":"2022-03-28T06:11:25.204Z","comments":true,"path":"2022/03/28/2022/2203-并行体系结构笔记1/","link":"","permalink":"https://chivier.github.io/2022/03/28/2022/2203-%E5%B9%B6%E8%A1%8C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B01/","excerpt":"A parallel computer is a collection of processing elements that can communicate and cooperate to solve a large problem fast.","text":"A parallel computer is a collection of processing elements that can communicate and cooperate to solve a large problem fast. 当代主流的并行机系统并行机器结构纵览SIMD 阵列处理机SIMD并行机的一种。多台处理器（即处理单元 PE）排成阵列的拓扑结构,利用资源重复的方法开拓并行性。此类机器的程序是单控制线程,按照顺序或并行步执行之。单一的指令运行在大型规则的数据结构（如数组和矩阵等）上，使阵列处理机也常叫做数据并行结构（Data Parallel Architecture）。 向量处理机在向量机中，标量处理器被集成为一组功能单元,它们以流水线方式执行存储器中的向量数据。能够操作于存储器中任何地方的向量就没有必要将应用数据结构映射到不变的互连结构上,从而大大地简化了数据对准的问题。 共享存储多处理机按照 Flynn 分类法，共享存储的多处理机系统，是属于 MIMD 系统。分为紧耦合和松耦合两种。前者共享主存通信；后者借助总线适配器处理数据，各个处理器地位平等。 分布存储多计算机分布存储的多计算机是属于消息传递型并行计算机，其中，每个处理器都是一个独立性较强的节点,系由处理器、本地存储器、I/O设备和消息传递通信接口所组成。由于每个计算节点的本地存储器容量较大,所以运算时所需的绝大部分的指令和数据均可取自本地存储器。当不同计算节点上的进程需要通信时,就可通过接口进行消息交换。由于节点之间耦合程度较低,所以此系统也常称为松散耦合的多机系统。 共享分布存储的多处理机共享存储的多处理机由于受互连网络带宽的限制而扩展性较差,但由于是单一共亨地址空间，所以较易于编程；而分布存储的多计算机，由于是松散性耦合，所以易于扩展,但多地址空间却使编程较困难。共享分布存储的多处理机是将物理上分布的存储系统,通过硬件和软件的办法,向用户提供一个单一的全局地址空间。这样，共享分布存储多处埋机系统既具有分布存储多机系统易于扩展的特性，又具有共享存储多处理机系统易于编程的优点。 当代流行结构 单指令流多数据流SIMD计算机； 并行向量处理机 PVP； 对称多处理机 SMP； 大规模并行处理机 MPP； 工作站机群 COW； 分布式共享存储DSM 多处理机； 并行计算机的主要访存模型均匀存储访问模型UMA（Uniform Memory Access）模型是均匀存储访问模型的简称。 其特点是： 物理存储器被所有处理器均匀共享； 所有处理器访问任何存储字取相同的时间(此即均匀存储访问名称的由来); 每台处理器可带私有高速缓存； 外围设备也可以一定形式共享。 这种系统由于高度共享资源，而称为紧耦合系统（Tightly Coupled System）。 当所有的处理器都能等同地访问所有I/O设备,能同样地运行执行程序(如操作系统内核和I/O服务程序等)时,称为对称多处理机SMP；如果只有一台或一组处理器(称为主处理器），它能执行操作系统并能操纵 I/O，而其余的处理器无 I/O 能力(称为从处理器)，只在主处理器的监控之下执行用户代码，这时称为非对称多处理机。一般而言，UMA结构适于通用或分时应用。 非均匀存储访问模型NUMA(Nonuniform Memory Access)模型是非均匀存储访问模型的简称。 NUMA的特点是： 被共享的存储器在物理上是分布在所有的处理器中的，其所有本地存储器的集合就组成了全局地址空间； 处理器访问存储器的时间是不一样的；访问本地存储器 LM 或群内共享存储器CSM 较快，而访问外地的存储器或全局共享存储器GSM ( Global Sbared Memory)较慢(此即非均匀存储访问名称的由来)； 每台处理器照例可带私有高速缓存,且外设也可以某种形式共享。 全高速缓存存储访问模型COMA(Cache－Only Memory Access)模型是全高速缓存存储访问的简称。它是NUMA的一种特例。 其特点是： 各处理器节点中没有存储层次结构，全部高速缓存组成了全局地址空间; 利用分布的高速缓存目录D进行远程高速缓存的访问； COMA中的高速缓存容量一般都大于二级高速缓存容量； 使用COMA时，数据开始时可任意分配,因为在运行时它最终会被迁移到要用到它们的地方。 高速缓存一致性非均匀存储访问模型它实际上是将一些 SMP 机器作为一个单节点而彼此连接起来所形成的一个较大的系统。其特点是： 绝大多数商用 CC－NUMA 多处理机系统都使用基于目录的高速缓存一致性协议； 它在保留 SMP 结构易于编程的优点的同时,也改善了常规SMP的可扩放性问题； CC－NUMA实际上是一个分布共享存储的DSM多处理机系统； 它最显著的优点是程序员无需明确地在节点上分配数据，系统的硬件和软件开始时自动在各节点分配数据,在运行期间,高速缓存一致性硬件会自动地将数据迁移至要用到它的地方。 总之,CC－NUMA所发明的一些技术在开拓数据局部性和增强系统的可扩性方面很有效。不少商业应用,大多数数据访问都可限制在本地节点内,网络上的主要通信不是传输数据,而是为高速级存的无效性(Invalidation)所用。 非远程存储访问模型NORMA（No－Remote Memory Access）模型是非远程存储访问模型的简称。在一个分布存储的多处理机系统中,如果所有的存储器都是私有的,仅能由其自己的处理器所访问时,就称为NORMA。系统由多个计算节点通过消息传递互连网络连接而成,每个节点都是一台由处理器、本地存储器和(或)I/O外设组成的自治计算机。NORMA的特点是 所有存储器是私有的； 绝大数 NUMA 都不支持远程存储器的访问； 在 DSM 中，NORMA 就消失了。 CPI MPIS CPU_TIME 例子使用4GHZ主频的标量处理器执行一个典型测试程序，其所执行的指令数及所需的周期数如下表所示。试计算执行该程序的有效CPI、MIPS速率及总的CPU执行时间** 指令类型 指令数 时钟周期数 整数算术 45，000 1 数据传送 32，000 2 浮 点 15，000 2 控制转移 8，000 2 CPI= cycles per instruction = $\\dfrac{45000 * 1 + 32000 * 2 + 15000 * 2 + 8000 * 2}{45000 + 32000 + 15000 + 8000}$ =$\\dfrac{155000}{100000}$ = 1.55 MIPS= million instructions per second = $\\dfrac{4 * 10^9}{1.55 * 10^6}$ = 2580.6 CPU Time= $\\dfrac{155000}{4 * 10^9}$ = 0.00003875 s 为什么增加问题规模可以在一定程度提高加速比?Gustafson定律的基本出发点是： 对于很多大型计算,精度要求很高，即在此类应用中精度是个关键因素，而计算时间是固定不变的。此时为了提高精度,必须加大计算量,相应地亦必须增多处理器数,才能维持时间不变； 除非学术研究,在实际应用中,没有必要固定工作负载,而计算程序运行在不同数目的处理器上,增多处理器必须相应地增大问题规模,才有实际意义。 $$S^{\\prime}=\\frac{W_{\\mathrm{s}}+P W_{\\mathrm{p}}}{W_{\\mathrm{s}}+P \\cdot W_{\\mathrm{p}} / P}=\\frac{W_{\\mathrm{s}}+P W_{P}}{W_{\\mathrm{s}}+W_{\\mathrm{p}}}$$归一化后可得$$S^{\\prime}=f+P\\left(1-f^{\\prime}\\right)=P+f(1-P)=P-f(P-1)$$当 $P$ 充分大时, $S^{\\prime}$ 与 $P$ 儿乎成线性关系, 其斜率为 $1-f$。它意昩着随着处理器数目的增多, 加速几羊与处理器数成比例地线性增加, 串行比例 $f$ 不再是程序的瓶颈。 References","categories":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/categories/Architechture/"},{"name":"Parallel","slug":"Architechture/Parallel","permalink":"https://chivier.github.io/categories/Architechture/Parallel/"}],"tags":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/tags/Architechture/"},{"name":"Parallel","slug":"Parallel","permalink":"https://chivier.github.io/tags/Parallel/"}]},{"title":"2203-浮点数问题","slug":"2022/2203-浮点数问题","date":"2022-03-23T02:24:57.000Z","updated":"2022-03-23T02:26:13.063Z","comments":true,"path":"2022/03/23/2022/2203-浮点数问题/","link":"","permalink":"https://chivier.github.io/2022/03/23/2022/2203-%E6%B5%AE%E7%82%B9%E6%95%B0%E9%97%AE%E9%A2%98/","excerpt":"最近重读计算机体系结构，对于浮点数进行一些整理和复习。","text":"最近重读计算机体系结构，对于浮点数进行一些整理和复习。 IEEE 754 The IEEE Standard for Floating-Point Arithmetic (IEEE 754) is a technical standard for floating-point arithmetic established in 1985 by the Institute of Electrical and Electronics Engineers (IEEE). The standard addressed many problems found in the diverse floating-point implementations that made them difficult to use reliably and portably. Many hardware floating-point units use the IEEE 754 standard.– From Wikipedia IEEE754 http://evanw.github.io/float-toy/ IEEE 754 是一类标准，主要包含： arithmetic formats: sets of binary and decimal floating-point data, which consist of finite numbers (including signed zeros and subnormal numbers), infinities, and special “not a number” values (NaNs) interchange formats: encodings (bit strings) that may be used to exchange floating-point data in an efficient and compact form rounding rules: properties to be satisfied when rounding numbers during arithmetic and conversions operations: arithmetic and other operations (such as trigonometric functions) on arithmetic formats exception handling: indications of exceptional conditions (such as division by zero, overflow, etc.) 一般的浮点数表示形式如： 采用 :Sign(Blue) + Biased Exponet(Green) + Fraction(Red) 对于我们编程来说有如下需要注意的问题： Rounding RuleRound to nearest, ties to evenRound to nearest, ties away from zeroRound toward 0Round toward +∞Round toward −∞ (Since C++11) std::round, std::roundf std::roundl, std::lround std::lroundf, std::lroundl std::llround, std::llroundf NANNAN 有两种： QNAN SNAN 其中 QNAN 是可以利用计算构造的，SNAN 则是内置标注的 下面用几个例子说明如何使用： 常见的比较方式有：Most operations with at least one NaN operand. Indeterminate forms: The divisions (±0) / (±0) and (±∞) / (±∞). The multiplications (±0) × (±∞) and (±∞) × (±0). Remainder x % y when x is an infinity or y is zero. The additions (+∞) + (−∞), (−∞) + (+∞) and equivalent subtractions (+∞) − (+∞) and (−∞) − (−∞). The standard has alternative functions for powers: The standard pow function and the integer exponent pown function define 00, 1∞, and ∞0 as 1. The powr function defines all three indeterminate forms as invalid operations and so returns NaN. Real operations with complex results, for example: The square root of a negative number. The logarithm of a negative number. The inverse sine or inverse cosine of a number that is less than −1 or greater than 1. 如果需要 trace NAN 的时候，可以这样： Reference https://en.wikipedia.org/wiki/IEEE_754 https://stackoverflow.com/questions/8341395/what-is-a-subnormal-floating-point-number https://en.cppreference.com/w/cpp/numeric/math/round https://en.cppreference.com/w/cpp/types/numeric_limits/has_quiet_NaN https://en.cppreference.com/w/cpp/types/numeric_limits/has_signaling_NaN https://stackoverflow.com/questions/18118408/what-is-the-difference-between-quiet-nan-and-signaling-nan https://ieeexplore.ieee.org/document/8766229 https://docs.python.org/3/library/fractions.html https://www.boost.org/doc/libs/1_57_0/libs/rational/rational.html http://h5cpp.org/ https://docs.h5py.org/en/stable/mpi.html http://www.netlib.org/scalapack/ https://www.openblas.net/ https://github.com/jerryz123/riscv-OpenBLAS","categories":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/categories/Architechture/"},{"name":"Compiler","slug":"Architechture/Compiler","permalink":"https://chivier.github.io/categories/Architechture/Compiler/"},{"name":"FP","slug":"Architechture/Compiler/FP","permalink":"https://chivier.github.io/categories/Architechture/Compiler/FP/"}],"tags":[{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/tags/Compiler/"},{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/tags/Architechture/"},{"name":"FP","slug":"FP","permalink":"https://chivier.github.io/tags/FP/"}]},{"title":"2203-TFcustom","slug":"2022/2203-TFcustom","date":"2022-03-09T08:22:47.000Z","updated":"2022-03-09T08:24:17.141Z","comments":true,"path":"2022/03/09/2022/2203-TFcustom/","link":"","permalink":"https://chivier.github.io/2022/03/09/2022/2203-TFcustom/","excerpt":"实验记录：如何在 Tensorflow 中用 cuda 实现一个自定义的层的环境搭建（好吧我坦白我比较菜，环境就搞了好几天）","text":"实验记录：如何在 Tensorflow 中用 cuda 实现一个自定义的层的环境搭建（好吧我坦白我比较菜，环境就搞了好几天） Docker 配置首先我们最好在一个 docker 环境中进行测试，因为这个问题涉及到 cuda 版本、tf 版本和系统版本的多方调节，在 docker 中便于维护一个稳定独立的实验环境。 参考的安装文档是：https://github.com/NVIDIA/nvidia-docker 需要使用 Nivdia-Docker, 因为需要在 docker 中调用 GPU。 详细的安装方式参考了： https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker 参考 Installing on Ubuntu and Debian 小节。 完成了这一步之后我们开始参考 TF 的 custom-op 的具体实现方案。 Custom OPhttps://github.com/tensorflow/custom-op Tensorflow 的官方给予了一个模版，不过这个模版的下载花费了不少力气，因为 docker proxy 配置花了不少时间。这里采用实验的 docker 镜像是：custom-op-gpu-ubuntu16 此外，为了方便对 docker 内的代码进行修改，这里采用将本地的一个仓库目录直接挂载到 docker 里，例如我用如下的操作方式： 建立模板仓库 此处设置模板，之后 clone 到一个 $CUSTOMOP 目录下。 Docker 准备1sudo docker run -it -v $CUSTOMOP:/custom-op --rm --gpus all chivier-tensorop /bin/bash 之后文件被复制到了 /custom-op 目录下 但是这个时候官方的操作指令不能成功，在 GPU 版本的 custom-op 编译的时候会报关于 cuda_helper.h 找不到的错误，这个时候刷要借助一些特殊操作： 1234cd /usr/local/lib/python3.6/dist-packages/tensorflow/include/mkdir -p third_party/gpus/cudacd third_party/gpus/cudaln -s /usr/local/cuda/* . 之后 Makefile 才可以正常工作，在配置完成之后我发现可能 pytorch 可以更好的解决问题。这一部分的 docker 在此封存。","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://chivier.github.io/categories/Tensorflow/"},{"name":"Cuda","slug":"Tensorflow/Cuda","permalink":"https://chivier.github.io/categories/Tensorflow/Cuda/"},{"name":"Deeplearning","slug":"Tensorflow/Cuda/Deeplearning","permalink":"https://chivier.github.io/categories/Tensorflow/Cuda/Deeplearning/"}],"tags":[{"name":"Cuda","slug":"Cuda","permalink":"https://chivier.github.io/tags/Cuda/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://chivier.github.io/tags/Tensorflow/"},{"name":"Deeplearning","slug":"Deeplearning","permalink":"https://chivier.github.io/tags/Deeplearning/"}]},{"title":"2202-CudaProgramming","slug":"2022/2202-CudaProgramming","date":"2022-02-19T22:28:54.000Z","updated":"2022-02-20T06:55:45.791Z","comments":true,"path":"2022/02/20/2022/2202-CudaProgramming/","link":"","permalink":"https://chivier.github.io/2022/02/20/2022/2202-CudaProgramming/","excerpt":"1 Requirements","text":"1 Requirements 在开始教程之前，简单说明一下下面步骤的需求和测试方法： Git: 之后的范例使用 git 作为拉取 Cuda 11+：使用 11 以上的 cuda 版本确保之后的步骤可以正常使用 CMake：项目构建采用 cmake 确保多平台可以进行测试和实验 官方文档的学习曲线比较陡峭，下面整理一些例子帮助快速上手。参考官方手册：Cuda Programming Guide，见附件。此后简称它“手册”。 2 设备和主机首先在这里，我个人想赞美一下 Nvidia 作为国际一流大厂的开源精神和优秀兼容性。现在的 Cuda 支持跨平台、语法兼容。这里语法兼容是指：cuda 是包含 C++17 语法的。直接写的 C++ 代码是可以在机器上直接运行的。 官方也有一个例子，说明 cuda 和 g++的编译内容可以混合使用：这一设计大大节约了程序移植的时间。 在开始编程之前，需要分离我们的传统思维，程序可以不只在 CPU 上运行，还可以在 GPU 上面运行。因此，这里诞生两个概念：Host &amp; Device。实际上，对于大部分的异构计算框架，例如：OpenCL、UPC 等等，都是可以指定 Host &amp; Device 的。这里的 Host 一般代指我们的 CPU, 而 Device 代指我们的 GPU。下面是一个例子： 12345678910111213141516171819 __device__ void gpu_hello() &#123; printf(&quot;gpu hello!\\n&quot;); &#125; __host__ void cpu_hello() &#123; printf(&quot;cpu hello!\\n&quot;); &#125; __global__ void kernel() &#123; gpu_hello(); &#125; int main() &#123; kernel&lt;&lt;&lt;1, 2&gt;&gt;&gt;(); cudaDeviceSynchronize(); cpu_hello(); return 0; &#125; 其中我们可以看到三类不同的函数修饰：_device_，__host__，和 __global\\ 在手册 4.2.1 函数类型限定词一节中进行了详细介绍。 2.1 设备定义 _device_ 是在设备上跑的，只可以从设备上调用 _host_ 是在 CPU 上跑的，只可以从主机上调用 _global_ 是在设备商跑的，只可以从主机上调用 如果一个函数不加修饰，默认他是 _device_ 函数，正如上面的 main 一样。 如果一个函数需要同时在 CPU 和 GPU 上都能执行，那么可以同时加上 host 和 device 两个关键字。需要判断具体在那个设备上，可以使用： 12// cuda// cpu 2.2 函数调用如果是 device 或者 host 函数，我们可以在恰当的位置直接调用。如果是 global 调用的时候，我们需要用&lt;&lt;&lt;arg1, arg2&gt;&gt;&gt;，去声明我们申请的资源。这个我们在[下一节](#\\ 3\\ Block\\ 和\\ Thread) 会说明。 2.3 函数限制由于计算的行为限制，一些特殊的程序行为在 cuda 代码中是被严格禁止的，例如： _host_ 和 _global_ 不支持递归 _global_ 返回值要求是 void 调用 GPU 的函数声明和定义不要分离，写在同一个文件里 更多限制见手册，不过上述两条基本包含了日常开发的需要。 12这里额外补充一点，是因为特殊的需要说明一下。关于上述的第三点，我们尽管可以使用特殊的方法，例如CUDA_SEPARABLE_COMPILATION等方法可以分离定义，但是会有无法内联等问题对性能产生巨大影响。处于这些原因，我个人建议__global__和__device__ **&lt;u&gt;声明和调用他们的地方&lt;&#x2F;u&gt;** 最好写到同一个文件里。 2.4 Cuda Version &amp; GPU Versionhttps://en.wikipedia.org/wiki/CUDA 这个部分一般来说不太需要关心，但是上面给出一个链接用来说明各个版本的 GPU 的 compute capacity 的问题，每张 GPU 都有一个属于自己的版本号，版本号是向下兼容的，即高版本号的卡可以跑任何版本号低于自己卡上编译出来的程序。用尽可能高版本的卡的特性去编译程序有利于充分发挥程序的性能。 在 CMakeLists.txt 中设置： 1set (CMAKE_CUDA_ARCHITECTURES 61) 其中 61 是 1080 的版本号，在表格中有写出，也可以使用程序输出： 12345678910111213141516 __device__ void gpu_hello() &#123; #ifdef __CUDA_ARCH__ printf(&quot;%d\\n&quot;, __CUDA_ARCH__); #endif &#125; __global__ void kernel() &#123; gpu_hello(); &#125; int main() &#123; kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(); cudaDeviceSynchronize(); return 0; &#125; 用来检测当前的版本是否正确，因为如果在 CMakeLists.txt 中不指明，那么机器会默认使用最低版本的驱动，也就是 520 版本的进行编译和后续优化。这显然不是我们希望的。 这里有一个我之前收藏的小文，介绍了更多的硬件细节： https://zhuanlan.zhihu.com/p/394352476 2.5 关于设备上的输出问题如果我们在 device 或者 global 的代码里调用了 printf 等输出函数，这个时候需要使用前面已经多次使用过的 cudaDeviceSynchronize() 才能生效。因为处于高性能的需求，我们的 CPU 代码执行和 GPU 代码执行是异步执行的。所以我们调用 GPU 代码之后，CPU 程序实际上是会继续执行的。如果要等上面的 GPU 代码执行完成，需要在此处同步等待一下。（可以尝试把之前程序的 cudaDeviceSynchronize() 删除进行一个小小的测试）此外 cout 等流输出在 cuda 中是禁止的，因为流输出里包含了过多的函数行为和复杂特性，Nvidia 的工程师暂时还没有实现这些特性。 3 Block 和 Thread上面一节我们提到，如果我们调用 global 声明的函数的时候需要说明计算资源。这里我们解释一下 &lt;&lt;&lt;arg1, arg2&gt;&gt;&gt; 中两个参数的含义。 3.1 从例子开始首先先从下面这个例子说明： 1234567891011 using namespace std; __global__ void kernel() &#123; printf(&quot;Block %d of %d, Thread %d of %d\\n&quot;, blockIdx.x, gridDim.x, threadIdx.x, blockDim.x); &#125; int main() &#123; kernel&lt;&lt;&lt;4, 3&gt;&gt;&gt;(); cudaDeviceSynchronize(); return 0; &#125; 输出结果： 123456789101112Block 0 of 4, Thread 0 of 3 Block 0 of 4, Thread 1 of 3 Block 0 of 4, Thread 2 of 3 Block 2 of 4, Thread 0 of 3 Block 2 of 4, Thread 1 of 3 Block 2 of 4, Thread 2 of 3 Block 1 of 4, Thread 0 of 3 Block 1 of 4, Thread 1 of 3 Block 1 of 4, Thread 2 of 3 Block 3 of 4, Thread 0 of 3 Block 3 of 4, Thread 1 of 3 Block 3 of 4, Thread 2 of 3 Cuda 有两个层级的并行，一个是 block 级别，一个是 thread 级别。&lt;&lt;&lt;arg1, arg2&gt;&gt;&gt; 中： Arg1 = block 数目 = gridDim.x Arg2 = 每个 block 中 thread 的数目 = blockDim.x（我曾经反对首字母小写的驼峰命名，后来被 Nvidia 教育了） 3.2 Block 和 Thread 的设计意义为什么需要进行这两级的设计呢？其实这个和 GPU 的硬件设计方式有关系。我们的代码直接和硬件设计相关。 首先从命名上不难看出，GPU 的设计是为了进行 2D 和 3D 的网格类型计算。对应的应用就是：图形图像处理、粒子引擎模拟、网格算法计算。我们在计算是经常需要 “切分大数据，进行分发计算，最后再进行收集”。也就是常说的 Scatter-and-Gather, 或者 Fork-and-Merge。 现在的 GPU 架构中： 一个 GPU = 多个 Streaming Multiprocessor (SM) + cache 组成 一个 SM = Streaming Processor（SP）+ cache 组成 SM 用于处理 block SP 用于处理 thread 很大一方面理由就是为了更加充分利用多级缓存的优势。 3.3 Flatten Mode 和 Dimension Mode由于 Block 和 Thread 的两级设计导致我们的划分可能存在一定的困难，有一个简单粗暴的方法可以直接把他们压平。直接把上面那个例子进行压平改写： 1234567891011 using namespace std; __global__ void kernel() &#123; printf(&quot;Thread %d of %d\\n&quot;, blockIdx.x * blockDim.x + threadIdx.x, blockDim.x * gridDim.x); &#125; int main() &#123; kernel&lt;&lt;&lt;4, 3&gt;&gt;&gt;(); cudaDeviceSynchronize(); return 0; &#125; 输出结果： 123456789101112Thread 0 of 12 Thread 1 of 12 Thread 2 of 12 Thread 6 of 12 Thread 7 of 12 Thread 8 of 12 Thread 3 of 12 Thread 4 of 12 Thread 5 of 12 Thread 9 of 12 Thread 10 of 12 Thread 11 of 12 由于 cuda 的适用范围，还有另外一种模式的其实在 HPC 应用中更加受到欢迎和广泛使用，一般称为 Dimension Mode。 首先展示一下结果： 1234567891011121314 __global__ void kernel() &#123; printf(&quot;Block (%d,%d,%d) of (%d,%d,%d), Thread (%d,%d,%d) of (%d,%d,%d)\\n&quot;, blockIdx.x, blockIdx.y, blockIdx.z, gridDim.x, gridDim.y, gridDim.z, threadIdx.x, threadIdx.y, threadIdx.z, blockDim.x, blockDim.y, blockDim.z); &#125; int main() &#123; kernel&lt;&lt;&lt;dim3(2, 1, 1), dim3(2, 2, 2)&gt;&gt;&gt;(); cudaDeviceSynchronize(); return 0; &#125; 首先看三维的例子： 12345678910111213141516Block (0,0,0) of (2,1,1), Thread (0,0,0) of (2,2,2) Block (0,0,0) of (2,1,1), Thread (1,0,0) of (2,2,2) Block (0,0,0) of (2,1,1), Thread (0,1,0) of (2,2,2) Block (0,0,0) of (2,1,1), Thread (1,1,0) of (2,2,2) Block (0,0,0) of (2,1,1), Thread (0,0,1) of (2,2,2) Block (0,0,0) of (2,1,1), Thread (1,0,1) of (2,2,2) Block (0,0,0) of (2,1,1), Thread (0,1,1) of (2,2,2) Block (0,0,0) of (2,1,1), Thread (1,1,1) of (2,2,2) Block (1,0,0) of (2,1,1), Thread (0,0,0) of (2,2,2) Block (1,0,0) of (2,1,1), Thread (1,0,0) of (2,2,2) Block (1,0,0) of (2,1,1), Thread (0,1,0) of (2,2,2) Block (1,0,0) of (2,1,1), Thread (1,1,0) of (2,2,2) Block (1,0,0) of (2,1,1), Thread (0,0,1) of (2,2,2) Block (1,0,0) of (2,1,1), Thread (1,0,1) of (2,2,2) Block (1,0,0) of (2,1,1), Thread (0,1,1) of (2,2,2) Block (1,0,0) of (2,1,1), Thread (1,1,1) of (2,2,2) 再来给出一个二维的例子： 1234567891011121314 __global__ void kernel() &#123; printf(&quot;Block (%d,%d,%d) of (%d,%d,%d), Thread (%d,%d,%d) of (%d,%d,%d)\\n&quot;, blockIdx.x, blockIdx.y, blockIdx.z, gridDim.x, gridDim.y, gridDim.z, threadIdx.x, threadIdx.y, threadIdx.z, blockDim.x, blockDim.y, blockDim.z); &#125; int main() &#123; kernel&lt;&lt;&lt;dim3(2, 3, 1), dim3(2, 1, 1)&gt;&gt;&gt;(); cudaDeviceSynchronize(); return 0; &#125; 结果最后一个维度都是 0, 我们使用结果的时候不使用 z 维度即可 123456789101112Block (1,2,0) of (2,3,1), Thread (0,0,0) of (2,1,1) Block (1,2,0) of (2,3,1), Thread (1,0,0) of (2,1,1) Block (0,2,0) of (2,3,1), Thread (0,0,0) of (2,1,1) Block (0,2,0) of (2,3,1), Thread (1,0,0) of (2,1,1) Block (0,1,0) of (2,3,1), Thread (0,0,0) of (2,1,1) Block (0,1,0) of (2,3,1), Thread (1,0,0) of (2,1,1) Block (1,0,0) of (2,3,1), Thread (0,0,0) of (2,1,1) Block (1,0,0) of (2,3,1), Thread (1,0,0) of (2,1,1) Block (0,0,0) of (2,3,1), Thread (0,0,0) of (2,1,1) Block (0,0,0) of (2,3,1), Thread (1,0,0) of (2,1,1) Block (1,1,0) of (2,3,1), Thread (0,0,0) of (2,1,1) Block (1,1,0) of (2,3,1), Thread (1,0,0) of (2,1,1) 3.4 如何设置计算资源？上面说了我们 GPU 并行的时候有两个层级，第一个是 Block 级别，第二个是 Thread 级别。为此我们需要设置两个级别的数目。 首先我们先看我们最多可以用多少资源。使用 cuda samples 中的 deviceQuery （Make 直接编译整个 cuda-samples 项目可以找到） 此程序会列举机器上的所有设备，列举设备之后可以展示出机器的所有详细信息。这里我们看到了关键的几行信息： Maximum number of threads per block以及Maximum dimension size of a thread block 前者比较好理解，我们看看后一个 dimension 的含义，首先先列举一下官方论坛的说辞： There are multiple limits. All must be satisfied. The maximum number of threads in the block is limited to 1024. This is the product of whatever your threadblock dimensions are (x_y_z). For example (32,32,1) creates a block of 1024 threads. (33,32,1) is not legal, since 33*32*1 &gt; 1024. The maximum x-dimension is 1024. (1024, 1, 1) is legal. (1025, 1, 1) is not legal. The maximum y-dimension is 1024. (1, 1024, 1) is legal. (1, 1025, 1) is not legal. The maximum z-dimension is 64. (1, 1, 64) is legal. (2, 2, 64) is also legal. (1, 1, 65) is not legal. 配合论坛中的内容，这里也很好理解了。 结合了上面的例子，cuda 的变成已经变得相对直观，用来优化一些简单的循环已经可以实现了。这里可以概括一下： cuda Block 级别相当于 C++ 线程，数目可以设置比较大，调度依靠 GPU ，方式类似于 CPU 调度 threads cuda Thread 级别相当于 SIMD，有数目上限，受限于 cuda core 的数目和一些维度参数 4 变量行为简单的例子说明完成，下面开始介绍每一个具体的函数内部，我们程序的行为。 4.1 显存和内存在使用 GPU 编程（也有可能在玩游戏）的时候，有一个词时常出现：显存。这个词已经暗示我们 GPU 的内存分布和 CPU 的内存分布实际上是不一样的。我们在设备上的内容、和主机上的内容直接需要一些同步机制去同步。 首先一图概览接下来的内容： 简述一下： 显存和内存独立管理各自的 DRAM 互相调用树枝需要使用 cudaMemcpy Unified 统一管理模式可以解决管理问题，但是代价是需要额外的时间开销 下面配合具体的例子说明。 4.2 显存内存不能互相调用4.2.1 设备调用内存失败我们复习一下在内存中如何申请空间，在 C/C++ 中，我们一般会使用一对函数： malloc &amp; free 用于一块内存的申请与释放。 下面给出一个例子： 1234567891011121314151617181920212223 __global__ void kernel(int *arr) &#123; arr[0] = 0; int index = 1; while (arr[index] != 0) &#123; arr[0] += arr[index]; index++; &#125; &#125; int main() &#123; int *a; a = (int *)malloc(sizeof(int) * 12); int index = 1; for (index = 1; index &lt;= 10; ++index) &#123; a[index] = index; &#125; kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(a); printf(&quot;%d&quot;, a[0]); cudaDeviceSynchronize(); free(a); return 0; &#125; 4.2.2 主机调用显存失败这里首先说明一下 cuda 是如何展示显存的。在介绍之前，先需要介绍一下两个函数接口：cudaMalloc &amp; cudaFree 这里需要说明的是 cudaMalloc 的用法和 malloc 差异极大： 1cudaError_t cudaMalloc (void** ptr, size_t size); 配合下图理解： 我们申请的是一个 “指向 GPU 数据指针的指针”。 我们申请到的空间是在一个二级指针上存储，下面举一个例子： 1234567891011121314151617181920212223 __global__ void kernel(int *arr) &#123; arr[0] = 0; int index = 1; while (arr[index] != 0) &#123; arr[0] += arr[index]; index++; &#125; &#125; int main() &#123; int *a; cudaMalloc(&amp;a, sizeof(int) * 12); int index = 1; for (index = 1; index &lt;= 10; ++index) &#123; a[index] = index; &#125; kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(a); printf(&quot;%d&quot;, a[0]); cudaDeviceSynchronize(); cudaFree(a); return 0; &#125; 4.2.3 cuda Error Handling上面两个失败的例子再次说明了内存和显存不能“直接”混合使用。（下面会说一种支持混合使用的技术）前者结果是 0, 后者结果是段错误。导致的原因是因为内存地址和显存地址不是直接统一的。 为了方便调试，cuda 提供了一系列的纠错调试机制，在前面的程序中，用到的：cudaMalloc，cudaFree，cudaDeviceSynchronize 都有返回类型便于我们调试，返回类型是一个 cudaError_t 的没枚举类型，可以被 printf 直接输出。 但是输出了我们是不能理解函数的具体含义的，也不方便我们进行 debug。这里 cuda samples 里面提供了一个非常好的例子，我们可以直接引用 helper_cuda.h 头文件解决问题。 12345678910cmake_minimum_required(VERSION 3.10) set(CMAKE_CXX_STANDARD 17) set(CMAKE_BUILD_TYPE Release) set(CMAKE_CUDA_ARCHITECTURES 61) project(devices LANGUAGES CXX CUDA) add_executable(hello hello.cu) target_include_directories(hello PUBLIC /usr/local/cuda/samples/common/inc) 1234567891011121314151617181920212223 __global__ void kernel(int *arr) &#123; arr[0] = 0; int index = 1; while (arr[index] != 0) &#123; arr[0] += arr[index]; index++; &#125; &#125; int main() &#123; int *a; a = (int *)malloc(sizeof(int) * 12); int index = 1; for (index = 1; index &lt;= 10; ++index) &#123; a[index] = index; &#125; kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(a); checkCudaErrors(cudaDeviceSynchronize()); printf(&quot;%d\\n&quot;, a[0]); free(a); return 0; &#125; 这样就完成了我们的 debug 工作，此时输出结果为： 120CUDA error at /home/chivier/Projects/cudatest/08-errhandle/hello.cu:23 code=700(cudaErrorIllegalAddress) &quot;cudaDeviceSynchronize()&quot; 这里的 IllegalAddress 就说明了地址无法正常使用。 4.2.5 cudaMemcpy那么正确的做法是什么呢？我们如果需要通信两个地方的内存，需要借助 cudaMemcpy 函数。 下面是正确的改正方法： 123456789101112131415161718192021222324252627282930 __global__ void kernel(int *arr) &#123; arr[0] = 0; int index = 1; while (arr[index] != 0) &#123; arr[0] += arr[index]; index++; &#125; &#125; int main() &#123; int *a; a = (int *)malloc(sizeof(int) * 12); int index = 1; for (index = 1; index &lt;= 10; ++index) &#123; a[index] = index; &#125; int *cuda_a; cudaMalloc(&amp;cuda_a, sizeof(int) * 12); cudaMemcpy(cuda_a, a, sizeof(int) * 12, cudaMemcpyHostToDevice); kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(cuda_a); cudaMemcpy(a, cuda_a, sizeof(int) * 12, cudaMemcpyDeviceToHost); checkCudaErrors(cudaDeviceSynchronize()); printf(&quot;%d\\n&quot;, a[0]); free(a); cudaFree(cuda_a); return 0; &#125; 结果是： 155 这个时候我们可以总结一般的 cuda 变成行为方法： Generate Data/Read Data Copy: Host-&gt;Device Calculate Copy: Device-&gt;Host Print out 12这里说明一下：cudaMemcpy可以自动实现同步工作，可以省去cudaDeviceSynchronize。 4.2.4 Unified Memory首先先给出官方的一份博客：Unified Memory 我们把上面的例子直接改写： 12345678910111213141516171819202122232425 __global__ void kernel(int *arr) &#123; arr[0] = 0; int index = 1; while (arr[index] != 0) &#123; arr[0] += arr[index]; index++; &#125; &#125; int main() &#123; int *a; checkCudaErrors(cudaMallocManaged(&amp;a, sizeof(int) * 12)); int index = 1; for (index = 1; index &lt;= 10; ++index) &#123; a[index] = index; &#125; kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(a); checkCudaErrors(cudaDeviceSynchronize()); printf(&quot;%d\\n&quot;, a[0]); cudaFree(a); return 0; &#125; Unified Memory 申请的空间在 Host 和 Device 上都直接可以正常使用。节省代码，但是代价也是随之而来的，我们需要使用一定的性能作为代价。这个有时是劣势，但有些时候这种方法反而可以达到优化的效果。 4.3 变量传输和计算这里我们简单介绍一下一般的循环模式。 4.3.1 grid-stride loop在 cuda 中，并行的模式有一点特殊，我们称为 grid-stride loop。 简单解释一下： 如果我们希望对一个循环进行并行，直观的想法就是分配足够多的线程执行他。如果循环次数少于 1024, 我们完全可以使用一个 block, 里面分配 循环次数对应的线程数 从而达到目的。但是这里不是我们希望看到的结果，因为我们不能保证我们的循环次数一定小于 1024。我们用下面的例子说明我们是如何用 cuda 执行循环的： 12345678910111213141516171819202122 __global__ void kernel(int *arr, int n) &#123; for (int i = threadIdx.x; i &lt; n; i += blockDim.x) &#123; arr[i] = i; &#125; &#125; int main() &#123; int n = 114; int *arr; checkCudaErrors(cudaMallocManaged(&amp;arr, n * sizeof(int))); kernel&lt;&lt;&lt;1, 4&gt;&gt;&gt;(arr, n); checkCudaErrors(cudaDeviceSynchronize()); for (int i = 0; i &lt; n; i++) &#123; printf(&quot;arr[%d]: %d\\n&quot;, i, arr[i]); &#125; cudaFree(arr); return 0; &#125; 由于 cuda 的大显存设计，我们大可以将一个数组很大一块连续块装入，而且 cuda 的计算机制保证了 blockDim 不会太大（1024）。所以这里尽管是跳步加，也不会过多的伤害到空间局部性。在不同的设备上，我们可以通过直接调整 blockDim 进行性能的测试，从而调优。Debug 的时候也可以直接把 gridDim 改成 1 从而进行便捷的调试。此外，这种写法的逻辑非常好整理，也方便进行记忆。为此这种方法被人们广泛使用。 如果我们需要启用多个 Block, 那么我们面临一个新的问题，如果循环次数不是 blockDim 的整数倍我们如何处理？这里的办法是非常国际通用的，大家广泛的使用如下写法： 12345678910int loopCount = .....;....int block_dim = ...;int grid_dim = (loopCount - 1) / block_dim + 1;...call_kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(); 好文推荐（示意图很好）： http://alexminnaar.com/2019/08/02/grid-stride-loops.html 官方博客中还推荐了另外一种非常灵活的写法：https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/ 12345__global__ void saxpy(int n, float a, float *x, float *y) &#123; for (int i = blockIdx.x * blockDim.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; y[i] = a * x[i] + y[i]; &#125;&#125; 相当与我们的 Flatten Mode 的编程方法，确保我们不会落下数据没有循环。 虽说大部分 C++17 的代码 cuda 可以跑起来，但是 STL 容器 cuda 并没有很好的适配和实现，如果需要用容器，我们需要自己定义 allocator。这里推荐一个 gist： https://gist.github.com/CommitThis/1666517de32893e5dc4c441269f1029a 其中定义了： 12345678910111213141516171819202122232425262728293031template &lt;typename T&gt;class unified_alloc&#123;public: using value_type = T; using pointer = value_type*; using size_type = std::size_t; unified_alloc() noexcept = default; template &lt;typename U&gt; unified_alloc(unified_alloc&lt;U&gt; const&amp;) noexcept &#123;&#125; auto allocate(size_type n, const void* = 0) -&gt; value_type* &#123; value_type * tmp; auto error = cudaMallocManaged((void**)&amp;tmp, n * sizeof(T)); if (error != cudaSuccess) &#123; throw std::runtime_error &#123; cudaGetErrorString(error) &#125;; &#125; return tmp; &#125; auto deallocate(pointer p, size_type n) -&gt; void &#123; if (p) &#123; auto error = cudaFree(p); if (error != cudaSuccess) &#123; throw std::runtime_error &#123; cudaGetErrorString(error) &#125;; &#125; &#125; &#125;&#125;; 如果此时我们需要定义 vector, 只需要： 1std::vector&lt;int, unified_alloc&lt;int&gt;&gt; arr(length); 即可。 1这里vector即使定义成功了，我们使用的时候还是会有一些问题，因为__global__函数的参数限制问题，我们只能传递 arr.data() 从而获取类似数组地址的方法传递参数。综上所属，楞写 STL 不是一个好办法，下面的 thrust 中会介绍一些靠谱的办法。 4.3.2 算子传输在 cuda 编程的时候，经常遇到下面这个问题： 对于很多类似的函数，我们只需要更换其中的一个小函数即可，例如计算 $$\\sum_{i=0}^n Sin(a_i),;\\sum_{i=0}^n Cos(a_i),;\\sum_{i=0}^n Tan(a_i),;…$$ 很多时候只需要换一个算子，我们不需要重复构造很多个函数（减少函数数量其实是有一定好处的，对于模式类似的函数，如果适当利用 lambda 算子，我们可以减少编译器的编译负担） 这种时候我们可以采用两种方法。 第一种就是 lambda 算子： 123456789101112131415161718192021222324252627282930313233343536 template &lt;class Func&gt; __global__ void kernel(int n, Func func) &#123; for (int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func(i); &#125; &#125; int main() &#123; int n = 10; int *arr; cudaMallocManaged(&amp;arr, n * sizeof(int)); int block_dim = 128; int grid_dim = (n - 1) / block_dim + 1; kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (int i) &#123; arr[i] = i; &#125;); checkCudaErrors(cudaDeviceSynchronize()); kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (int i) &#123; printf(&quot;%d, %f\\n&quot;, i, sinf(arr[i])); &#125;); checkCudaErrors(cudaDeviceSynchronize()); // Compare // for(int index = 0; index &lt; n; ++index) &#123; // printf(&quot;%d, %f\\n&quot;, index, sinf(index)); //&#125; cudaFree(arr); return 0; &#125; 注意 lambda 算子也是要在 GPU 上执行的，所以需要加上 _device_ 进行修饰。 第二种方法就是使用类似于函数指针的方式。不过 cuda 中函数指针的定义非常严格： 1234567891011121314151617181920212223242526272829303132333435363738394041424344 template &lt;class Func&gt; __global__ void kernel(int *arr, int n, Func func) &#123; for (int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func(arr, i); &#125; &#125; struct funcop1 &#123; __device__ void operator()(int *arr, int i) &#123; arr[i] = i; &#125; &#125;; struct funcop2 &#123; __device__ void operator()(int *arr, int i) &#123; printf(&quot;%d %f\\n&quot;, arr[i], sinf(arr[i])); &#125; &#125;; int main() &#123; int n = 10; int *arr; cudaMallocManaged(&amp;arr, n * sizeof(int)); int block_dim = 128; int grid_dim = (n - 1) / block_dim + 1; kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(arr, n, funcop1&#123;&#125;); checkCudaErrors(cudaDeviceSynchronize()); kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(arr, n, funcop2&#123;&#125;); checkCudaErrors(cudaDeviceSynchronize()); // Compare // for(int index = 0; index &lt; n; ++index) &#123; // printf(&quot;%d, %f\\n&quot;, index, sinf(index)); //&#125; cudaFree(arr); return 0; &#125; 需要注意的是： 由于地址类型在传递时，CPU 和 GPU 不一致，所以需要用结构体封装一层 结构体中的函数是在 GPU 上计算，需要用 device 修饰 结构体中函数需要用 operator () 修饰 到这里，基础部分已经基本结束。 4.4 高级计算行为4.4.1 thrust之前我们提及过，在 cuda 中无法使用 C++ STL 进行编程，为此我们需要使用 Nviida 提供的黑科技： thrust。 首先简单介绍一下，thrust 库被称为： Template library for CUDA，自从 cuda 4.0 就开始有了（甚至比 unified Memory 还早是我没想到的）。主要目的是对标 C++ STL。简化 HPC 编程。 4.4.1.1 vector 对标C++ STL 中 vector 容器属实是一个使用主力了，在 thrust 中我们也有对应的实现，分别为：universal_vector，host_vector，device_vector。他们的用途根据名字应该已经可以猜到了。使用 thrust 之后，我们可以直接使用 = 进行数值拷贝。Cuda 中已经完成了这一部分的重载工作。 下面列举一个例子： 123456789101112131415161718192021222324252627282930313233343536373839 template &lt;class Func&gt; __global__ void kernel(int n, Func func) &#123; for (int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func(i); &#125; &#125; int main() &#123; int n = 65536; int block_dim = 128; int grid_dim = (n - 1) / block_dim; thrust::host_vector&lt;float&gt; x_host(n); thrust::host_vector&lt;float&gt; y_host(n); thrust::generate(x_host.begin(), x_host.end(), []&#123;return std::rand() / 3.0;&#125;); thrust::generate(y_host.begin(), y_host.end(), []&#123;return std::rand() / 11.0;&#125;); printf(&quot;%f + %f = \\n&quot;, x_host[0], y_host[0]); thrust::device_vector&lt;float&gt; x_dev(n); thrust::device_vector&lt;float&gt; y_dev(n); x_dev = x_host; y_dev = y_host; kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [x = x_dev.data(), y = y_dev.data()] __device__ (int index)&#123; x[index] = x[index] + y[index]; &#125;); checkCudaErrors(cudaDeviceSynchronize()); x_host = x_dev; printf(&quot;%f\\n&quot;, x_host[0]); return 0; &#125; 输出结果： 12601429824.000000 + 151421216.000000 = 752851072.000000 本程序成功的展示了 thrust_vector 之间互相 copy 的行为，这里辅助使用了一下 thrust :: generate 用于生成随机序列。（这就是前一节花篇幅辅助介绍算子传递的原因，lambda 算子在 thrust 中会有广泛的应用，尽管这是 C++20 才应该有的特性，但是很多编译器早早的提供了支持「赞美 LLVM」。） 4.4.1.2 other thrustsThrust 中还有很多和 STL 对标的内容，例如 For_each、sort、count_if 这些都是非常常用的 thrust 函数，使用方法和 generate 几乎一致，没有过多差别。 https://thrust.github.io/doc/namespacethrust.html 这里个人推荐在上面的网页中查找 thrust 的 API。Doxygen 提供了详细的文档管理。我们可以查到具体的使用方法和相对应的例子。 4.4.2 atomic说道这个问题，很容易会和生产-消费的问题联系到一起。这里先列举一个翻车的例子： (下面这个例子中顺便引入了一个 trick, 在 cuda 中我们是可以使用全局变量的，但是和我们管理内存的方式是一样的，一个全局变量也是有“位置”的，我们在 GPU 和 CPU 上的全局变量需要使用 cudaMemcpyFromSymbol 进行拷贝) 1234567891011121314151617181920212223242526272829303132333435363738394041424344__device__ float sum = 0;template &lt;class Func&gt;__global__ void kernel(int n, Func func) &#123; for (int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func(i); &#125;&#125;int main() &#123; int n = 65536; int *arr; float result = 0; cudaMallocManaged(&amp;arr, n * sizeof(int)); int block_dim = 128; int grid_dim = (n - 1) / block_dim; kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (int i) &#123; arr[i] = i; &#125;); kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (int i) &#123; sum += sinf(arr[i]); &#125;); cudaMemcpyFromSymbol(&amp;result, sum, sizeof(float), 0, cudaMemcpyDeviceToHost); checkCudaErrors(cudaDeviceSynchronize()); printf(&quot;%f\\n&quot;, result); // Compare result = 0; for(int index = 0; index &lt; n; ++index) &#123; result += sinf(index); &#125; printf(&quot;%f&quot;, result); cudaFree(arr); return 0;&#125; 上面的例子非常好理解，是我们之前一个 lambda 例子的微微改进，我们之所以说明这个例子是因为这个程序行为非常“鬼畜”。每次执行结果都可能不同。那么问题在哪里呢？ 在于 1sum += sinf (arr[i]) 操作实际上不是原子的。我们的不同的 i 会抢占对于 sum 的使用。 修正方法也很简单： 1234567891011121314151617181920212223242526272829303132333435363738394041424344 __device__ float sum = 0; template &lt;class Func&gt; __global__ void kernel(int n, Func func) &#123; for (int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func(i); &#125; &#125; int main() &#123; int n = 65536; int *arr; float result = 0; cudaMallocManaged(&amp;arr, n * sizeof(int)); int block_dim = 128; int grid_dim = (n - 1) / block_dim; kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (int i) &#123; arr[i] = i; &#125;); kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (int i) &#123; atomicAdd(&amp;sum, sinf(arr[i])); &#125;); cudaMemcpyFromSymbol(&amp;result, sum, sizeof(float), 0, cudaMemcpyDeviceToHost); checkCudaErrors(cudaDeviceSynchronize()); printf(&quot;%f\\n&quot;, result); // Compare result = 0; for(int index = 0; index &lt; n; ++index) &#123; result += sinf(index); &#125; printf(&quot;%f\\n&quot;, result); cudaFree(arr); return 0; &#125; 即改为： 1atomicAdd(&amp;sum, sinf(arr[i])); 此时就只有一点点由于加法顺序不同导致的精度误差了。这一些误差是可以被接受的。 那么我们继续分析一下这个问题，在 cuda 内部我们是如何实现原子的。这个问题在“编译原理”课程中可能有过类似的解答。为了实现一个操作的原子性，我们需要“盯着他的数值”，只有我们“计算完成”“原始值也没变化”的时候，我们才能成功的优化。 换而言之，类似 atomicAdd, 我们又如下的步骤： Value_prev = Target Target += … Return Value_prev 如果此时 Value_prev 和现在的状态一致的，就可以进行更新。 Cuda 中还有这些原子函数： atomicAdd (dst, src)atomicSub(dst, src)atomicOr(dst, src)atomicAnd(dst, src)atomicXor(dst, src)atomicMax(dst, src)atomicMin(dst, src) 他们都有返回值，返回违背更改前的数值。 更加一般的，我们可以自己定义一个属于自己的原子操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 __device__ float sum = 0; __device__ float my_atom_add(float *dst, float src)&#123; int old = __float_as_int(*dst); int expect; do &#123; expect = old; old = atomicCAS((int *)dst, expect, __float_as_int(__int_as_float(expect) + sinf(src))); &#125; while(expect != old); return old; &#125; template &lt;class Func&gt; __global__ void kernel(int n, Func func) &#123; for (int i = blockDim.x * blockIdx.x + threadIdx.x; i &lt; n; i += blockDim.x * gridDim.x) &#123; func(i); &#125; &#125; int main() &#123; int n = 65536; int *arr; float result = 0; cudaMallocManaged(&amp;arr, n * sizeof(int)); int block_dim = 128; int grid_dim = (n - 1) / block_dim; kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (int i) &#123; arr[i] = i; &#125;); kernel&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;(n, [=] __device__ (int i) &#123; my_atom_add(&amp;sum, arr[i]); &#125;); cudaMemcpyFromSymbol(&amp;result, sum, sizeof(float), 0, cudaMemcpyDeviceToHost); checkCudaErrors(cudaDeviceSynchronize()); printf(&quot;%f\\n&quot;, result); // Compare result = 0; for(int index = 0; index &lt; n; ++index) &#123; result += sinf(index); &#125; printf(&quot;%f\\n&quot;, result); cudaFree(arr); return 0; &#125; 我们使用 atomoicCAS 按照类似的逻辑步骤： 记录维护原始值 试图 CAS 更改 成功改动之后可以停下 这里使用了一些技巧，结合下面的官网借口解释： https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomiccas AtomicCAS 是一个只支持整数的借口，如果需要浮点支持，需要进行 as float 进行转换。 12这里不难看出另一个问题，如果我们的原子操作被严格执行，那么原子操作会成为一个严重的瓶颈。相当于所有的数据都要过一遍着一个原子操作。但是实际上GPU跑起来还是非常快的，这是因为GPU根据blockDim和gridDim进行了操作，部分串行。以求和为例，我们会将数据分成几个大块，分别计算部分和，最后再进行规约。利用这种方法保证了此处不会成为瓶颈。因此也不难看出：原子操作都是可以 Fork-And-Merge 的操作。","categories":[{"name":"Cuda","slug":"Cuda","permalink":"https://chivier.github.io/categories/Cuda/"},{"name":"Parallel","slug":"Cuda/Parallel","permalink":"https://chivier.github.io/categories/Cuda/Parallel/"},{"name":"Develop","slug":"Cuda/Parallel/Develop","permalink":"https://chivier.github.io/categories/Cuda/Parallel/Develop/"}],"tags":[{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/tags/Develop/"},{"name":"Cuda","slug":"Cuda","permalink":"https://chivier.github.io/tags/Cuda/"},{"name":"Parallel","slug":"Parallel","permalink":"https://chivier.github.io/tags/Parallel/"}]},{"title":"2202-QemuTest","slug":"2022/2202-QemuTest","date":"2022-02-04T05:26:31.000Z","updated":"2022-02-04T08:18:02.463Z","comments":true,"path":"2022/02/04/2022/2202-QemuTest/","link":"","permalink":"https://chivier.github.io/2022/02/04/2022/2202-QemuTest/","excerpt":"由于重装系统之后，我的本地实验环境一直没有找时间去重新配置。在这里总结一下关于 riscv 测试环境的一些配置方法。","text":"由于重装系统之后，我的本地实验环境一直没有找时间去重新配置。在这里总结一下关于 riscv 测试环境的一些配置方法。 主要参考为： Running 64- and 32-bit RISC-V Linux on QEMU 在 QEMU 上运行 RISC-V 64 位版本的 Linux 本地配置环境本地系统环境如下： 内核有点更新过头，不过不碍事，可以继续正常使用。 12345sudo apt install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \\ gawk build-essential bison flex texinfo gperf libtool patchutils bc \\ zlib1g-dev libexpat-dev git \\ libglib2.0-dev libfdt-dev libpixman-1-dev \\ libncurses5-dev libncursesw5-dev 就完成了准备环境的安装。我们之后的工作单独建立一个目录： 1234cd ....[Anything you like]mkdir riscvcd riscvexport RISCV_EXP_HOME=$PWD Riscv-gnu-toolchains使用软件源一个偷懒的方法是使用软件源里已经编译完成的 riscv 软件工具链。使用 apt 可以看到如下的包可以选择进行安装： 编译安装（推荐）12cd $RISCV_EXP_HOMEgit clone https://gitee.com/mirrors/riscv-gnu-toolchain 直接下载 gitee 上的镜像，速度更快。 之后我们需要对一个模块进行切除： 12cd riscv-gnu-toolchaingit rm qemu Qemu 我们之后自己进行安装。 接着复制子模块内容： 1git submodule update --init --recursive 然后进行 autoconf 工具链的编译： 12./configure --prefix=/opt/riscv64sudo make linux -j 4 最后测试安装是否成功： 1riscv64-unknown-linux-gnu-gcc -v 其实如果是为了测试编译的话，我们到这一步已经完成了。如果需要检验我们是否有可靠的 riscv 环境下的可用二进制可执行文件，我们需要使用 Qemu 进行测试。 Qemu首先下载解压： 1234cd $RISCV_EXP_HOMEwget https://download.qemu.org/qemu-5.1.0.tar.xztar xf qemu-5.1.0.tar.xzcd qemu-5.1.0.tar.xz Autoconf 软件，老样子直接安装，注意需要指定一下这里是 riscv 的工作环境： 123./configure --target-list=riscv64-softmmu,riscv64-linux-user --prefix=/opt/qemumake -j 4sudo make install 编译内核再完成上面两个步骤之后，我们最重要的工具链已经基本完成了。可以把下面的这句写到环境变量里面： 1export PATH=$PATH:/opt/riscv64/bin:/opt/qemu/bin 下载内核，可以从镜像下载，这里选择一个特定的内核版本： 12git clone git@gitee.com:mirrors/linux_old1.gitgit checkout v5.4 内核编译就是沿用如下方法： 12make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- defconfigmake ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- -j 4 制作文件系统这里使用 busybox 制作，首先下载源码： 12git clone https://gitee.com/mirrors/busyboxsource.gitcd busyboxsource 1CROSS_COMPILE=riscv64-unknown-linux-gnu- make menuconfig 打开配置菜单后进入第一行的 “Settings”，在”Build Options”节中，选中 “Build static binary (no shared libs)”，设置好后退出保存配置。 之后再次配置和编译： 12CROSS_COMPILE=riscv64-unknown-linux-gnu- make -j 4CROSS_COMPILE=riscv64-unknown-linux-gnu- make install 完成之后我们回到实验目录： 1qemu-img create rootfs.img 4g 安排 4g 的实验空间。将它文件格式定为 ext4： 1mkfs.ext4 rootfs.img 之后把刚刚在 busybox 中生成的内容移动过来： 12345678cd $RISCV_EXP_HOMEmkdir rootfssudo mount -o loop rootfs.img rootfscd rootfssudo cp -r ../busyboxsource/_install/* .sudo mkdir proc sys dev etc etc/init.dcd etc/init.d/sudo touch rcS 在 RC 文件中写入一些基本信息： 123mount -t proc none /procmount -t sysfs none /sys/sbin/mdev -s 修改 RC 权限： 1sudo chmod +x rcS 安全期间，退文件环境。 1sudo umount rootfs 至此，我们已经完成了所有的操作。 使用 Qemu 启动1qemu-system-riscv64 -M virt -m 256M -nographic -kernel linux/arch/riscv/boot/Image -drive file=rootfs.img,format=raw,id=hd0 -device virtio-blk-device,drive=hd0 -append &quot;root=/dev/vda rw console=ttyS0&quot; 我们就可以启动了。我个人使用 alias 将上面命名为 rsicvexp 方便自己进行测试。 之后测试的时候在外部交叉编译生成 riscv 的可执行文件，复制到 rootfs 里面，然后就可以进行运行和测试了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Qemu","slug":"Linux/Qemu","permalink":"https://chivier.github.io/categories/Linux/Qemu/"},{"name":"Compiler","slug":"Linux/Qemu/Compiler","permalink":"https://chivier.github.io/categories/Linux/Qemu/Compiler/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/tags/Compiler/"},{"name":"Qemu","slug":"Qemu","permalink":"https://chivier.github.io/tags/Qemu/"}]},{"title":"2202-制作alternative","slug":"2022/2202-制作alternative","date":"2022-02-04T02:01:34.000Z","updated":"2022-02-04T08:18:43.150Z","comments":true,"path":"2022/02/04/2022/2202-制作alternative/","link":"","permalink":"https://chivier.github.io/2022/02/04/2022/2202-%E5%88%B6%E4%BD%9Calternative/","excerpt":"在做各种编译环境的时候，我们经常遇到这么一个问题: 我们的编译器需要调整到特定的版本，例如 gcc-4 或者 g++-8。","text":"在做各种编译环境的时候，我们经常遇到这么一个问题: 我们的编译器需要调整到特定的版本，例如 gcc-4 或者 g++-8。 但是我们使用的时候往往不会去刻意用额外的 CC=xxx CXX=xxx 之类的前缀，在网上 copy 命令的时候也非常容易忘记这件事情。 为此，Linux 中有一个 alternative 机制可以保证这一点从容灵活。这里做一个简单的介绍。 实验环境本次实验在 ACSA-snode6 机器上进行：机器环境由于不小心作大死变成了过高版本的 ubuntu 。不过问题不大，内核新一点也不算是坏事。 使用命令： 1ls /usr/bin/gcc-* 检查一下我们有哪些版本 如果是没有使用过的组，会有下面的这种情况： 但是这个不重要，使用： 12sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 8sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-8 8 其中最后一个数字代表 alternative 的优先级，我个人建议直接和版本好进行相关的对应联系起来，方便记忆。 类似的方法，把各个版本的 gcc 和 g++ 依次安装上来。之后再去使用 update-alternative 就可以看到如下的效果： 选择需要的版本即可。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Tricks","slug":"Linux/Tricks","permalink":"https://chivier.github.io/categories/Linux/Tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Tricks","slug":"Tricks","permalink":"https://chivier.github.io/tags/Tricks/"}]},{"title":"2202-没有指纹好气哦","slug":"2022/2202-没有指纹好气哦","date":"2022-02-03T09:19:12.000Z","updated":"2022-02-03T09:20:37.330Z","comments":true,"path":"2022/02/03/2022/2202-没有指纹好气哦/","link":"","permalink":"https://chivier.github.io/2022/02/03/2022/2202-%E6%B2%A1%E6%9C%89%E6%8C%87%E7%BA%B9%E5%A5%BD%E6%B0%94%E5%93%A6/","excerpt":"今天是没有指纹的第X天，自从我更新到 Ubuntu 22.04 之后，我深刻意识到这个系统相比 Debian 的落伍之处，虽然大家都是 Debian 系的，但是近两年来 Ubuntu 开发者开始不做人事。和 Gnome 开发组进行摆烂竞赛。对于此事我不做过多评价，只是：","text":"今天是没有指纹的第X天，自从我更新到 Ubuntu 22.04 之后，我深刻意识到这个系统相比 Debian 的落伍之处，虽然大家都是 Debian 系的，但是近两年来 Ubuntu 开发者开始不做人事。和 Gnome 开发组进行摆烂竞赛。对于此事我不做过多评价，只是： Ubuntu 升级之后大量的硬件驱动失去了支持，例如指纹、触控板等 Gnome 升级后和 GTK-3 系列软件发生快捷键冲突 有人问我 GTK-3 系列的软件多不多，我只能说 Gnome 的原生文件管理器就是基于 GTK-3 的。 吐槽太多了，下面记录我今天忍无可忍，发誓修复指纹的过程： 开始分析首先我先在 Google 上面进行了一番查询，发现了 Stack Overflow 上有人遇到了类似的情况： 类似状况链接 但是下面的解决方案不太管用。这个时候我开始怀疑自己的电脑是不是因为之前进水导致指纹传感坏了。 再次分析 在 lsusb 的界面里，发现了一个我感到陌生的模块，这个模块我之前并未过多在意，仔细一查： https://www.dell.com/community/Linux-General/No-driver-for-fingerprint-reader-Goodix-27c6-5381-on-Linux/td-p/8018706 好家伙，就是你做坏事了。 紧急查阅驱动，使用 1sudo -E ./hw-probe -all -upload 检测配件看看： https://linux-hardware.org/?probe=30ddfbc611 寄，这下裂开了，所有的发行版后面都跟着大大的 Fail 那么问题又来了，我之前在 Ubuntu2004 的时候是怎么使用指纹的呢？也就是说这个驱动其实是可以用的，但是需要和特定版本的库以及其他库进行配合。那么我们再想想办法。 单独录入如果我需要单独录入指纹，那么我们会用到 fprintd-enroll 命令。但是新的问题诞生了： fprintd-enroll 无法使用 这个时候发现，我用的 libfprintd 版本是 0.4。而一个可用的版本是 0.6。 在一番搜索之后，在 Dell 驱动支持的一个民间网站上找到了一个版本，用下面的命令下载： 12wget -O ~/Downloads/libp.deb http://dell.archive.canonical.com/updates/pool/public/libf/libfprint-2-tod1-goodix/libfprint-2-tod1-goodix_0.0.6-0ubuntu1\\~somer ville1_amd64.deb 好吧，折腾一圈心力憔悴。 终于可以读入我的指纹信息了，我开开心心录完指纹之后发现： KDE 不支持，但是具体的原因是什么呢？这个时候我再次进行探究。 登录系统我们在登录的时候，我们不能使用指纹录入。Ubuntu 的登录使用的是 gdm 系统，而 KDE 用的是 sddm。Sddm 的最新方面还没有支持上，Plasma 也没支持……那我只能寄了。 题外话（关于差点吧电脑搞没）我今天的一次测试差点把我电脑直接搞死。 如果我想把指纹应用到登录和 sudo 权限的时候，我们就要在 /etc/pam.d/sudo 和 /etc/pam.d/sdmm 进行修改。 https://wiki.archlinux.org/title/KDE_Wallet#Unlock_KDE_Wallet_automatically_on_login 我改完之后彻底没了…… 所有用到 sudo 的地方都开始报错： 1sudo: PAM account management error: Permission denied 最终我找到了一丝生机： 我们使用 Dolphin 调用编辑器的时候，我可以用用户密码去获取 root 权限，而 Shell 中不可能得到。这次事件之后我把我的 root 密码写到了我的笔记本（纸质）上面。终于活下来了。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Tricks","slug":"Linux/Tricks","permalink":"https://chivier.github.io/categories/Linux/Tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Tricks","slug":"Tricks","permalink":"https://chivier.github.io/tags/Tricks/"}]},{"title":"2201-环境变量编辑器","slug":"2022/2201-环境变量编辑器","date":"2022-01-31T12:51:23.000Z","updated":"2022-01-31T12:51:58.984Z","comments":true,"path":"2022/01/31/2022/2201-环境变量编辑器/","link":"","permalink":"https://chivier.github.io/2022/01/31/2022/2201-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%BC%96%E8%BE%91%E5%99%A8/","excerpt":"设计思想","text":"设计思想 最近遇到了这么一个问题：我们在编辑环境变量的时候，往往会有一些定制化的需求，如何方便的编辑环境变量是一个比较难的问题。 变量类别： 路径变量 路径组变量 IP地址变量 字符串变量 分类别进行“检测分类”和“编辑” 检测：字符串检测编辑：整合操作序列，软件退出并且确认保存之后才会被执行一系列的export指令 需要解决的问题： 操作流程 cli用户界面设计 ranger读取器（todo？） env的编辑逻辑 开发笔记实现变量类型的识别首先 ipv4 和 ipv6 的形式非常简单，有特定的识别方法。 1234567891011121314def check_ipv6(address: str) -&gt; bool: try: socket.inet_pton(socket.AF_INET6, address) return True except socket.error: return False def check_ipv4(address): try: socket.inet_aton(address) return True except socket.error: return False 下一步思考路径。路径有两种可能： 合法路径 不合法路径（可能因为某种原因被删除了） 那么如何设计合法的路径名呢？ 这里我考虑了一些情况： 路径名中可能包含其他环境变量，但是根据规范 环境变量名只能是大小写字母、数字、下划线构成 路径名可能会有多个/重复，但是这个不影响他作为一个合法路径 这样就构成了一个简单的路径名称合法判断正则（顺便得到了一个可以用来检测环境变量名称是否合法的正则） 01/29/2022 21:35我想骂人问题的性质已经变了。对于环境变量的解读其实工作应该是shell处理的，而不是我自己去复现一个parse工具因为Linux的文件命名过于随意，文件名可以有： 、$ 所以路径名没法很好的解析出来不过我也受够了，不管别的了，直接开搞吧，姑且认为这个美好的世界上还是人类居多吧 01/31/2022 20:43好吧，莫名其妙就做完了 github.com/Chivier/enview 功能不做过多赘述啦，我们直接在github里面看效果啦","categories":[{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/categories/Rust/"},{"name":"Develop","slug":"Rust/Develop","permalink":"https://chivier.github.io/categories/Rust/Develop/"},{"name":"DSL","slug":"Rust/Develop/DSL","permalink":"https://chivier.github.io/categories/Rust/Develop/DSL/"}],"tags":[{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/tags/Rust/"},{"name":"DSL","slug":"DSL","permalink":"https://chivier.github.io/tags/DSL/"},{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/tags/Develop/"}]},{"title":"2110-数据流加速处理器","slug":"2022/2110-数据流加速处理器","date":"2022-01-21T18:46:15.000Z","updated":"2022-01-21T18:47:48.714Z","comments":true,"path":"2022/01/22/2022/2110-数据流加速处理器/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2110-%E6%95%B0%E6%8D%AE%E6%B5%81%E5%8A%A0%E9%80%9F%E5%A4%84%E7%90%86%E5%99%A8/","excerpt":"综述","text":"综述 近年来数据流处理器需求增长，传统冯诺依曼架构不再够用。 FPGA项目：Microsoft Catapult FPGA 加速器项目 特征： 计算强度高，阶段长 具有简单控制流的小指令占用空间 直接的内存访问和重用模式 原因很简单：通过利用并发性，这些属性有助于非常高效的硬件实现。 现有的数据并行硬件解决方案在这些工作负载上表现良好，但为了更通用，为了取代特定领域的硬件，牺牲了太多的效率。 例如，短向量 SIMD 依赖于低效的通用流水来进行控制和地址生成，但加速代码通常没有复杂的控制和内存访问。 GPU 使用硬件来隐藏内存延迟以实现大规模多线程，但加速代码的内存访问模式通常可以在没有多线程的情况下轻松解耦。 可重构的粗粒组成架构（CGRA）和专用的地址空间（Scratchpad） 图1：图2：图3： 红色箭头表面着之间存在依赖关系，这里不能同时执行。 当端口A和端口B可用，则计算开始。同时，最后两个命令生成并排队。一旦计算的一个实例完成，所计算的数据就开始流传输到内存。 适应数据流的特征：1. 应该保证DFG图应该保证足够大2. 数据流的流动应该尽可能的“长”3. 重用的数据应该保证被scratchpad记录，以保证减少访存 理解：scratchpad = Cache，可以根据应用定制大小 应该设计的接口范例： 例子： 重新回到 Scoreboard 设计 这个图非常关键，应该就是OneAPI的设计逻辑，因为OneAPI引用了ISCA09和ISCA17的文章和此文均有关联。 在之前的文章中，不止一次提到了数据流处理器这个“古老”的设计理念。根据我所掌握的历史来看，数据流思想的诞生应该从1974年，在ISCA上由Dennis 和Misunas在“A Preliminary Architecture for a Basic Data Flow Processor”中提及。在之后的若干年里，Treleaven （ACM Computing Surveys1982） ，Veen （ACM Computing Surveys1986）,Gurd （CACM 1985 ），Arvind and Nikhil （IEEE TC 1990）,Lee （IEEE Computer 1994 ）中也数次提及这个概念。但是由于控制流结构在通用处理器中的商业模式已经较为稳定，数据流的研究一直以来被视为非主流的设计方案。直到深度学习处理器这类逐渐向火以来，数据流的概念又被当下的研究者重新研究。本文主要对于ISCA_2017中的一文写些文中的精髓部分的理解。 数据流设计的起源思想是：具有长时间的高计算强度，简单的控制模式和依赖关系，简单的流式存储访问和重用结构。本文中定义了一个通用的架构（硬-软件接口），该架构可以提供更有效的数据流式表达程序。 流式数据流架构的三点基本抽象原则： 用于重复的流水线计算的数据流图 基于流的命令，以促进数据在组件之间以及到内存的高效移动 专用（便签本）地址空间，可以有效地重复使用数据 基于以上的三点抽象原则： 上图描述了流数据流的程序员视图，包括数据流图本身，以及用于内存访问，读取重用和递归的显式流通信。抽象的表达了直观的硬件实现； 上图表示的是本文中的high-level的设计。它由可重构的粗粒组成架构（CGRA）和专用的地址空间（Scratchpad），通过宽总线连接至内存。它由一个简单的控制核心进行控制，该控制核心发送流命令由内存控制引擎，暂存器控制引擎和CGRA同时执行。这个基于流的接口的粗颗粒性质使内核相当简单而不牺牲高度并行的执行。流访问模式和受限的内存语义也使高效地址生成和协调硬件。相对于特定领域的体系结构，流数据流处理器可以重新配置其数据路径和内存流，因此更普遍和适应性强。 初探Stream-Dataflow架构 本文提出的流式数据流的架构主要由Stream组件和dataflow组件构成。其中Stream组件提供类似于vertor运算的与内存交互的接口（这是vertor架构的优势，下图b），dataflow组件提供空间上的计算规范（这是dataflow的优势，下图a）。 Stream-Dataflow 流式数据流的抽象架构 上图主要设计思想是stream接口提供对一组有序的stream命令的支持，该命令嵌入在现有的Von Neu mann ISA中。流命令指定长和并发的内存访问模式。可表达的模式包括连续的，跨步的和间接的。我们添加了一个单独的“Scratch”地址空间，该地址空间可用于有效收集和访问重复使用的数据。最后，数据流接口通过数据流图（DFG）公开指令及其相关性。 DFG的输入和输出接口被命名为具有可配置宽度的端口，它们是流命令的源和目的地。 Micro-architecture设计思想 一种标准的硬件实现包括：用于计算的粗粒度可重配置体系结构（CGRA），可编程暂存器，用于处理存储器或暂存器访问命令的流引擎以及用于生成流命令的控制核心。流分派器强制流之间的体系结构相关性。控制核心可以执行任意程序，但可以编程为将尽可能多的工作分流到流数据流硬件。（结合第二张图分析） Stream-Dataflow的详细设计方案 这部分主要从抽象，执行模型和ISA来描述数据流的体系结构。 抽象 再次观察架构图的图a，数据流的架构中，通过将控制计算的顺序，映射城数据流图。通过数据的流向和barrier来控制数据流向的有序正确进行。在数据流图中，存在着指令数据计算的先后的依赖关系，一条中间指令的执行，必须等到符合满足它的数据已经ready时，才可以开始进行计算。将传统的PC指令控制的顺序，转换成数据之间的依赖关系。在数据流图当中，用户显示命令数据的起点节点和终止节点来确保一次数据的迭代的开始与终止。在架构设计中，用户还可以自定义barrier用以确保程序的序列正确执行。如果没有barrier的控制，那么只要等到数据的ready，所有的数据流都可以同时执行各自的任务。 编程与执行模型 Stream-Dataflow由配置信息，数据流动，以及barrier命令组成。在通用的程序当中，可以通过转换变为数据流的代码，实例如下： 在图a中，内存访问了a，b和r。根据架构a的乘加运算关系可将左侧的代码转换为右侧的代码。在下面的b图中，是上述程序的执行过程。程序均以命令开始启动数据开始计算，红色箭头表面着之间存在依赖关系，这里不能同时执行。当端口A和端口B可用（端口宽度为3），则计算开始。同时，最后两个命令生成并排队。一旦计算的一个实例完成，所计算的数据就开始流传输到内存。当所有数据都释放到内存系统中时，屏障命令的条件得到满足，控制核心也将恢复。为了获得更好的性能，应该保证DFG图应该保证足够大，这样可以满足尽可能多的指令并行运算。第二，数据流的流动应该尽可能的“长”。第三，重用的数据应该保证被scratchpad记录，以保证减少访存。 ISA指令集 指令集的设计代表了体系结构设计的灵魂。下图是Stream-Dataflow支持的指令集。 在上面的表格中，访存的地址的格式文中作者进行了特别的设计使得更符合数据流思想。 这样的模式是二维的仿射访问，由访问大小access size（最低级别访问的大小），跨步stride size（连续访问之间的大小）和前进的步数number of strides。对于不同情况下的（linear，Strided等）可以映射成下面图那种形式。 微架构的设计 设计有着两个原则： 避免使用大型的或者耗电量大的结构，特别如多端口存储器 充分利用ISA提供的并发性。 根据以上的两个原则，可以设计出： 在整体上看来，该设计在生成流命令的时候考虑了低功耗控制内核，一组与引擎有效连接并移动数据的流引擎，以及用于高效并行计算的深层管道可重配置数据流基板。 详细来说，主要由以下五种组件构成： 控制核：一种低功耗的单发有序控制核，目的是生成数据流命令用以调度程序 Stream Dispatcher：该单元通过跟踪流资源分配和向流引擎发出命令来管理流引擎的并发执行。 流引擎：进行数据访问和移动，通过三个“流引擎”，其中一个用于存储（便于广泛访问内存），一个用于暂存器（高效数据）重用，和一个用于DFG重复（用于在没有内存存储的情况下立即重用）。流引擎对各自的内存和暂存器资源分配给他们的流进行仲裁。 向量端口：向量端口是两个端口之间的接口。CGRA执行的计算以及传入/传出数据的流。另外，一组矢量端口不连接到CGRA的设备用于存储间接加载/存储的流地址。 CGRA：粗粒度可重配置架构支持数据流图的流水线计算，CGRA避免了重复访问寄存器文件或近期内存数据。 在此过程中，由数据流引擎负责控制该流的生命周期，该引擎负责调度相关程序，发布新的流命令等。 流调度与控制核心 流分派器的作用是增强对流（和屏障命令）的资源依赖性，并通过向它们发送命令来协调流引擎的执行。这部分的内部架构设计如下： 从图中可以看出，来自控制核心的流请求被排队（Stream Cmd Queue），直到它们可以被命令解码器处理为止。该单元与资源状态检查逻辑进行协商，以确定是否可以发出命令，如果可以，则将其出队。屏障命令阻止核心发出进一步的流命令，直到解决屏障条件为止。 资源管理 具有相同源或目标端口的后续流必须按程序顺序发布，即控制核心上流的动态顺序。流分配单元负责维护此顺序，并通过在记分板上跟踪矢量端口和流引擎状态来实现。在发布流之前，它会检查这些记分板的状态。 引导程序端口的状态为“已占用”，“空闲”或“所有请求”。端口在发布时（由资源分配器）从空闲状态变为占用状态，并且该流在飞行中逻辑上拥有该资源。当该流结束时，关联的流引擎会通知调度程序将向量端口的记分板条目更新为自由状态。飞行中的所有请求状态指示所有对内存流的请求已完全发送到内存系统（但尚未到达）。此状态作为一种优化存在，以使使用同一端口的两个内存流能够同时在存储系统中拥有它们的请求。 流引擎 流引擎管理组件通过被许多激活流对各种资源的并发访问（内存接口，暂存器，输出向量端口）。通过从流分配器接收命令来启动流引擎。然后，它们在流的生命周期内协调地址生成和数据传输，并最终在释放相应的向量端口时通知调度程序（当流完成的时候）。流分配器确保并发流对其向量端口具有专用访问权限。未连接到CGRA的矢量端口促进了间接访问，该端口可缓冲运行中的地址。 整体上来说，该架构的设计就大致如此。他的效果评估如下： 55nm下的仿真结果，对比功耗与面积。 运行DNN时候与GPU,Diannao的性能比较。 总结： 本文提出了一种新的执行模型和架构，流式数据流架构，它提供了抽象，可以平衡矢量和空间体系结构之间的折衷，并在重要的一类数据处理工作负载上获得二者的专业化能力。 我们设想，这种架构的范式可以具有根本性通过减少专用模块的数量来简化对未来芯片的影响。相反，流数据流类型的结构可以与CPU和GPU处理器并排放置，并具有综合功能当程序遇到适当的阶段以进行高效加载时，就可以快速运行。这不仅减少了面积和复杂性大量的专用加速器，还可以减轻不断增长的设计和验证成本。在如此广阔的环境中，开发有效的编译工具以平衡这些架构所提供的并行性和数据重用之间的复杂权衡至关重要。为流数据流体系结构提供动态编译支持可以提高特定架构的能效。","categories":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/categories/Architechture/"},{"name":"Dataflow","slug":"Architechture/Dataflow","permalink":"https://chivier.github.io/categories/Architechture/Dataflow/"}],"tags":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/tags/Architechture/"},{"name":"Dataflow","slug":"Dataflow","permalink":"https://chivier.github.io/tags/Dataflow/"}]},{"title":"2110-OP DSL","slug":"2022/2110-OP-DSL","date":"2022-01-21T18:46:04.000Z","updated":"2022-01-21T18:47:48.470Z","comments":true,"path":"2022/01/22/2022/2110-OP-DSL/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2110-OP-DSL/","excerpt":"https://op-dsl.github.io/papers.html","text":"https://op-dsl.github.io/papers.html OP2 设计OP2 API 对于非结构网格的联系往往需要用复杂的拓扑序列维护关系，但是不同的网格具有不同的性质，例如四边形网格，每一个网格只会有上下左右四个联系单元。对于一般的拓扑关系，我们维护： sets data on sets connectivity between sets (mapping) operation over sets 用四边形网格为例，我们关心的集合有： 1234int nedges = 12; int ncells = 9; int nbedges = 12; op_set edges = op_decl_set(nedges, &quot;edges&quot;); op_set cells = op_decl_set(ncells, &quot;cells&quot;); op_set bedges = op_decl_set(nbedges, &quot;bedges&quot;); 数据维护 12345678double cell_data[9] = &#123;0.12B, 0.345, 0.224, 0.11B, 0.246, 0.324, 0.112, 0.92B, 0.237&#125;; double edge_data[12] = &#123;3.3, 2.1, 7.4, 5.5, 7.6, 3.4, 10.5, 9.9, B.9, 6.4, 4.4, 3.6&#125;; op_dat dcells op_decl_dat(cells, 1, &quot;double&quot;, cell_data, &quot;data_on_cells&quot;); op_decl_set(edges, 1, &quot;double&quot;, edge_data, &quot;data_on_edges&quot;); 连接性： 1234int edge_to_cell[24] = &#123;0,1, 1,2, 0,3, 1,4, 2,5, 3,4, 4,5, 3,6, 4,7, 5,B, 6,7, 7,B &#125;; op_map pecell = op_decl_map(edges, cells, 2, edge_to_cell, &quot;edge_to_cell_map&quot;); 操作 kernel function： 12345678void res(double* edge, double* cellO, double* cel11)&#123; *cellO += *edge; *cell1 += *edge; &#125; op_par_loop (res, &quot;residual_calculation&quot;, edges, op_arg(dedges, -1, Op_ID, 1, &quot;double&quot;, OP_READ), op_arg(dcells, 0, pecell, 1, &quot;double&quot;, oP_INC), op_arg(dcells, 1, pecell, 1, &quot;double&quot;, OP_INC)); 核函数需额外的说明： 其中涉及了关于潜在数据依赖的处理，这一部分机制之后也会考虑。 并行策略网格分区方案还是依赖了ParMetis 两个大的并行级别： distributed memory single-node/shared-memory 就是节点间并行和节点内并行。节点内并行的重要性高于节点间并行。因为节点之间并行其实只能通过MPI做Message Passing，我们更加 care 的是节点内的情况。设计遵循3条关键假设： each compute node will have GBs of memory memory bandwidth is a major limitation there is very little local shared memory Cuda 策略由于关键假设2，所以需要最小化主存和进程的通讯量。对于间接循环（涉及间接引用数据集的循环），这导致了使用小分区的想法，这些小分区足够小，以便每个小分区的所有间接数据集都能够适应有限的共享内存 在 NVIDIA GPU 中的每个 SM 上。对于数据冲突的问题，会有其他策略，这部分之后介绍。基于来自 FFTW 的想法，我们为每个并行循环构建了一个执行“计划”，该计划是该循环在 GPU 上的执行的自定义阻塞，从而优化使用每个多处理器上的本地共享内存，并详细考虑了循环计算。 MPI 策略 暴力全部拷贝同步。 计算策略和 Cuda 类似，也使用了类似于 FFTW 的 execution plan Plan construction这一部分在代码 c/core/op_lib_core 中有详细说明。 是并行循环在其上执行的抽象“元素”的集合。 “数据集”是与集合相关的数据，例如流变量或边权重，它们是并行循环函数的参数。 在特定的并行循环中，“间接数据集”是使用来自另一组的映射间接引用的数据集。 预处理器 op2.m 为每个并行循环识别参数 nargs 的数量、间接数据集 ninds 的数量以及从参数到间接数据集 inds[] 的映射。 最后一个对每个参数都有一个条目；如果它等于 -1，则该参数不引用间接数据集。 执行计划将执行集划分为小分区。 这些在代码中被称为“块”，因为它是一个较短的词。 与 CUDA 线程块相比，“块”一词的用法略有不同，但每个计划块都由单个 CUDA 块处理，因此希望不会太混乱。 计划块的大小使得间接数据集适合每个 SM 可用的有限共享内存量（“流式多处理器”，NVIDIA 用于描述其 GPU 中的每个执行单元的首选术语）。 这个想法是将间接数据集保存在共享内存中，以最大限度地重用数据并避免全局内存流量。 然而，这需要对用于引用这些数据集的映射重新编号。 算法执行步骤为： 通过简单地附加到列表来构建对数据集的所有引用的列表 对列表进行排序并消除重复项——然后定义从本地索引到全局索引的映射 使用一个大的工作数组来反转映射，给出从全局索引到局部索引的映射 创建使用新本地索引的映射表的新副本 请注意，每个间接数据集最终都有自己的重复映射表。在这种情况下，我们目前通过复制重新编号的映射表会浪费内存和内存带宽。将来应该通过识别此类重复项、取消分配重复项并将指向重复表的指针更改为指向主表来消除这种情况。 为了避免数据依赖，这里使用染色策略。目标是为每个元素分配一个颜色，没有两个相同颜色的元素引用相同的间接数据集元素 对于每个间接数据集元素，我们维护一个引用它的元素的颜色列表。 从这个初始化为空的列表开始： 循环遍历 set 元素引用的所有间接数据集元素，以找到尚未引用它们的最低索引颜色 将此设置为元素的颜色 再次循环所有间接数据集，将此颜色添加到它们的列表中 核间策略 维护边界","categories":[{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/categories/Compiler/"},{"name":"DSL","slug":"Compiler/DSL","permalink":"https://chivier.github.io/categories/Compiler/DSL/"}],"tags":[{"name":"DSL","slug":"DSL","permalink":"https://chivier.github.io/tags/DSL/"},{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/tags/Compiler/"}]},{"title":"2111-数据流语言设计-version1","slug":"2022/2111-数据流语言设计-version1","date":"2022-01-21T18:44:58.000Z","updated":"2022-01-21T18:47:49.026Z","comments":true,"path":"2022/01/22/2022/2111-数据流语言设计-version1/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2111-%E6%95%B0%E6%8D%AE%E6%B5%81%E8%AF%AD%E8%A8%80%E8%AE%BE%E8%AE%A1-version1/","excerpt":"初衷","text":"初衷 为了研究为什么需要做数据流，什么应用需要数据流这个问题，我个人经历了一段时间的思考。参考学习了COStream项目： 流程序，即有序处理数据序列的程序COStream编程语言是一种面向并行体系结构的高性能流编程语言，采用同步数据流图的计算模式，即程序实现了一些独立的结点(为独立计算单元，COStream中称为actor)，这些结点通过输入和输出通道进行数据传递(即actor的输出边和输出边)，这些节点一起组成了代表整体运算的流图。 COStream语言的主要目的是: 在多核架构下揭露并利用流程序固有的并行性 自动实现特定域中流应用专家进行的优化 提高程序员在流域中的工作效率 COStream如何实现程序的并行: 任务划分 给数据流图中的各结点分配处理器核（核的总个数由后台程序员确定），一个结点对应一个核，一个核可对应多结点，使各核的计算量大致相同，总通信开销尽量小。 阶段赋值 给数据流图中各结点分配阶段号（总的阶段号由编译器决定），使每一阶段的总工作量大致相同，前一阶段的结点所需数据不依赖后一阶段中结点的输出。 软件流水 采用软件流水技术，实现并行。其中，软件流水中第n阶段执行阶段号为n的结点。 适用于数据流的应用： 大的数据流适合COStream应用的最根本特征体现在其在一个大数据序列(甚至是无穷的)，即数据流上进行操作，数据流中的每一个数据项在有限的时间内被处理，然后被丢弃。 独立的数据流结点从概念上说，一个流的计算体现在该程序中数据流的转换。我们定义数据流的基本计算单元为actor：在每次执行阶段中，从输入流中读一个或多个数据项，对其进行计算，然后将一个或多个计算结果写入到输出流中。Actor通常都是独立和自足的，即没有包含对全局变量和其他actor的引用。一个流程序就是由一系列的actor组成的数据流图，其中一些actor的输出将是另外一些actor的输入。 一个稳定的计算模式在程序稳态执行的过程中，数据流图的结构通常是不变的。即，一系列确定的actor将按照一个有序的顺序反复执行，给定一个输入数据流，将产生一个输出数据流。 滑动窗口的计算数据流中的每一个值通常都会被同一个actor在连续的执行中所检测，也被称为滑动窗口。滑动窗口的例子包括生物序列分析、自然语言的处理、图像的处理（锐化、模糊化等）、网络数据包的检测等。 偶尔的流外通信除了大容量的数据流将从一个actor流向另一个actor，actor也将通信一些少量的控制信息在一些罕见的不规则的基础上。例如：改变手机的音量，在屏幕中打印错误信息，或者改变自适应FIR actor中的系数。 这些信息通常和数据流中的数据相同步，例如调频电台在数据流中的某个特定点的传输时改变其频率。 高性能的期望通常一些数据流程序需要满足实时性的限制，因此效率（延迟和吞吐量反面）是主要的考虑因素。另外有一些嵌入式的流程序将用于手机环境中，因此电量消耗，存储限制，代码大小限制等也很重要。 一个粗糙的设计我们研究数据流有3个主要问题需要解决： 问题的描述和设计模式（数据描述方法） 任务划分和分配方法（数据流动方法） 任务执行需要的数据传输问题（数据依赖分析） 个人选择对应的三项研究分别为： OP2 ： 数据描述 SVF ： 数据依赖分析 COStream ：数据流动方法 这种时候必要的时候需要设计多级编译： 第一级编译 (Data Compiler) ： 原有程序不需要改动，将他编程更“规范”的数据描述模式 第二级编译（Dependencies Compiler）：如果程序需要流动，涉及依赖的部分需要复用数据和资源，这一部分需要通过旁路(Bypassing)处理 第三级编译（Flow Compiler）：将已经处理好依赖的部分编程更加适合计算的数据流，交付给具体的runtime 我们暂时借用OP2的基本数据设计模式：OP2 详情参考 [[2110-OP DSL]] 详细设计数据编译设计个人认为，数据编译设计最基本的单元是：数据元素、数据块 元素顾名思义，即为单个的item，从简设计，目前只提供：16/32/64 bits integer","categories":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/categories/Architechture/"},{"name":"Dataflow","slug":"Architechture/Dataflow","permalink":"https://chivier.github.io/categories/Architechture/Dataflow/"}],"tags":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/tags/Architechture/"},{"name":"Dataflow","slug":"Dataflow","permalink":"https://chivier.github.io/tags/Dataflow/"}]},{"title":"2111-数据流经典论文整理","slug":"2022/2111-数据流经典论文整理","date":"2022-01-21T18:44:44.000Z","updated":"2022-01-21T18:47:48.902Z","comments":true,"path":"2022/01/22/2022/2111-数据流经典论文整理/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2111-%E6%95%B0%E6%8D%AE%E6%B5%81%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/","excerpt":"数据流发展综述","text":"数据流发展综述 自计算机诞生以来, 计算机系统研究人员为提升计算速度, 一直百折不挠、不懈努力. 几十年间学 术界、产业界开展了多种多样的计算机体系结构探索, 产生了很多令人耳目一新的成果, 人们熟知的冯诺依曼结构瓶颈被反复诟病, 但是冯诺依曼计算机结构依然是当前计算机系统的主流架构. 在 谈及非冯计算机体系结构时, 数据流计算机无疑是被提及最多的. 控制流计算思想在表达计算任务方面比较符合人类的思考习惯.首先通过指令序列描述计算任务执行过程. 其中, 指令用操作码表示功能, 操作数表示被处理的数据. 控制流计算任务被描述为一串指令序列. 经典计算机体系结构中, 设计了以程序计数器 (program counter, PC) 为核心的控制器实现控制流计算思想.在执行时首先需要将待执行的指令取出, 经过译码后执行指令, 并通过地址访问内存, 获取需要的数据, 最后将结果数据写回到存储器中. 完成该条指令后, 程序计数器自动加一, 获取下一条指令继续上述流程. 在计算机系统发展初期,研究人员逐渐发现控制流计算思想中存在的性能瓶颈问题, 即指令执行是串行的, 而且取指令、取操作数、存结果等动作都需要访问存储器。 在基于数据流的计算任务中, 一项运算操作在获得了所有需要的操作数时即可执行, 所产生的结果数据不会被存储器保存, 而是直接作为操作数发送给后续的操作, 直到产生最终的输出结果. 与控制流计算思想中的指令序列串相比, 数据流图以图的形式描述了计算任务的并发执行全过程, 同时数据可以按照数据流图中边的指向直接传递到运算操作, 不需要缓存到存储器中. 静态数据流机是根据数据流计算思想, 具体实现出来的一种执行机构, 其基本结构主要由取指令部件、指令存储部件、处理部件、更新部件等组成. 在静态数据流机中运行程序时, 操作数不通过 “寻址” 被访问, 而是通过 “令牌 (token)” 或 “值” 的形式进行传递. 数据流计算机中的信息项由数据令牌和操作包组成, 其中, 数据令牌由结果值和目的地组成, 操作包由操作码、操作数和后继指令位置等组成. 待执行的数据流程序存放在指令存储部件中, 当某条指令所需的所有数据令牌都到达后, 取指令部件将相应的指令取出, 发送到可执行指令队列. 当物理计算资源有空闲时, 队列中的指令将依次被分配给处理部件进行并发执行. 这种等待结点所有输入弧中都获取到令牌后触发该结点执行的行为被称为“点火(firing)”, 是数据流计算模型的重要特点之一. 所产生结果形成新的令牌发送到更新部件中, 更新部件按令牌中的目标地址将令牌发送到指令存储部件内的相应指令位置.如果有指令已经获取到了所有需要的令牌, 更新部件会将该指令的地址发送给取指令部件, 进行下一次的数据流执行. 动态数据流机重点解决数据流图的边存在多次执行的问题. 静态数据流机虽然具备基本的数据流执行能力, 但它不仅依赖于数据, 也需要配合带有简单控制信号的 “控制令牌” 来确认指令间的数据传送, 且无法保证并发的重复性调用 (例如递归)对于这个问题, 动态数据流机通过 “标号令牌(tagged-token)” 的方式, 使单条弧上可以同时存在多个不同的令牌. 相比于静态数据流机, 动态数据流机在执行机构上增加了一个 “匹配部件”, 该部件负责添加标号和匹配标号的工作, 使数据令牌的传送不再依赖于控制令牌. 更新/取值部件通过标号的配对, 从指令存储部件中获取指令, 结合收到的数据令牌组, 合并出可执行的指令, 送至可执行指令队列. 这样一来, 数据流程序的并行性得到了更大限度的开发, 也具备了更完善的功能. Dennis 的 数据流文章：https://dl.acm.org/doi/10.1145/642089.642111 这篇文章可以说是诸多数据流研究的开端。有人称，这种数据流叫做 Static Data Flow，也有人叫 Pure Data Flow。 其核心思想可以用：A data flow node fires (fetched and executed) when all its inputs are ready 进行概括。 Dennis老师对数据流处理器进行了四种基本模块的设计： Fork Primitive Ops Switch Merge 图示： 数据流图中，所有的值可以表示为 token 的形式，一般来说，token 采用一个三元组的形式：&lt;ip, p, v&gt;， 其中，ip为指令指针，指向对应的数据流元件，p为端口，表示对应的数据流接口，v为指令值，表示传递过去的数据。 举个例子：$x = (a + b) * (b * 7)$ 流图形式为： 其中 (a + b) 的结果 姑且称为 c，c可以记录为：&lt;Mul-2, Left, (a + b)&gt;, Mul-2 是因为他传入第二层的乘号，Left 是传入左侧 Port 一个非常经典的例子可以说明控制流和数据流的区别： 其中所有的弧线表示数据依赖，如果采用数据流，那么每一个格子，即我们使用到数据的地方，是不可能有重复弧边的，这说明数据流方法可以有效规避数据依赖导致的冒险等问题。 为了使得程序正常运作，需要一些“协议”保证，论文原文如下： 即输入就绪、输出弧无数据阻塞。但是静态数据流依旧。此外还有一条，但是是在static的定义中被补充：每个计算节点只有一个指令实例可以被fire。 即每一条指令同一时间只能被一次执行。对于高度复用类型的程序，static数据流就不再合适，例如：循环程序和复杂数据结构。 Monsoon 处理器 文章： Executing a Program on the MIT TaggedToken Dataflow Architecture 上述所说，为了处理类似循环，我们需要将token放在unbounded queue的结构中。这就诞生了 dynamic dataflow。 dynamic dataflow 中引入了一个新的结构，有人称为 context， 有人称为 frame pointer，有人称为 instruction template。总之就是对 token 的一个拓展。 现在的形式为：token &lt;fp, ip, port, data&gt; fp 即为 frame pointer，用于记录此条token将被哪个指令实例所接收。如果Frame里面已经有buffer记录了，那么可以流动起来并且计算结果，否则就将此token记录存储在frame列表中。 此设计被发表于 ISCA 1990 动态数据流的思路可以简单的用这张图概括： 更多关于 Tag 的处理在论文中有所介绍，不过这一部分和我们的需求不尽相同，这里不做过多探究。 传统数据流方法的优劣上述的两种方法其实都是传统数据流方法。作为经典的数据流方法，他们的优势是非常明显的： 可以最大程度上激发并行度，即使对于不规整的程序行为（不简单直接的控制人跳转，复杂的依赖关系等等）也有极好的并行效果 只有“实际依赖”才会阻塞程序（写后读依赖） 缺点同样明显： 数据流编程模式缺乏固定统一的方法和接口，同时debug非常困难，因为程序原有的逻辑行为已经被破坏，也没有固定的状态表示方法 中断行为描述起来异常困难，没有很好的控制方法把程序终止 过于依赖查表（tag表、数据表等等），对内存不友好，对计分板设计提出极高的需求 指令周期不固定，阻塞时间不定长，关键节点的流速会影响全局流速 发展设想：数据流和控制流的结合设想1: ISA级别优化对于大体框架我们保持不变，但是我们的数据流针对ISA级别进行处理，编译器不改动，对后端的架构进行更新和修改。即： Keep control flow at the ISA level, do dataflow underneath, preserving sequential semantics 设想2：整合模式保留数据流模型，但在 ISA 级别合并控制流以提高效率、利用局部性并简化资源管理（计分板）。同时将线程合并到数据流中：先静态方法排指令；当第一条指令被触发时，剩余的指令会不间断地执行。 Keep dataflow model, but incorporate control flow at the ISA level to improve efficiency, exploit locality, and ease resource managementIncorporate threads into dataflow: statically ordered instructions; when the first instruction is fired, the remaining instructions execute without interruption 其实这种模式方案更贴切，如果需要实现这种方案，直观的思路有二： 用编译器处理 提高用户门槛，让用户使用指导语句、编程接口去自己控制数据流图 如何更好的将两者整合实现时我们的目标。 UPC++UPC++是一个支持分区全局地址空间（PGAS）编程的C++库。它是设计用于在分布式内存并行计算机上编写高效、可扩展的并行程序的一个工具。UPC++的关键通信设施是单边远程内存访问（RMA）和远程过程调用（RPC）。UPC++的控制模型是单程序、多数据（SPMD），每个独立的组成程序进程可以像在C++中那样访问本地内存。PGAS内存模型另外还提供 全局地址空间的单边RMA通信，它被分配在共享段中，分布在各个进程中。分布在各个进程中。 UPC++还具有远程程序调用（RPC）的功能。通信，使其很容易将计算转移到驻留在远程进程的数据上进行操作。UPC++的设计是为了支持超大规模的高性能计算，库的接口和 实施的重点是最大限度地提高可扩展性。在UPC++中，所有的通信操作都是 语法上是明确的，这鼓励程序员考虑与通信和数据移动相关的成本。和数据移动相关的成本。此外，所有的通信操作在默认情况下都是异步的，鼓励程序员寻求重叠的机会。程序员寻找机会将通信延迟与其他有用的工作重叠起来。UPC++ 提供了富有表现力和可组合的抽象，旨在有效地管理程序中异步的积极使用。在程序中的积极使用。这些设计原则的目的是使程序员能够使用UPC++编写应用程序，即使是性能良好的程序。使用UPC++编写应用程序，甚至在几十万个内核上也能表现良好。","categories":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/categories/Architechture/"},{"name":"Dataflow","slug":"Architechture/Dataflow","permalink":"https://chivier.github.io/categories/Architechture/Dataflow/"}],"tags":[{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/tags/Architechture/"},{"name":"Dataflow","slug":"Dataflow","permalink":"https://chivier.github.io/tags/Dataflow/"}]},{"title":"2112-Docker笔记","slug":"2022/2112-Docker笔记","date":"2022-01-21T18:44:25.000Z","updated":"2022-01-21T18:47:49.246Z","comments":true,"path":"2022/01/22/2022/2112-Docker笔记/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2112-Docker%E7%AC%94%E8%AE%B0/","excerpt":"Docker 简介","text":"Docker 简介 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 版本开始，则进一步演进为使用 runC 和 containerd。 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 下面的图片比较了 Docker 和传统虚拟化方式的不同之处。传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 基本概念Imageroot 文件系统比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统。 Container镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体 使用镜像获取镜像1docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 一般情况下 docker 的镜像下载如果是教育网，那么速度非常高效。如果需要使用镜像，那么可以使用： https://yeasy.gitbook.io/docker_practice/install/mirror 的教程进行安排。 镜像列表1docker image ls 删除镜像1docker image rm ... 使用容器创建容器实例1docker run -it --rm ubuntu:18.04 bash -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。 ubuntu:18.04：这是指用 ubuntu:18.04 镜像为基础来启动容器。 bash：放在镜像名后的是 命令，这里我们希望有个交互式 Shell，因此用的是 bash。 这里是交互式和镜像互动的方法。 更多操作在Docker Cheatsheet中学习 使用实例： Overleaf docker 安装这里介绍一下在node6上配置overleaf的过程。 由于overleaf已经开源，所以可以使用他们的docker直接进行配置。 镜像拉取1docker pull sharelatex/sharelatex 配置文件拉取12wget https://raw.githubusercontent.com/sharelatex/sharelatex/master/docker-compose.ymlsudo vim docker-compose.yml 需要修改的就是ports: - 80:80,一般80端口都被apache或nginx占用了，改用其他端口如：ports: - 9000:80 启动sharelatex1docker-compose up -d 安装latex包123docker exec -it sharelatex bashtlmgr update --self --alltlmgr install scheme-full 创建admin打开： http://hostname:9000/launchpad创建admin即可 配置高亮12apt install python3apt install python-pygments 参考：【1】https://www.jianshu.com/p/408a3b7a40b0【2】https://yxnchen.github.io/technique/Docker%E9%83%A8%E7%BD%B2ShareLaTeX%E5%B9%B6%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%E4%B8%AD%E6%96%87%E7%8E%AF%E5%A2%83/#%E5%AE%89%E8%A3%85%E5%B9%B6%E9%85%8D%E7%BD%AEShareLaTeX【3】https://sparktour.me/2021/04/02/self-host-overleaf/","categories":[{"name":"Docker","slug":"Docker","permalink":"https://chivier.github.io/categories/Docker/"},{"name":"Tutorial","slug":"Docker/Tutorial","permalink":"https://chivier.github.io/categories/Docker/Tutorial/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://chivier.github.io/tags/Docker/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://chivier.github.io/tags/Tutorial/"}]},{"title":"2112-Obsidian2Hexo","slug":"2022/2112-Obsidian2Hexo","date":"2022-01-21T18:43:21.000Z","updated":"2022-01-21T18:47:49.522Z","comments":true,"path":"2022/01/22/2022/2112-Obsidian2Hexo/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2112-Obsidian2Hexo/","excerpt":"转换功能","text":"转换功能 方便将自己的 Obsidian Markdown 转换成 Hexo Markdown。 对于转换的时候，有一些需求： 语法层面主要是：图形标签的转换工作：检索path 标签层面 时间，自动更新成当前日期 标签，自动提炼文档前的tag 链接，暂时不处理（懒，能用就行了，别管那么多） 已经完成，代码位置： https://github.com/Chivier/H2O2H 反向翻译之后有时间再做吧","categories":[{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/categories/Compiler/"},{"name":"Translator","slug":"Compiler/Translator","permalink":"https://chivier.github.io/categories/Compiler/Translator/"}],"tags":[{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/tags/Compiler/"},{"name":"Translator","slug":"Translator","permalink":"https://chivier.github.io/tags/Translator/"}]},{"title":"2112-系统重装","slug":"2022/2112-系统重装","date":"2022-01-21T18:43:10.000Z","updated":"2022-01-21T18:47:49.618Z","comments":true,"path":"2022/01/22/2022/2112-系统重装/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2112-%E7%B3%BB%E7%BB%9F%E9%87%8D%E8%A3%85/","excerpt":"系统重装笔记","text":"系统重装笔记 自从更换了新电脑之后，用了接近一年的windows11，但是在工作的时候发现了诸多问题。首先，从回顾我的工作流程开始： 开机 打开wsl 进入Projects目录，使用vscode编程 除此之外，windows对于我所有的用途为： 浏览器看网页 outlook查看邮件 Office做ppt 那么问题又来了，一般的展示我不会使用ppt，在使用obsidian之后我就更不用Office系列了，唯一需要Office的功能是Publisher。而且长期使用wsl给我的16G内存带来了巨大负担。此外还有WSL GUI的UI风格不统一、Windows11的宋体任务栏等诸多问题让我最终还是回归了熟悉的Linux系统。 在这一次装机的大部分流程和之前的Rebuild My Home基本一致，但是部分由于系统更新导致了一些可能存在的问题，在这里予以记录。 1. 输入法现在的Linux下，输入法名称不再是 SogouPinyin， 搜狗官方予以的支持也非常不完善。要不是因为我长期使用小鹤双拼，我已经专用百度输入法了。 这里使用麒麟Ubuntu的源，直接安装里面配置好的sogou pinyin即可： 123curl -sL &#x27;https://keyserver.ubuntu.com/pks/lookup?&amp;op=get&amp;search=0x73BC8FBCF5DE40C6ADFCFFFA9C949F2093F565FF&#x27; | sudo apt-key addsudo apt-add-repository &#x27;deb http://archive.ubuntukylin.com/ukui focal main&#x27;sudo apt upgrade 之后直接安装即可。 1sudo apt install sogouimebs 最后在语言选项中，和之前一样的方法修改成fcitx如果输入经常卡主，可能使ibus和fcitx5的冲突导致，可以用卸载ibus的方式解决。不过方法比较激进，慎重操作。 2. Wechat &amp; TIM这里使用一种偷懒的方法进行安装。直接使用deepin-wine的源进行安装： 1wget -O- https://deepin-wine.i-m.dev/setup.sh | sh 之后使用命令安装： 1sudo apt-get install com.qq.weixin.deepin 即可。 顺带一提，这种方法还可以安装一些其他软件： Software Package Name Wechat com.qq.weicin.deepin QQ com.qq.im.deepin TIM com.qq.office.deepin QQ Music com.qq.music.deepin 爱奇艺 com.iqiyi.deepin 此外，Wine Tray 的处理方法是使用Gnome Extensions的Topicon 3. UtoolsUtools可以替代部分Albert之前的内容。随软件发展，尽管Utools没有和Linux适配的检索软件，但是大量好用的插件可以弥补不足。主要的常用功能有： 软件启动器 剪贴板 取色器 翻译 因为Linux没有和Windows一样好用的检索软件，这里提供一个参考，使用catfish进行GUI检索，locate 和 fzf 配合使用完成命令行检索。 4. NeovimNeovim中配置Coc.nvim，之后安装插件会比之前vim更简单。这里仅作为参考，不是所有人都能很好的适应vim。此外我个人vim也并未进行过多配置。核心插件只有tabnine。 5. 触控板这里在LG gram 16的笔记本上翻车了，触控板驱动可以使用，但是和系统并未配置好。手势和操作不能很好的使用。 这里使用fusuma进行触控板改写。损失了一定的流畅度，但是总体而言，效果还是可用的。特别是定制了4指工作区切换之后，系统变得更加舒适。 6. 字体和colorls为了更舒适的写程序和文档，一个好的字体是必不可少的一个部分。这里我使用两款字体：Source Code Pro 和 Sauce Code Pro 其中，后者是在前者的基础上添加了一些符号。主要用途是配合colorls使用。这样命令行的观感更舒适，而且可以更清楚的识别文件的类型。 例如： 7. 工作同步这里的工作同步使用了两套系统共同进行维护，一套是Microsoft Onedrive，另一套是自己的群辉smb+ftp双接口。 首先说说Onedrive，Onedrive在Windows下确实是非常完美的解决方案。但是在Linux下没有很好的适配版本。有一个貌似可用的软件叫Onedriver，但是性能堪忧。最终选择微软为Linux适配的命令行Onedrive工具进行调试。 教程： https://github.com/abraunegg/onedrive 项目配套了SharePoint的教程。 如果资金尚可，Insync其实也是一个非常好的选择。 8. 需要额外注意的小Tip这里需要提醒一下使用snap安装软件的局限性。snap安装的软件非常类似wine或者说是docker的模式，将足够多的包和基础设施进行独立封装。这就导致了snap安装的软件是一种类似虚拟机的模式运行的，能够访问的目录和软件权限都有和wine一样的问题。这也就是为什么snap中软件浏览文件的模式非常奇特，和系统默认软件安装的效果截然不同。 所以snap只适合安装： 游戏 小工具 使用方法非常独立的软件 网络工具 这里我只有这些软件使用snap安装： telegram 聊天软件怎么装都差不多 ao 给予electron的Microsoft Todo lepton Gist的管理工具 p7zip 7zip的桌面端 drawio 简单的画图工具 这些工具使用snap安装非常便捷，而且使用相对独立，和其他编程工具、办公软件交互其实不太多。","categories":[{"name":"linux","slug":"linux","permalink":"https://chivier.github.io/categories/linux/"},{"name":"ubuntu","slug":"linux/ubuntu","permalink":"https://chivier.github.io/categories/linux/ubuntu/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://chivier.github.io/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://chivier.github.io/tags/ubuntu/"}]},{"title":"2201-ICS课程总结","slug":"2022/2201-ICS课程总结","date":"2022-01-21T18:43:02.000Z","updated":"2022-01-21T18:47:49.746Z","comments":true,"path":"2022/01/22/2022/2201-ICS课程总结/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2201-ICS%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/","excerpt":"ICS课程总结","text":"ICS课程总结 在2021年的最后，我对之前的所有实验给出一份参考。 首先先介绍各个实验的设计思路： Lab0：学习git的使用，方便我们进行之后的实验 Lab1：使用LC3实现乘法，加深对补码的理解；拓展实现思路是竖式乘法，其中蕴含了“对数复杂度求解问题”的思想，以此拓展介绍其他算法。 Lab2：递推方法的实现，让大家熟悉如何分配寄存器。这个流程在之后的工作中也会经常使用。例如使用尽量少的变量达到减少空间的目的，或者合理设计数据拷贝传递，达到减少复制数据的效果。 Lab3：实现代码的优化，这里实现方案有三种： 找规律，数列有周期性 循环展开 打表，预先求值 Lab4：类似于逆向的过程，第一个题可以读代码，理解递归，也可以使用枚举暴力尝试。第二个题是一个数学题，一个脑筋急转弯。 Lab5：复现代码，同奇怪的方法进行实验，这里只要求功能上实现。由于只是功能上实现，大家自由发挥。当然，最适合LC3实现素数判定的算法是筛法。 Lab6：想让大家秀一秀，“甚至可以有诡异的方法实现编程”（我们之前的习题课学习过Makefile，你甚至可以用Make和CMake实现）。 LabA：实现汇编器，学习Makefile的使用。学习使用C++的STL。 LabS：实现模拟器，学习CMake的使用，LibBoost的使用。学习下载、安装、和使用第三方库。面向对象编程的入门。 在下面的讲义中将给出所有实验原始执行方案，因为各种原因没有被执行，仅供学习试用。 Lab 0使用git进行工作管理其实是非常方便的。在日常工作管理的时候，使用git可以带来很多便利。因为日常经常有如下需求： 我想把这个程序改一下接口，给另一给程序使用。 程序有一部分功能是完善的，但是有另一部分功能不可用，需要进行大规模debug。 我要和同学开黑写代码。 这种需求不可避免要用git。这里补充一些其他工具，在这里只列一些我常用的工具。 gitg：一个便捷的可视化工具，轻量免费 在vscode里安装git插件也是非常好的选择，我日常都是这么使用的以至于我对很多git操作其实并不熟练。 Lab 1实验思路这是一个使用 LC3 指令复现乘法的实验，首先理解问题非常重要：什么是乘法 The multiplication of whole numbers may be thought of as repeated addition; that is, the multiplication of two numbers is equivalent to adding as many copies of one of them, the multiplicand, as the quantity of the other one, the multiplier. Both numbers can be referred to as factors. 这句话看起来像是一个废话，但是包含了本次试验最基本的算法：使用加法累加完成。但是如果是负数次或者0次，改定义需要拓展。对应的，程序可能需要写分支进行处理。但是这个不是这次试验的本意。 但是众所周知，LC3的机器使用补码对数字进行存储。这里需要对补码进行更加深入的认识（下面为了方便使用8位补码举例）： $$-2 = (11111110)_2$$ 但是如果换一种理解，我们可以认为： $$(11111110)2 = (100000000)_2 - (10)_2 = 256{10} - 2_{10}$$ 那么一个数字Num的补码等价于： $$2^{totalbits} + Num$$ LC3中我们使用的是16位二进制，这里我们使用 $M$ 表示 $2^{totalbits}$ 。 如果使用乘法计算 $(a \\times b) ; mod ; M$ ，相当于： $$a \\times b ; mod ; M = (M + a) \\times (M + b) ; mod ; M$$ 也就是说： 我们可以无视补码条件，直接暴力进行加法 即使其中一个数$x$是负数，我们也可以将它视作$(M+x)$的形式，暴力处理 那么 L 版本的代码就得到了： 1230001 111 111 0 00 0000001 001 001 1 111110000 101 111111101 那么如果需要考虑性能呢？ 我们会用另一种我们在小学三年级的时候用过的算法进行实现，下面举一个例子： 1234567891011 1 0 1 1 1 * 1 1 0 1 0 ────────────── 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1─────────────────────... 在列出结果之前，相比大家已经知道做法了，就是采用位移和加法的形式对数值进行相加。 下面是一个参考程序，为了方便阅读，先给出了实验的汇编形式： 12345678910ADD R3, R3, #1ADD R5, R5, #8ADD R5, R5, #8LOOP AND R6, R3, R1 BRZ NEXT ADD R7, R7, R0NEXT ADD R3, R3, R3 ; R3 &lt;&lt;&#x3D; 1 ADD R0, R0, R0 ; R0 &lt;&lt;&#x3D; 1 ADD R5, R5, #-1 ; R5 -&#x3D; 1 BRP LOOP 123456789100001011011100001000110110110100000011011011010000101110011000000000001000000000100011111110000010001011011000011000100100100000100011011011111110000001111111001 但是这依旧不是最好的方案，显然，可以采用“循环展开”再次优化。在Lab3的分析中我将给出详细介绍。 第一次试验看似非常简单，但是蕴含了一个重要的思想：如果操作$2^x$次操作$A$可以被操作$B$替代，那么我们可以将算法进行指数级别化简。下面介绍两个类似的应用。 应用1：快速幂算法计算$a^b ; mod ; c$。 一个简单的思路是采用我们上面L版本程序的思路：循环进行乘法 12345678int calc(int a, int b, int c) &#123; int ans = 1; int i; for (i = 0; i &lt; b; ++i) &#123; ans = ans * a % c; &#125; return ans;&#125; 而一个优化版本的方法和P版本程序思路一致： 我们计算并且记录 $a^1,a^2,a^4,a^8…$ 选出上述对应的指数相加，因为$a^p \\times a^q = a ^ {p + q}$。所以这里求幂的方法和之前求加法的思路一致 123456789101112int calc(int a, int b, int c) &#123; int ans = 1; int t = a; while (b) &#123; if (b &amp; 1) &#123; ans = ans * t % c; &#125; b &gt;&gt;= 1; t = t * t % c; &#125; return ans;&#125; 应用2：递推公式求解对于递推公式，例如： $$f(n) = a_{n-1}f(n-1) + a_{n-2}f(n-2) + a_{n-3}f(n-3) + … + a_{n-k}f(n-k)$$ 我们可以采用求解特征方程（组）的方法对其进行求解，得到一个时间复杂度为$O(1)$的算法。但是这样会有精度问题，举一个最简单的例子，对于一般的Fibonacci数列进行求解。 $$f(1) = 1 \\f(2) = 1 \\f(n) = f(n-1) + f(n-2)$$ 容易得到通项公式为： $$f(n) = \\frac{1}{\\sqrt{5}} ((\\frac{1+\\sqrt{5}}{2})^{n} - (\\frac{1-\\sqrt{5}}{2})^{n})$$ 但是求数值的时候一定会有精度损失，特别是当n特别大的时候精度会被放大，具体原理大家学习浮点数表示方法的时候应该有所体会。所以大部分时候，我们都不会用这种方法进行计算，而是采用一个类似于应用一的方法。 $${\\displaystyle {f(n+2) \\choose f(n+1)}={\\begin{pmatrix}1&amp;1\\1&amp;0\\end{pmatrix}}{f(n+1) \\choose f(n)}}$$ 我们将递推公式写成矩阵形式，这样不难看出我们求下一项的方法其实是以此乘法计算。那么我们复用上一个应用的算法，得到： $${\\displaystyle {f(n) \\choose f(n-1)}={\\begin{pmatrix}1&amp;1\\1&amp;0\\end{pmatrix}}^n{f(1) \\choose f(0)}}$$ 计算一个矩阵的幂我们采用类似的方法进行计算即可。 原始方案采用和平均代码指令数，平均执行指令数的比值作为成绩。而且仅有本次实验占比的20%。这种评分方法参考清华大学的并行编程课程，我个人也非常赞同这种方案，可以看出同学之间水平的差异，也方便评分，不至于到期末的时候大家都被教务处把分数弄得一团糟。既然这一部分因为某些原因被取消，那么大家基本都是满分了，这次实验就变得异常简单。大家都快乐的完成了实验。 Lab 2 &amp; 3实验思路这两次的实验是计算一个递推关系： F(0) = 1 F(1) = 1 F(2) = 2 F(n) = (F(n-1) + 2 * F(n-3)) mod 1024 (1 &lt;= n &lt;= 16384) 这里如果我们使用递归方法进行编程，那么将会耗费大量的时间，所以我们采用递推方法进行编程。同时采用类似于流水的设计方案。 参考代码如下： 12345678910111213141516171819202122.ORIG x3000LD R5, MODNUMBERADD R1, R1, #1ADD R2, R2, #1 ;F[1] &#x3D; 1ADD R3, R3, #2 ;F[2] &#x3D; 2ADD R4, R3, #0LOOP ADD R4, R4, R1 ;F[N] &#x3D; F[N - 1] + F[N - 3] ADD R4, R4, R1 ;F[N] &#x3D; 2 * F[N - 1] + F[N - 3] AND R4, R4, R5 ;F[N] &#x3D; (2 * F[N - 1] + F[N - 3]) mod 1024 ADD R1, R2, #0 ADD R2, R3, #0 ADD R3, R4, #0 ADD R0, R0, #-1 ;N--BRNP LOOPADD R7, R1, #0HALTMODNUMBER .FILL #1023NUMBERA .FILL #0NUMBERB .FILL #0NUMBERC .FILL #0NUMBERD .FILL #0.END 程序性能的评估方法在这里为大家进行介绍，很多同学不会统计自己程序的时间。但是这一个部分的工作其实非常简单，而且方法非常多样，这里只介绍一种作为参考。例如上面的程序如果我要进行评测指令条数，最简单的方法是用一个“同构的程序”进行计算。 例如： 1234567891011121314int count = 0;r5 = 1023;count++;r1 = 1;count++;r2 = 1;count++;r3 = 2;count++;r4 = 0;count++;loop: r4 = r4 + r1;count++;... 每一条指令之后我都进行一个count自增操作，最后输出count即可。（所以建议使用有goto语句的语言进行同构程序评测，否则需要手动转换成while/for循环） 对于实验3的优化其实也非常简单，一个直观的思路是采取循环展开进行优化。我们举一个具体的例子进行理解。 下面有两个循环： 12345678910111213/// Loop Afor (i = 0; i &lt; 10; i++) &#123; f[i] = g[i] * 2; g[i] = h[i] - 2;&#125;/// Loop Bfor (i = 0; i &lt; 10; i += 2) &#123; f[i] = g[i] * 2; g[i] = h[i] - 2; f[i + 1] = g[i + 1] * 2; g[i + 1] = h[i + 1] - 2;&#125; 这两个循环是否一样呢？他们看起来都计算了f的10项和g数组的10项，但是两个循环的指令数目不同。原因在于对于i的操作的数目不同。我们将两个循环完整的展开： Loop A: 1234567f[i] = g[i] * 2;g[i] = h[i] - 2;i++;f[i] = g[i] * 2;g[i] = h[i] - 2;i++;... Loop B: 123456f[i] = g[i] * 2;g[i] = h[i] - 2;f[i + 1] = g[i + 1] * 2;g[i + 1] = h[i + 1] - 2;i += 2;... 同样计算两项，前者用了6条指令，后者只有5条。 对于lab3的数据的设计我也采用了一个直观的方法：只评测10项，这10项我都是4的倍数，那么可以使用四次展开的方法进行优化。 但是这是否达到最优了呢？ 对于特定的数据，这显然不是最优的，我们可以打表得到答案。对于一般数据，我们不难发现，这个数列其实是周期性的。所以一个能得到正常运行结果的方案是： 对于一个周期内的数据打表，周期之外的利用减法，然后输出。 原始设计方案Lab2：使用最少寄存器进行编程（R0和R7作为输入和输出不算在内），使用5个寄存器，如果超出限制则会扣除10%的分数。使用最少指令数进行编程进行评分。 Lab3：递推的范围，公式变为 F(n) = (F(n-1) + 2 * F(n-3)) mod 1024 (1 &lt;= n &lt;= 65536) 但是出于某种原因，此部分评分被移除，大家都非常愉快的完成了这两次实验。 Lab 4实验思路对于这次实验，其实是一个娱乐性质的游戏。我们先从第一个部分分析。 第一个部分的代码，我们给出的分析模式非常简单，只有4位需要补充。最简单的方法是进行16次枚举，配合LC3 Tool完成实验。其实希望通过这一个部分的实验收取大家的脚本，看看大家都用了什么自动化的方法和工具。 这一个部分希望借助这个代码帮大家理解递归程序的思想，原始汇编如下： 12345678910111213141516171819.ORIG x3000LEA R2,Stack ; R2 is StackAND R0,R0,#0 ; Foo called?Main JSR FooHALTFoo STR R7,R2,#0 ; Store R7 to stackADD R2,R2,#1 ; Increment stackADD R0,R0,#1 ; Called Foo!LD R1,Counter ; Decrement CounterADD R1,R1,#-1ST R1,CounterBRz After ; After N times,RETJSR Foo ; Otherwise, recurAfter ADD R2,R2,#-1 ; Decrement stackLDR R7,R2,#0RETStack .BLKW #10Counter .FILL #5.END 机器码如下： 123456789101112131415161718192021222324252611100100000011100101000000100000010010000000000111110000001001010111111010000000000101001010000100010000001000010010001000010001000100100111111100110010000011110000010000000001010011111111100000010100101111110110111010000000110000011100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000101 第二个部分的程序我这边进行了一些提示，程序是希望对7计算余数，但是有一个部分是对8计算除法，我们计算$x$对7的余数时，不妨换一个表达方法，让$x = 8k + r$其中$0 \\le r &lt; 8$$$x ; mod ; 7 = (8k + r) ; mod ; 7 = (k + r) ; mod ; 7$$有了这个提示，这个程序也就不难了，除8是通过位移进行的，对8取余数是通过AND进行计算的。 原始汇编如下： 1234567891011121314151617181920212223.ORIG x3000LOOPM JSR DIV8AND R2, R1, #7ADD R1, R2, R4ADD R0, R1, #-7BRP LOOPMADD R0, R1, #-7BRN STOPADD R1, R1, #-7STOP HALTDIV8 AND R2, R2, #0 ; R1 &#x2F; 8 -&gt; R4AND R3, R3, #0AND R4, R4, #0ADD R2, R2, #1ADD R3, R3, #8LOOP AND R5, R3, R1BRZ NEXTADD R4, R2, R4NEXT ADD R2, R2, R2ADD R3, R3, R3BRP LOOPRET.END 原始设计每个人拿到的程序都是不同的，是对16位bit进行随机反转得到的（不告诉你哪16位有错误）。鉴于实验难度过大，以及教务处提倡位更多同学减轻实验负担，这个部分已经被删除。于是大家都轻松愉快的完成了实验。 Lab 5这一部分的实验显然大部分同学曲解了我的本意，实验本意是：functionally复现，也就是说我只要你判断素数即可，算法我不care。但是大部分同学都在楞写了乘法去余数，这里我只希望大家复习一下筛法求素数的算法：筛法素数百度百科 我依稀记得我在五年级的数学课本后的数学小天地（也可能是其他名字）里面学习过这个算法，相比这个算法不是很难，但是几乎没有同学用这个算法进行实践，因此我推荐大家复习一下小学数学课本。 这里程序不再详细写出，评测过程正在进行。 Lab 6一个不需要我评讲的实验，希望大家自己学习一下自己常用语言的时间评测工具，这种属于基本技能，相比是之后的科研工作中不可或缺的一个部分，希望大家能够掌握。 Lab A&amp;S今年第一次采用了**程序填空+提问**的方式进行检查实验。个人来看达到了比较好的实验效果，掌握了如何构建编译环境、如何编译命令行工具。这门课的重要作用之一就是在计算机学院的学习中承担承上启下的作用。掌握一些先进的开发工具和一些正确的开发方法是一个积极向上的计算机系学生的必备素养，所以这里我坚持使用C++进行实验设计。 其中有一些设计是为了大家进行更好的理解和学习，例如： 汇编器实验中存留接口，可以方便有兴趣的同学设计指令集拓展，可以自己开发更有意思的部分 模拟器实验中采用libboost，有兴趣的同学回去了解学习这个在计算机开发 深入理解“指令集”如何变成一个可以执行的模型 如果明年继续设计此部分实验，我将会进行如下设计： 设计Python的版本 完成图形界面设计 设计扩展指令集和扩展结构，例如更多的特殊功能寄存器，或者是cache 同样，今年的此部分实验也是抄袭的重灾区，框架中给出信息过多，考察重点偏向了学生对框架的理解。明年会调节比重。 原始设计除了完成实验，需要为自己的代码写文档，学习使用doxygen/Sphinx或这其他代码文档工具编写文档，介绍接口、算法、程序框架。鉴于期末需要减轻负担，这一部分已经被移除。 课程总结今年的课程设计，总体而言，我个人是非常愉快的。在实验被削弱后，我想大部分同学都轻松愉快的完成了实验。 实验和习题课，我分别教授了大家： git的使用方法 代码阅读和代码阅读辅助工具 如何在github上挑选优质项目进行学习 简单的debug技巧 简单的Markdown展示技巧 文档撰写 轻量级的多文件项目编译开发(GNU Make) CMake项目的编译 第三方库的安装和配置 环境变量编辑 论文阅读和整理 相关文献查询 搜索引擎的使用 我希望能尽自己微薄之力，为中国科学技术大学的本科生教育提升水平和质量，希望同学们在有限的时间内学习更多的内容。如果您是其中一位按照要求完成所有实验的同学，我希望你能有所收获，并且在一个学期的挣扎和努力中，对于系统运维，软件安装，环境配置都有了自己的品味和理解。在这个学期的努力下，很多同学学会了如何使用搜索引擎，这一点并不是开玩笑，很多时候“如何精确的描述自己的问题”比解决问题往往更加重要。对此我个人深感欣慰。这门课程在计算机学院的学习中，承担了承上启下的重要作用。我希望在这门课程里，大家对计算机科学有了一个更底层，更深刻的认识。如果大家之后在其他课程的学习遇到困难也欢迎随时和我联系。 我个人也是一位就读于安老师实验室的研究生，个人能力有限，精力有限，脾气有时候也有点急躁。这个学期感谢大家参与我设计的折磨人的实验，感谢大家这个学期对我的包容和支持。 鉴于今年的教学情况，我个人对我自己进行批评和反省，并提出以下改进方案： 大作业提供Python版本，不是每一个同学都想学习C++，也不是每一个同学都需要会配环境 降低实验难度和评分要求，以更多的同学可以满分为目标设计实验 增加答疑时长，明年我研究生课程将结束，所以可以更多的时间为同学服务，同时我会改正自己不耐烦的坏毛病 对于实验补测和补交放宽条件，最好设计自动评测在线工具，方便更多的同学能随时随地检查自己实验的正确性","categories":[{"name":"ICS","slug":"ICS","permalink":"https://chivier.github.io/categories/ICS/"},{"name":"TA","slug":"ICS/TA","permalink":"https://chivier.github.io/categories/ICS/TA/"}],"tags":[{"name":"TA","slug":"TA","permalink":"https://chivier.github.io/tags/TA/"},{"name":"ICS","slug":"ICS","permalink":"https://chivier.github.io/tags/ICS/"}]},{"title":"2201-布谷计划","slug":"2022/2201-布谷计划","date":"2022-01-21T18:42:53.000Z","updated":"2022-01-21T18:47:49.842Z","comments":true,"path":"2022/01/22/2022/2201-布谷计划/","link":"","permalink":"https://chivier.github.io/2022/01/22/2022/2201-%E5%B8%83%E8%B0%B7%E8%AE%A1%E5%88%92/","excerpt":"好吧，从2022年开始，我计划将自己变成一个不咕的人。为了实行这个计划，我觉得还是有必要用自己的博客督促一下自己。那么我的博客重新更新开始，但是在更新之前，我发现我过去一年其实写了很多文章和报告。","text":"好吧，从2022年开始，我计划将自己变成一个不咕的人。为了实行这个计划，我觉得还是有必要用自己的博客督促一下自己。那么我的博客重新更新开始，但是在更新之前，我发现我过去一年其实写了很多文章和报告。 不过…… Hexo的格式僵硬，我日常一般用更利于同步的obsidian和notion。为了更好的解决这个问题，我个人觉得使用一个翻译器比我手动改更好一些。 在编写之前，我个人预想了一些设计理念，最终选定了Python编写（主要是便捷）。但是我一般使用python只是作为脚本类小工具编写，这里我需要做一个好用一点的命令行工具，最好用pypi进行打包。那么我们开始。 Pypi首先进行比较，我在使用pypi的setup.py前后，我对自己的程序需要进行什么改动？ 简而言之，我自己对自己的程序进行了参数翻新。使得我们的程序可以进行更好的参数解析。如果使用 sys.argv 可能会有无法正确解析的问题，它更适合用来写小脚本，而不是功能复杂的命令行工具。argparse这里有一篇短文非常适合速成学习： Python-argparse 至于 setup.py 由于我是自用，所以我就快点搞搞得了，直接简单粗暴搞出来： 12345678910111213setup( name=&quot;o2h&quot;, version=&quot;0.1.0&quot;, author=&quot;Chivier Humber&quot;, entry_points=&#123; &quot;console_scripts&quot;: [&quot;obs2hexo=o2h.o2h:o2h&quot;], &#125;, license=&quot;MIT&quot;, keywords=&quot;translator&quot;, packages=find_packages(),) 复杂的功能并没有补充，这里介绍两项： entry_points： 用来制定命令行工具，格式为 [执行命令]=‘模块名’.&#39;文件名&#39;:&#39;函数名&#39;。我的例子写的不好，可以参考 StackOverflow pypi。官方教程也有更完善的信息。 packages： 使用自动检索功能即可 这样我就完成了一个翻译器的快速制作。","categories":[{"name":"Work","slug":"Work","permalink":"https://chivier.github.io/categories/Work/"},{"name":"UI","slug":"Work/UI","permalink":"https://chivier.github.io/categories/Work/UI/"}],"tags":[{"name":"Work","slug":"Work","permalink":"https://chivier.github.io/tags/Work/"},{"name":"UI","slug":"UI","permalink":"https://chivier.github.io/tags/UI/"}]},{"title":"2110-LLVM整理","slug":"2022/2110-LLVM整理","date":"2021-11-04T16:42:39.000Z","updated":"2022-01-21T18:47:48.294Z","comments":true,"path":"2021/11/05/2022/2110-LLVM整理/","link":"","permalink":"https://chivier.github.io/2021/11/05/2022/2110-LLVM%E6%95%B4%E7%90%86/","excerpt":"前言","text":"前言 这里首先先说明我整理次文档的目的，LLVM是我日常工作学习中最常用的工具，小到用C++写一个demo，大到做自带代码优化和代码分析，可以说我的日常工作学习离不开LLVM的Toolchains，在这里，我将自己对LLVM的见解和认识在这里做一个系统的整理和介绍。 这里我基于 LLVM 12 版本进行介绍，参考了一些 LLVM 的相关总结资料和书籍，结合官方文档，进行如下总结。 使用系统环境 ## 编译 LLVM 项目 简单来说步骤如下： 12345git clone https://github.com/llvm/llvm-project.gitgit checkout -b llvmorg-12.0.0cd llvm-projectmkdir buildcmake –G Ninja -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR -DLLVM_ENABLE_PROJECTS=clang ../llvm 对于cmake项目的一般编译方法如此，这里需要对一些选项补充说明： LLVM_TARGETS_TO_BUILD： LLVM的目标平台，例如：AArch64, AMDGPU, ARM, BPF, Hexagon, Lanai, Mips, MSP430, NVPTX, PowerPC, RISCV, Sparc, SystemZ, WebAssembly, X86。默认和目前所在机器一致。 LLVM_ENABLE_PROJECTS： LLVM可以包含的组件，一般编译只加上clang，所有的组件为：clang, clang-tools-extra, compiler-rt, debuginfo-tests, lib, libclc, libcxx, libcxxabi, libunwind, lld, lldb, llgo, mlir, openmp, parallel-libs, polly, pstl。 LLVM_ENABLE_ASSERTIONS： Assertion check，非必要，但是可以加上。 LLVM_ENABLE_THREADS: 线程库，例如Pthreads，一般会考虑加上。 LLVM_ENABLE_WARNINGS: 如果可能，编译LLVM不应生成警告消息。因此，默认情况下会打开打印警告消息的选项。要将其关闭，必须指定–DLLVM_ENABLE_WARNINGS=off。 LLVM_OPTIMIZED_TABLEGEN: 通常，tablegen 工具使用与 LLVM 其他部分相同的选项构建。 同时使用tablegen生成大部分代码生成器。 因此，tablegen 在调试版本中要慢得多，从而显着增加了编译时间。 如果此选项设置为 ON，则在启用优化的情况下编译 tablegen，即使对于调试版本，也可能减少编译时间。 默认为关闭。 要启用此功能，您必须指定 –DLLVM_OPTIMIZED_TABLEGEN=ON。 上述选项可以自行根据需求安装，更详细的编译选项说明见官方文档： Building LLVM with CMake LLVM 代码结构在 llvm-project 目录里，有诸多子目录，这些子目录包括了项目的各个内容组件，下面将概括性介绍这些组件的内容： llvmllvm 目录存放 LLVM 项目的核心内容，即编译器后端工具。 重要组件有： llc: 静态编译器，llc 将 LLVMIR 文件作读入，输出 bitcode，特定架构汇编，或者直接输出二进制文件。 llvm-objdump, llvm-dwarfdump: 用于检查生成的对象文件，反编译工具。 llvm-ar：用于从 obj 文件整理生成归档文件。 llvm-mc：这里需要额外强调，此工具我个人使用也并不是很多，但是将来会大有用途。该工具可以是一个机器码试验场，可以方便的编译和反汇编机器码并进行微调，在新增指令时非常有用。 polly数学优化方法，位于 Polly 目录中的 Polly 项目向 LLVM 添加了另一组优化。它基于一种称为多面体模型的数学表示法。使用这种方法，可以进行复杂的优化，例如针对缓存位置优化的循环。如果有时间可以稍微阅读了解一下。 mlirMLIR 项目旨在为 LLVM 提供多级中间表示。LLVM IR 已经处于较低级别，并且源语言的某些信息在编译器中生成IR期间丢失。所以 LLVM IR 并不能作为独立的编程语言使用（虽然理论上可行，但是写起来和写汇编一样麻烦），IR 的作用是面向未来，适应多种架构的后端。对于新的架构或者硬件设备，从 IR 到机器码或者二进制文件的成本是非常低廉的。 clangclnag编译器也是llvm项目的一个重要组成部分，代码位于clang目录中。它提供了一套用于词法分析、语法分析、语义分析和从C、C++、Objtovi-C和Objul-C++源文件生成LLVM IR的库。 libclang 和相关组件基本位于 clang 中，其余一些额外的组件位于 clang-tools-extra 中。例如其中的 clang-tidy 是一个轻量级的代码整理工具。 lldlld目录主要提供连接器。编译器创建的目标文件必须与运行时库链接在一起以形成可执行文件。链接器支持 ELF、COFF、Mach-O 和 WebAssembly 格式。 lldb一个和 gdb 等价的工具。 llvm-runtimellvm 运行时环境可以由 glibc 提供，也可以用自己的组件： compiler-rt 项目提供独立于编程语言的支持库。 它包括通用功能，例如 32 位 i386 的 64 位除法、各种santinizer、fuzzing 库和 profiling 库 libunwind 提供非绑定DWARF标准数据，用于debug libcxxabi 提供 C++ 异常处理 libcxx C++标准库 libc C标准库 libclc OpenCL的运行时 小结一己之见，LLVM之所以能够得到工业界的广泛认可和推崇，一个重要的理由就是LLVM设计的普适性。举个例子，在我们自己定制前端或者对 C/C++ 做一些语言拓展的时候，我们可以复用 LLVM 的代码，而绝对不会有人使用 GNU 的代码，尽管 GNU 编译器是认可度最高，最可信的编译器设计。 使用 LLVM 相关库代码既然上一小节最后提到了 LLVM 的复用问题，这里可以使用 LLVM 做一个小小的测试作为第一个 LLVM 项目的用例。 这里举例，用一个完整的 cmake 项目说明 LLVM 整体的使用方法。 一般的项目展开，会有include放置头文件，src放置源代码和框架，lib放置我们设计的动态和静态的库。 目录树结构如下： 项目地址是：https://github.com/Chivier/llvm-test-frame 此处cmake可以直接抄走复用。个人认为之后对于DSL的开发不会脱离此模板。","categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://chivier.github.io/categories/LLVM/"},{"name":"Compiler","slug":"LLVM/Compiler","permalink":"https://chivier.github.io/categories/LLVM/Compiler/"}],"tags":[{"name":"LLVM","slug":"LLVM","permalink":"https://chivier.github.io/tags/LLVM/"},{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/tags/Compiler/"}]},{"title":"2109-Source to Source LLVM 调研","slug":"2022/2109-Source-to-Source-LLVM-调研","date":"2021-10-26T07:22:05.000Z","updated":"2022-01-21T18:47:48.138Z","comments":true,"path":"2021/10/26/2022/2109-Source-to-Source-LLVM-调研/","link":"","permalink":"https://chivier.github.io/2021/10/26/2022/2109-Source-to-Source-LLVM-%E8%B0%83%E7%A0%94/","excerpt":"翻译器调研","text":"翻译器调研 首先阅读了一些相关的科研工作 GitHub - OP-DSL/clang-op-translator: Clang-based translator for OP2 但是这里最重要的还是自己实现一个Demo并且测试 翻译器实验 clang-tool这里众说纷纭，网上并没有一个”直接可用“的版本供我进行快速测试和检查，经历了一整天的失败之后，在LLVM12.0和LLVM12.1版本上，Google搜索的几乎所有方法全部失败，因为LLVM11的API大改动导致之后的GetLocStart等clang::Stmt类里的方法更名，需要重新设计测试例子。 这里测试方案重新在 LLVM clang-extra-tools 里，基于 LLVM clang tool template 进行更改和测试。 失败记录 #1直接进行 cmake 失败，失败记录如下： 12345678910111213141516171819202122232425262728CMake Warning (dev) in CMakeLists.txt: No project() command is present. The top-level CMakeLists.txt file must contain a literal, direct call to the project() command. Add a line of code such as project(ProjectName) near the top of the file, but after cmake_minimum_required(). CMake is pretending there is a &quot;project(Project)&quot; command on the first line.This warning is for project developers. Use -Wno-dev to suppress it.CMake Error at CMakeLists.txt:6 (add_clang_executable): Unknown CMake command &quot;add_clang_executable&quot;.CMake Warning (dev) in CMakeLists.txt: No cmake_minimum_required command is present. A line of code such as cmake_minimum_required(VERSION 3.16) should be added at the top of the file. The version specified may be lower if you wish to support older CMake versions for this project. For more information run &quot;cmake --help-policy CMP0000&quot;.This warning is for project developers. Use -Wno-dev to suppress it.-- Configuring incomplete, errors occurred!See also &quot;/home/chivier/opt/llvm/clang-tools/tool-template/build/CMakeFiles/CMakeOutput.log&quot;. add_clang_executable 没有 include 合适的 .cmake 文件，所以无法使用 Unknown CMake command “add_clang_executable” 此处给出了一个不了了之的回答，并没有解决问题。之后对于LLVM的框架重新理解和思考，应该在find_package LLVM 和 libclang 入手，着手解决 LLVM 的 cmake 发现问题。 尝试用其他方法链接 LLVM 的 cmake 内容 Building LLVM example 这里只给出了解决 add_llvm_excutable 的方案，并没有解决我的问题 失败记录 #2这里尝试直接去解决LLVM的问题，直接编译 1g++ ToolTemplate.cpp -I/home/chivier/opt/llvm/llvm-download/include -std=c++14 -fno-exceptions -fno-rtti -D_GNU_SOURCE -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS `llvm-config --libs all` 这里直接采用 12llvm-config --cxxflagsllvm-config --libs all 得到llvm需要的c++编译选项和llvm需要链接选项，但是此时发现无法链接，找不到需要的链接库，报错如下： 12345678910111213/usr/bin/ld: cannot find -lLLVMMCParser/usr/bin/ld: cannot find -lLLVMMC/usr/bin/ld: cannot find -lLLVMDebugInfoCodeView/usr/bin/ld: cannot find -lLLVMDebugInfoMSF/usr/bin/ld: cannot find -lLLVMBitReader/usr/bin/ld: cannot find -lLLVMCore/usr/bin/ld: cannot find -lLLVMRemarks/usr/bin/ld: cannot find -lLLVMBitstreamReader/usr/bin/ld: cannot find -lLLVMBinaryFormat/usr/bin/ld: cannot find -lLLVMTableGen/usr/bin/ld: cannot find -lLLVMSupport/usr/bin/ld: cannot find -lLLVMDemangle... 失败记录 #3根据之前的失败经验，分析之前的错误内容，主要错误集中在：add_clang_executable 的执行可行问题。在github里对该关键词进行搜索，找到和我需求最为相似的项目：https://github.com/firolino/clang-tool.git但是编译报错还没有解决。 12345678910/home/chivier/Projects/clang-tool/src/utils/utils.cc: In function ‘bool utils::customRunToolOnCodeWithArgs(std::unique_ptr&lt;clang::FrontendAction&gt;, const llvm::Twine&amp;, const std::vector&lt;std::__cxx11::basic_string&lt;char&gt; &gt;&amp;, const llvm::Twine&amp;, const FileContentMappings&amp;)’:/home/chivier/Projects/clang-tool/src/utils/utils.cc:32:16: error: ‘class clang::tooling::ToolInvocation’ has no member named ‘mapVirtualFile’ 32 | invocation.mapVirtualFile(fileNameRef, code.toNullTerminatedStringRef(codeStorage)); | ^~~~~~~~~~~~~~/home/chivier/Projects/clang-tool/src/utils/utils.cc:35:20: error: ‘class clang::tooling::ToolInvocation’ has no member named ‘mapVirtualFile’ 35 | invocation.mapVirtualFile(filenameWithContent.first, filenameWithContent.second); | ^~~~~~~~~~~~~~make[2]: *** [src/CMakeFiles/clang-tool.dir/build.make:102: src/CMakeFiles/clang-tool.dir/utils/utils.cc.o] Error 1make[1]: *** [CMakeFiles/Makefile2:94: src/CMakeFiles/clang-tool.dir/all] Error 2make: *** [Makefile:84: all] Error 2 这里继续分析mapVirtualFile 调用 mapVirtualFile 的是一个 TollInnovation 类。这里存在一些借口不适配的问题。 成功记录在网上搜索 ToolInnovation， 在 github 上找到了一个性质类似的项目： https://github.com/firolino/clang-tool.git 此项目可以很好的完善我目前的研究，基于 clang-tool 的 CMakeLists 我写出了如下的文件： 12345678910111213141516171819202122232425262728project(LLVM_test)cmake_minimum_required(VERSION 2.8)find_package(LLVM REQUIRED)find_package(Clang REQUIRED)set(CMAKE_CXX_FLAGS &quot;-Wall -g3 -O0 -fno-rtti $&#123;LLVM_COMPILE_FLAGS&#125;&quot;)include_directories($&#123;LLVM_INCLUDE_DIRS&#125;)include_directories($&#123;CLANG_INCLUDE_DIRS&#125;)set(LLVM_LINK_COMPONENTS FrontendOpenMP Support )add_executable(tool-template ToolTemplate.cpp )target_link_libraries(tool-template PRIVATE clangAST clangASTMatchers clangBasic clangFrontend clangTooling clangToolingRefactoring ) clang tooling对于 clang tooling 的做法，需要有如下考量 调研期间发现了一个 LLVM 更好用一些的文档网站： https://docs.hdoc.io/hdoc/llvm-project/ 优势在于提供了 doxygen 中不便于搜索的麻烦，提供了搜索接口 https://docs.hdoc.io/hdoc/llvm-project/search.html LLVM 框架的整体架构是 Frontend -&gt; Optimizer -&gt; BackendFrontend = Lexer + ParserOptimizer = PassedBackend = MD Optimizer + CodeGen 分析出的 AST 树使我们前端分析的目标，但是 AST 的遍历具有一定的麻烦，我们不太可能根据 LLVM 每一代 API 的接口去设计我们的程序，这个实话需要借助 LLVM 一个相对独立的子项目，就是 clang tooling，作为 LLVM18 大会上的报告，Clang tooling 以及其代表组件 LibClang 在 “few years” 将维持稳定版本。 LibClang 的作用更想一个“光标”，用于遍历和访问每一个 AST 的 Translate Unit。 作为一个方便的接口，测试的时候可以先使用 Python 去开发和测试，便于调试。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from clang.cindex import *def is_function_call(funcdecl, c): &quot;&quot;&quot; Determine where a call-expression cursor refers to a particular function declaration &quot;&quot;&quot; defn = c.get_definition() return (defn is not None) and (defn == funcdecl)def fully_qualified(c): &quot;&quot;&quot; Retrieve a fully qualified function name (with namespaces) &quot;&quot;&quot; res = c.spelling c = c.semantic_parent while c.kind != CursorKind.TRANSLATION_UNIT: res = c.spelling + &#x27;::&#x27; + res c = c.semantic_parent return resdef find_funcs_and_calls(tu): &quot;&quot;&quot; Retrieve lists of function declarations and call expressions in a translation unit &quot;&quot;&quot; filename = tu.cursor.spelling calls = [] funcs = [] for c in tu.cursor.walk_preorder(): if c.location.file is None: pass elif c.location.file.name != filename: pass elif c.kind == CursorKind.CALL_EXPR: calls.append(c) elif c.kind == CursorKind.FUNCTION_DECL: funcs.append(c) return funcs, callsidx = Index.create()args = &#x27;-x c++ --std=c++11&#x27;.split()tu = idx.parse(&#x27;tmp.cpp&#x27;, args=args)funcs, calls = find_funcs_and_calls(tu)for f in funcs: print(fully_qualified(f), f.location) for c in calls: if is_function_call(f, c): print(&#x27;-&#x27;, c.location) print() OP2-ClangOP2 clang 项目是基于 LLVM 项目开发的。基本思想是为了适应更多更新的硬件设备，我们不应该去专门花时间在底层设计上，这些部分理应由编译器后端进行处理。更好的构建起前端到这里的框架才是一个 DSL 应该做的事情。非结构化网格是一个代表性的问题。 OP2 Clang 的主要工作是借用 Clang 将中间层 API 转移，用户不必直接去写 OP2 Library 中的 API 代码，而是用简单的逻辑说明代码的逻辑。Clang 再利用前端去实现 OP2 中的并行化。 Youtube 的视频讲解了论文的思路 https://www.youtube.com/watch?v=Ie2WjoUEnKw 设计思想重要部分是：handle significant structural transformations 其实这个工作的价值并不在于 Clang，而在于 OP2 库的并行化的易用性，那么这项工作是否真的那么容易复现呢？ 答案是肯定的，并且这里将给出一个更加简单的复现思路，如果读了之前的工作文档，那么会发现，如果使用 libclang Python API ，那么复现此工作将不再复杂，知识简单的：“模式匹配” + “代码替换” 其代码框架如下： Op2ModeScan -&gt; [generator] generator 包含如下部分：common, cuda, openmp, sequntial, vectorization 以 openmp 举例，我在下面的代码标出注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146namespace &#123;using namespace clang::ast_matchers;const auto parLoopSkeletonCompStmtMatcher = compoundStmt(hasParent(functionDecl(hasName(&quot;op_par_loop_skeleton&quot;))));&#125; // namespacenamespace OP2 &#123;using namespace clang::ast_matchers;using namespace clang;//___________________________________MATCHERS__________________________________// 下面用LLVM接口对AST的节点进行判定const StatementMatcher OMPKernelHandler::locRedVarMatcher = declStmt(containsDeclaration(0, varDecl(hasName(&quot;arg0_l&quot;))), hasParent(parLoopSkeletonCompStmtMatcher)) .bind(&quot;local_reduction_variable&quot;);const StatementMatcher OMPKernelHandler::locRedToArgMatcher = binaryOperator( hasOperatorName(&quot;=&quot;), hasRHS(ignoringImpCasts(declRefExpr(to(varDecl(hasName(&quot;arg0_l&quot;)))))), hasParent(parLoopSkeletonCompStmtMatcher)) .bind(&quot;loc_red_to_arg_assignment&quot;);const StatementMatcher OMPKernelHandler::ompParForMatcher = ompParallelForDirective().bind( &quot;ompParForDir&quot;); // FIXME check if it is in the main file.//_________________________________CONSTRUCTORS________________________________OMPKernelHandler::OMPKernelHandler( std::map&lt;std::string, clang::tooling::Replacements&gt; *Replace, const ParLoop &amp;loop) : Replace(Replace), loop(loop) &#123;&#125;//________________________________GLOBAL_HANDLER_______________________________void OMPKernelHandler::run(const MatchFinder::MatchResult &amp;Result) &#123; if (!lineReplHandler&lt;DeclStmt, 1&gt;( Result, Replace, &quot;local_reduction_variable&quot;, std::bind(&amp;OMPKernelHandler::handleRedLocalVarDecl, this))) return; if (!HANDLER(CallExpr, 2, &quot;func_call&quot;, OMPKernelHandler::handleFuncCall)) return; // if successfully handled return if (!lineReplHandler&lt;BinaryOperator, 7&gt;( Result, Replace, &quot;loc_red_to_arg_assignment&quot;, std::bind(&amp;OMPKernelHandler::handlelocRedToArgAssignment, this))) return; // if successfully handled return if (!HANDLER(OMPParallelForDirective, 0, &quot;ompParForDir&quot;, OMPKernelHandler::handleOMPParLoop)) &#123; return; &#125;&#125;//___________________________________HANDLERS__________________________________std::string OMPKernelHandler::handleFuncCall() &#123; std::string funcCall = &quot;&quot;; llvm::raw_string_ostream ss(funcCall); ss &lt;&lt; loop.getUserFuncInfo().funcName &lt;&lt; &quot;(&quot;; for (size_t i = 0; i &lt; loop.getNumArgs(); ++i) &#123; if (!loop.getArg(i).isReduction()) &#123; if (loop.getArg(i).isDirect()) &#123; ss &lt;&lt; loop.getArg(i).getArgCall(i, &quot;n&quot;); &#125; else &#123; ss &lt;&lt; loop.getArg(i).getArgCall( loop.dat2argIdxs[loop.dataIdxs[i]], (&quot;map&quot; + std::to_string(loop.mapIdxs[i]) + &quot;idx&quot;)); &#125; ss &lt;&lt; &quot;,&quot;; &#125; else &#123; ss &lt;&lt; &quot;&amp;arg&quot; &lt;&lt; i &lt;&lt; &quot;_l,&quot;; &#125; &#125; ss.str(); return funcCall.substr(0, funcCall.length() - 1) + &quot;);&quot;;&#125;std::string OMPKernelHandler::handleRedLocalVarDecl() &#123; std::string s; llvm::raw_string_ostream os(s); for (size_t ind = 0; ind &lt; loop.getNumArgs(); ++ind) &#123; const OPArg &amp;arg = loop.getArg(ind); if (arg.isReduction()) &#123; os &lt;&lt; arg.type &lt;&lt; &quot; arg&quot; &lt;&lt; ind &lt;&lt; &quot;_l = *(&quot; + arg.type + &quot; *)arg&quot; &lt;&lt; ind &lt;&lt; &quot;.data;\\n&quot;; &#125; &#125; return os.str();&#125;std::string OMPKernelHandler::handlelocRedToArgAssignment() &#123; std::string s; llvm::raw_string_ostream os(s); for (size_t ind = 0; ind &lt; loop.getNumArgs(); ++ind) &#123; const OPArg &amp;arg = loop.getArg(ind); if (arg.isReduction()) &#123; os &lt;&lt; &quot;*((&quot; + arg.type + &quot; *)arg&quot; &lt;&lt; ind &lt;&lt; &quot;.data) = arg&quot; &lt;&lt; ind &lt;&lt; &quot;_l;\\n&quot;; &#125; &#125; return os.str();&#125;std::string OMPKernelHandler::handleOMPParLoop() &#123; std::string plusReds, minReds, maxReds; llvm::raw_string_ostream os(plusReds); llvm::raw_string_ostream osMin(minReds); llvm::raw_string_ostream osMax(maxReds); // 计算可用资源 for (size_t ind = 0; ind &lt; loop.getNumArgs(); ++ind) &#123; const OPArg &amp;arg = loop.getArg(ind); if (arg.isReduction()) &#123; switch (arg.accs) &#123; case OP2::OP_INC: os &lt;&lt; &quot;arg&quot; &lt;&lt; ind &lt;&lt; &quot;_l, &quot;; break; case OP2::OP_MAX: osMax &lt;&lt; &quot;arg&quot; &lt;&lt; ind &lt;&lt; &quot;_l, &quot;; break; case OP2::OP_MIN: osMin &lt;&lt; &quot;arg&quot; &lt;&lt; ind &lt;&lt; &quot;_l, &quot;; break; default: // error if this is a reduction it must be one of OP_MIN, OP_MAX or // OP_INC assert(!arg.isReduction() || (arg.accs == OP2::OP_INC || arg.accs == OP2::OP_MAX || arg.accs == OP2::OP_MIN)); &#125; &#125; &#125; // 生成 omp 宏语句 if (os.str().length() &gt; 0) &#123; plusReds = &quot; reduction(+:&quot; + plusReds.substr(0, plusReds.length() - 2) + &quot;)&quot;; &#125; if (osMin.str().length() &gt; 0) &#123; minReds = &quot; reduction(min:&quot; + minReds.substr(0, minReds.length() - 2) + &quot;)&quot;; &#125; if (osMax.str().length() &gt; 0) &#123; maxReds = &quot; reduction(max:&quot; + maxReds.substr(0, maxReds.length() - 2) + &quot;)&quot;; &#125; return &quot;omp parallel for &quot; + plusReds + &quot; &quot; + minReds + &quot; &quot; + maxReds;&#125;&#125; // namespace OP2 这项工作本质上难度不大，对于之后工作的意义在于： 网格划分部分的代码其实可以根据群论提供的对称性思想进行划分和生成。我们只需要简单描述网格方法，之后就可以生成那一部分的代码，并且自动将 OpenMP 的部分自动植入。 正在测试的例子： 生成一个3维网格，每个格子里有10个点，之后会自由扩散。目前编码方法为自然编码，按长宽高依次顺次编号。 总结本周工作： 总结 OP2 Clang，学习项目框架，自己基本复现。 总结 LLVM Clang Tooling 工作框架，于 github: Chivier/still 总结 LLVM Python Clang API，分析 Translation Unit 的行为，编写函数调用 demo 见 github: Chivier/still 学习文档工具 hdoc 继续完善 3D 绘图库，目前可以完成自动生成任意亏格小于2的管状模型 编译 LLVM 12，13，14 的文档，对比 LLVM Clang 接口 Sourcetrail 分析 Python Clang API 之后工作计划： 完善算例，将该算例发展成为网格Benchmark 基于改 Benchmark 测试自动 OpenMP 并行化方案的可行性 自动优化工具测试 SPH 原版代码","categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://chivier.github.io/categories/LLVM/"},{"name":"DSL","slug":"LLVM/DSL","permalink":"https://chivier.github.io/categories/LLVM/DSL/"}],"tags":[{"name":"LLVM","slug":"LLVM","permalink":"https://chivier.github.io/tags/LLVM/"},{"name":"DSL","slug":"DSL","permalink":"https://chivier.github.io/tags/DSL/"}]},{"title":"New Laptop","slug":"2021/NewLaptop","date":"2021-03-25T01:11:08.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2021/03/25/2021/NewLaptop/","link":"","permalink":"https://chivier.github.io/2021/03/25/2021/NewLaptop/","excerpt":"Step 0: Before All2021年2月23日，我拿到了自己的新电脑，LG Gram 2021 16寸电脑。在这里记录我对电脑的配置过程和一些使用体验。","text":"Step 0: Before All2021年2月23日，我拿到了自己的新电脑，LG Gram 2021 16寸电脑。在这里记录我对电脑的配置过程和一些使用体验。 Step 0.1: Reinstall Windows在一切的一切之前，我先重新安装了系统。Windows家庭版缺少组策略和磁盘安全管理的功能，对我而言使用不是那么理想。所以在这里先重新安装了一些。不过这个时候问题已经出来了，重新安装Windows之后，由于驱动也被一并卸载了，所以需要重新安装。 百度lggram贴吧已经给出了一个解决方案： https://tieba.baidu.com/p/7239910408 可以在这里下载LG Control Center 当然，也可以在LG官网的驱动支持里找到需要的内容。 Step 0.2: Windows Insider为了使用一些特殊的功能需求，在这里我加入了Windows Insider计划，不过为了笔记本的稳定和安全，我这台电脑加入的是Beta测试。同时用学校的KMS激活了一下我的Windows Pro。 Step 0.3: Network网络相关的配置是一切工作最重要的一个部分之一了。包含了下面这些工作： 安装Clash for Windows，启用代理 安装Chrome Browser，启用Google的系列服务，包括我的密码、收藏夹、插件 找到之前的笔记本的SSH密钥对，放在用户目录下 Step1: Basic Software Install下面我把自己常用的软件安装记录一下： 搜狗输入法 这个应该不用太多解释，毕竟还是有中文输入的需求的，搜狗可以把你的输入习惯和词库记录，迁移性非常好。 Snipaste 这个是我个人比较常用的截图工具，在Microsoft Store里面下载。 Typora Markdown个人最喜欢的编辑器 下载地址：https://typora.io/ 这里补充一些，用于默认的主题都不是特批满意，个人在typora主页里面下载了额外的主题风格，我个人选择的是Ursine。 在这里可以打开Style文件夹，对风格进行配置。 Eartrumpet WIndows下最好用的音量管理工具，比原有的音量设置好用的多。 同样在Microsoft Store里面下载。 这里我补充一个测量，因为Eartrumpet是一个独立的工具，两个喇叭按钮在下面放着可能会比较奇怪。移除Windows原生的音量控制会有点点小小的麻烦，具体操作如下：（这个时候就体现出组策略的优势了） Windows+R执行gpedit.msc 如图所示，左侧的 User Configuration &gt; Administrative Templates &gt; Start Menu and Taskbar，在里面找到Remove the volumn control icon。启用这个选项就可以了。 AutoHotKey https://www.autohotkey.com/ 这个工具是一个必需品，为了下一个工具做准备。 Capslock-plus 一个非常好用的键盘扩展工具，具体的教程和介绍可以看这里： https://capslox.com/capslock-plus/ 建议从此处下载： https://github.com/wo52616111/capslock-plus 下载AHK代码，直接执行。 WIndows Terminal 阳间终端，虽然现在Windows的终端比以前好看了一点点，但是黑Windows Terminal还是没有什么可比性的。 Microsoft Store安装即可。 社交通讯 QQ，微信，腾讯会议，telegram，飞书，Zoom choco Windows下安装的一个利器，可以简单快捷的安装各种其他软件 https://chocolatey.org/install gsudo 这个是用choco安装的一个便捷工具，作用和linux下的Sudo一样，可以在管理员权限下使用命令。 pandoc 又是一个非常重要的基础工具，可以作为插件给其他软件使用，用于各种格式的文件的转换。 Microsoft Office Office 系列，用于常用编辑。 Visio 作图工具 Teamviewer 远程操作 VNC Viewer VNC 控制台 Zotero 论文整理 Steam 为了摸鱼 Matlab 科研工具 Mathematica 计算器 破解方法：https://ibug.io/blog/2019/05/mathematica-keygen/ Foxit Reader PDF阅读器、编辑器、OCR识别 Source Code Pro 字体配置 https://fonts.google.com/specimen/Source+Code+Pro?preview.text_type=custom Google 字体下载 解压之后放在C:\\Windows\\Fonts里即可 同时补充一个中文字体：Sarasa 安装方法同理 Bandizip 解压软件，7Zip的界面太丑了，有点难忍 Fences 桌面整理管理工具，可以用Nimi Places代替 总Steam里购买下载 Step2: Programming Environment2.1 Python先把最简单的工具安装起来，这个直接在官网下载安装程序就OK了。 2.2 Visual Studio2.3 Visual Studio Code这个才是真正的核心工具，插件完善，功能多元。 至于插件安装和配置之后会写一篇，我目前都用VSCode的同步功能，非常好用。 2.4 Git版本管理工具，不可或缺。 2.5 MSYShttps://www.msys2.org/ 用类似Arch的管理方法去管理各种基础编译环境，作用和以前的Cygwin是一样的，不过更加优秀。 2.6 WSL2这个是我日常工作不可或缺的一部分了，是我最常用的虚拟工作环境。 https://www.omgubuntu.co.uk/how-to-install-wsl2-on-windows-10 此处为安装教程。 如果安装不成功，需要下载wsl_update_x64进行补丁。 安装之后就可以顺利启动了。 2.7 Jetbrains CLion Pycharm PHPStorm WebStorm Idea 这5个都属于我的常用工具，官网下载即可。 2.8 X410X转发服务器，这里选用了X410，Microsoft Store 购买。 安装之后需要将WSL2和X410进行绑定和使用。使用有些技巧，在X410启动之后，需要更改WSL2的显示设置，在bashrc末尾添加如下内容： 123export DISPLAY_NUMBER=&quot;0&quot;export DISPLAY=$(grep -m 1 nameserver /etc/resolv.conf | awk &#x27;&#123;print $2&#125;&#x27;):$DISPLAY_NUMBERexport LIBGL_ALWAYS_INDIRECT=1 这样就实现了WSL的X转发。 2.9 TilixTilix是我个人偏好的终端，是在Linux下分屏最方便的终端。安装在WSL中进行： 1sudo apt install tilix 安装即可。 在windows中更自然的使用，需要做一下额外的调整和配置。 用AHK写一个快速启动的配置，使用更加像Linux。 1234567^!t:: Run, C:\\app\\tilix\\tilix.vbsReturn^BackSpace:: ;;Delete previous word Send ^+&#123;Left&#125;&#123;Del&#125;Return 这里有一个使用习惯，Ctrl + BackSpace用于删除整个单词。","categories":[{"name":"Windows","slug":"Windows","permalink":"https://chivier.github.io/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://chivier.github.io/tags/Windows/"},{"name":"Softwares","slug":"Softwares","permalink":"https://chivier.github.io/tags/Softwares/"}]},{"title":"X-forwarding Check","slug":"2021/x-forwarding-check","date":"2020-09-29T02:02:00.000Z","updated":"2021-12-23T04:47:04.000Z","comments":true,"path":"2020/09/29/2021/x-forwarding-check/","link":"","permalink":"https://chivier.github.io/2020/09/29/2021/x-forwarding-check/","excerpt":"When I use Linux or wanna use x-forward to use remote linux applications, I have to check out the x-forward port. But how to check is a really fuszy problem.","text":"When I use Linux or wanna use x-forward to use remote linux applications, I have to check out the x-forward port. But how to check is a really fuszy problem. So Is there a command to list all open displays on a machine? Reference: Stackoverflow: Is there a command to list all open displays on a machine If you want the X connection forwarded over SSH, you need to enable it on both the server side and the client side. (Depending on the distribution, it may be enabled or disabled by default.) On the server side, make sure that you have X11Forwarding yes in /etc/sshd_config (or /etc/ssh/sshd_config or wherever the configuration file is). On the client side, pass the -X option to the ssh command, or put ForwardX11 in your ~/.ssh/config.If you run ssh -X localhost, you should see that $DISPLAY is (probably) localhost:10.0. Contrast with :0.0, which is the value when you’re not connected over SSH. (The .0 part may be omitted; it’s a screen number, but multiple screens are rarely used.) There are two forms of X displays that you’re likely to ever encounter:Local displays, with nothing before the :.TCP displays, with a hostname before the :.With ssh -X localhost, you can access the X server through both displays, but the applications will use a different method: :NUMBER accesses the server via local sockets and shared memory, whereas HOSTNAME:NUMBER accesses the server over TCP, which is slower and disables some extensions.Note that you need a form of authorization to access an X server, called a cookie and normally stored behind the scenes in the file ~/.Xauthority. If you’re using ssh to access a different user account, or if your distribution puts the cookies in a different file, you may find that DISPLAY=:0 doesn’t work within the SSH session (but ssh -X will, if it’s enabled in the server; you never need to mess with XAUTHORITY when doing ssh -X). If that’s a problem, you need to set the XAUTHORITY environment variable or obtain the other user’s cookies.To answer your actual question:Local displays correspond to a socket in /tmp/.X11-unix. 1&gt;(cd &#x2F;tmp&#x2F;.X11-unix &amp;&amp; for x in X*; do echo &quot;:$&#123;x#X&#125;&quot;; done) Remote displays correspond to open TCP ports above 6000; accessing display number N on machine M is done by connecting to TCP port 6000+N on machine M. From machine M itself: 1234&gt;netstat -lnt | awk &#39; sub(&#x2F;.*:&#x2F;,&quot;&quot;,$4) &amp;&amp; $4 &gt;&#x3D; 6000 &amp;&amp; $4 &lt; 6100 &#123; print ($1 &#x3D;&#x3D; &quot;tcp6&quot; ? &quot;ip6-localhost:&quot; : &quot;localhost:&quot;) ($4 - 6000) &#125;&#39; (The rest of this bullet point is of academic interest only.)From another machine, you can use nmap -p 6000-6099 host_name to probe open TCP ports in the usual range. It’s rare nowadays to have X servers listening on a TCP socket, especially outside the loopback interface.Strictly speaking, another application could be using a port in the range usually used by X servers. You can tell whether an X server is listening by checking which program has the port open. 1&gt;lsof -i -n | awk &#39;$9 ~ &#x2F;:60[0-9][0-9]$&#x2F; &#123;print&#125;&#39; If that shows something ambiguous like sshd, there’s no way to know for sure whether it’s an X server or a coincidence.","categories":[{"name":"System","slug":"System","permalink":"https://chivier.github.io/categories/System/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"},{"name":"Linux Tricks","slug":"Linux-Tricks","permalink":"https://chivier.github.io/tags/Linux-Tricks/"}]},{"title":"WSL 2 Quick Fix","slug":"2021/WSL2-Quick-Fix","date":"2020-09-29T01:58:00.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2020/09/29/2021/WSL2-Quick-Fix/","link":"","permalink":"https://chivier.github.io/2020/09/29/2021/WSL2-Quick-Fix/","excerpt":"","text":"As is a well-known fact, Windows WSL 2 is not stable enough. Especially, you have taken some strange settings about yourNetwork. Here I will give out a common way to fix the WSL2 errors, such as ‘0xffffffff’ or something else. Method 1: NetshInput netsh.exe winsock reset in the powershell with administractor permission. Method 2: Automatic scan and fixInput sfc /scannow in the powershell is okay.","categories":[{"name":"System","slug":"System","permalink":"https://chivier.github.io/categories/System/"}],"tags":[{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"},{"name":"Windows","slug":"Windows","permalink":"https://chivier.github.io/tags/Windows/"}]},{"title":"Linux Themes","slug":"2021/Linux-Themes","date":"2020-09-17T23:02:41.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2020/09/18/2021/Linux-Themes/","link":"","permalink":"https://chivier.github.io/2020/09/18/2021/Linux-Themes/","excerpt":"Here is a simple sharing about how to modify the themes in Ubuntu.","text":"Here is a simple sharing about how to modify the themes in Ubuntu. PreparationBefore changing, the first is to install ‘gnome-tweaks’ &amp; ‘gnome-tweak-tool’. You can use ‘apt/apt-get’ to install. Download and SetWhich theme to choose is your freedom. You can choose from here: https://itsfoss.com/best-gtk-themes/ and put themes in ‘.icons’, ‘.themes’. Finally, choose themes in ‘tweaks’.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Tricks","slug":"Linux/Linux-Tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-Tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"}]},{"title":"Rebuild My Home - 04 Beautify","slug":"2021/Rebuild-My-Home-04-Beautify","date":"2020-02-11T15:09:06.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2020/02/11/2021/Rebuild-My-Home-04-Beautify/","link":"","permalink":"https://chivier.github.io/2020/02/11/2021/Rebuild-My-Home-04-Beautify/","excerpt":"Remove Ubuntu dockFirst of all, I wanna remove the left bar of my computer. I really don’t like it.","text":"Remove Ubuntu dockFirst of all, I wanna remove the left bar of my computer. I really don’t like it. 1sudo apt remove gnome-shell-extension-ubuntu-dock StacerA useful tool to help you decide which app to start when you boot your system. Also, it can help you clean the rubbish in your system. PlankMy favorite dock. sudo apt-get to install is okay. AlbertOpening any file or application is easy with Albert. It can search the file system with its files plugin and automatically looks for any installed application. With the &gt; prefix, it runs shell scripts in a heartbeat. Flat iconFlat remix Gnome dash fixGoogle it and I think you will like it ~","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Rebuild My Home - 03 Programming","slug":"2021/Rebuild-My-Home-03-Programming","date":"2020-02-11T14:54:05.000Z","updated":"2021-12-27T14:52:11.730Z","comments":true,"path":"2020/02/11/2021/Rebuild-My-Home-03-Programming/","link":"","permalink":"https://chivier.github.io/2020/02/11/2021/Rebuild-My-Home-03-Programming/","excerpt":"As a programmer, I don’t think you can bear only working with ‘gdb’ and ‘vim’. Tools can never too better. I will introduce my working environment.","text":"As a programmer, I don’t think you can bear only working with ‘gdb’ and ‘vim’. Tools can never too better. I will introduce my working environment. ZSH &amp; Tilix &amp; GoghAh, the most unbearable thing in Ubuntu is the default terminal is really ugly. Also I do not like bash. So I really recommend zsh + tilix. ZSH install Install zsh core and basic tools 1sudo apt-get install git zsh curl Execute 1sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; And then you can install zsh automatically. Set zsh as default shell 1chsh -s $(which zsh) Set zsh theme and edit your zsh configure. 1vim ~/.zshrc I need to add some my aliases, also I need to set up some plugins for my zsh 1234cd ~/.oh-my-zsh/custom/pluginsgit clone https://github.com/zsh-users/zsh-autosuggestionsgit clone https://github.com/zsh-users/zsh-history-substring-searchgit clone https://github.com/zsh-users/zsh-syntax-highlighting Don’t forget to add them to your .zshrc/plugins 1plugins=(git zsh-history-substring-search zsh-autosuggestions colored-man-pages zsh-syntax-highlighting) Tilix So, why tilix? tilix is a really useful terminal that can split screen easily. Tilix is easy to install. 1sudo apt-get install tilix But I wanna to set tilix as my default terminal. Here is a tutorial: 1sudo update-alternatives --config x-terminal-emulator Through this you can choose your default startup terminal emulator. However, if you try to use right click and ‘Open terminal here’, you will find the terminal is still gnome-terminal. About this problem I will share how to edit ‘right click’ panel in another tutorial. GoghUm, we almost finish all the steps. But I am unsatisfied with the color theme. Here I will share a perfect tool with you — ‘gogh.sh’ gogh github I recommend install it from here: 1bash -c &quot;$(wget -qO- https://git.io/vQgMr)&quot; And then choose your favorite color theme to download and then you can also choose in tilix preference. VSCodeMy favorite IDE, you can view more information here: VS Code QtFor Visualization. Download an install is okay. Qt","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Rebuild My Home - 02 Office","slug":"2021/Rebuild-My-Home-02-Office","date":"2020-02-11T14:53:56.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2020/02/11/2021/Rebuild-My-Home-02-Office/","link":"","permalink":"https://chivier.github.io/2020/02/11/2021/Rebuild-My-Home-02-Office/","excerpt":"Many people say that Ubuntu is not fit for Office work. I do not agree. Here I will introduce some apps to you and teach you how to install them.","text":"Many people say that Ubuntu is not fit for Office work. I do not agree. Here I will introduce some apps to you and teach you how to install them. Netease MusicHmm, no music no life. You can download from Netease Homepage And you can find a Linux version. 1sudo dpkg -i netease-cloud-music_xxx(version).deb And now I can build my Ubuntu with beautiful music. WPSWPS Office is a perfect office on linux. You can write documents, make PPTs very fluently with its help. You can download here: WPS foe linux I prefer using DEB file for installation. 1sudo dpkg -i wps-offxxx.deb You might meet some trouble here, if your Ubuntu is a grand new one. You might meet error information like: 123dpkg: dependency problems prevent configuration of wps-office: wps-office depends on libgtk2.0-0; however: Package libgtk2.0-0 is not installed. This means you need to install ‘libgtk2.0-common’. If there are other errors, you can solve by fix-broken. Just like this: 12sudo apt-get install ligtk2.0-commonsudo apt-get --fix-broken install After fix gtk dependencies, you can redo the install step by executing sudo dpkg -i xxx TyporaAs a Markdown lover, I cannot live without an elegant markdown editor. You can follow the installation steps on their home page. Typora for linux By the way I don’t like the default theme in Typora at all. You can choose your favorite style in Typora theme. I prefer using Ursine. Download from Github release. You can get a zip file after downloading. Unzip it and copy all the file in Ursine folder into your Typora Theme Folder. Mostly, you can find it at ~/.config/Typora/themes. Also, you can find it in your Typora Settings, File &gt; Settings &gt; Appearance &gt; Theme Folder. ChromeWell, I think I needn’t to introduce Chrome. Sogou PinyinAs a Chinese, I cannot avoid inputing Chinese sometimes. However I recommend Sogou pinyin not only for typing Chinese. Besides,Sogou pinyin has English spell hint function. I like it very much. However, install Sogou pinyin is a little difficult. Firstly, you need install Fcitx as a frame to hole Sogou pinyin. 1sudo apt install fcitx And then download Sogou here: Sogou pinyin for linux Use sudo dpkg -i to install it. Now open settings panel, choose Region &amp; Language and click Manage Installed language. Here you can install Chinese language configure for your computer. And you should choose Keyboard input method system to fcitx. Next step is reboot. After rebooting your computer, you can find a keyboard like icon. And now it’s time to add input method. However I have another important thing to share with you. As a programmer, I frequently use shift on my keyboard. But after using fcitx, shift will change your input language, and it is really annoying. Here is a tutorial about how to disable shift: Fcitx setting is saved here: ~/.config/fcitx/config Edit it, here are enough information about every configure in fcitx. Finally, do not forget to lock it. 1chmod -w config Snap storeHere I am going to install a series of apps by using snap store system. It’s really convenient to install through snap. I will list out here: Shotcut Free, cross-platform, open source video editor VLC player The ultimate media player MailSpring My favorite email client GNU Image Manipulation Program PS for ubuntu Pandocpandoc is a really powerful tool for documentations formats converting. Download DEB file and install it is okay. DiaAn convenient app to draw almost all kinds of simple graphs you need. It’s just like VISIO in linux. 1sudo apt-get install dia QQAlso there is a QQ-for-linux you can easily install by ‘apt install’. However, it is really awful: easily to get unconnected and you can only scan the QR code to login. So I recommend wine-QQ.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Rebuild My Home - 01 Get ready","slug":"2021/Rebuild-My-Home-01-Get-ready","date":"2020-02-11T14:53:37.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2020/02/11/2021/Rebuild-My-Home-01-Get-ready/","link":"","permalink":"https://chivier.github.io/2020/02/11/2021/Rebuild-My-Home-01-Get-ready/","excerpt":"Why Ubuntu?In the very beginnning in this serials of tutorial, I wanna quote some words from Mr. Richard Feyman.","text":"Why Ubuntu?In the very beginnning in this serials of tutorial, I wanna quote some words from Mr. Richard Feyman. What I cannot create, I do not understand. Linux family systems do highly respect their users. They have sudo option to allow users to do anything they want to do (Somethings may cause some big trouble). So, if you can understand the constucture and master some knowledge about computer science, Linux is a really wonderful choice. But why Ubuntu? Actually, there are many reasons. Firstly, I wanna say Ubuntu is one of the most popular Linux version in the world. There are enough informantion and resources about Ubuntu (You will find how important it is later). Another reason is my personal preference, I regard Ubuntu is one of the most elegant system in the world, light, easy to use, beautiful GUI, fast, easy to build. All in all, Ubuntu is the best system in my eyes. So, let our story begin. FFFFirstFFFFirst things(Why 4 Fs, Hmmm, there are 4 very very important things, I cannot sort their importance) are: Install vimHmm, I wanna emphasize here that vi is not vim. They are different apps. 1sudo apt install vim And if you are a really green hand on Linux. I recommand some other tools for you. 123sudo apt install nanosudo apt install geditsudo apt install geany There editors are all quite easy to get and easy to use. Change the sourceAs I am a Chinese, the official source is too slow for me. Here I recommand a tool: repository file generator You can genetate a new source config file easily. And then you just need to backup your old source config and create a new file here. Just like this: 123sudo cp /etc/apt/source.list /etc/apt/source.list.oldsudo vim /etc/apt/source.list# copy the source.list generated before Update sourceAnd don’t forget to update your source after change the source. 12sudo apt updatesudo apt upgrade Build proxyIt’s essential for Chinese users, many forums and resources are unavailable unless you have VPN.(But I won’t teach you how to build proxy here, I will show you about it in another tutorial)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Ubuntu Hotspot Creating and Configuring","slug":"2021/Ubuntu-Hotspot-Creating-and-Configuring","date":"2019-12-04T16:23:12.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2019/12/05/2021/Ubuntu-Hotspot-Creating-and-Configuring/","link":"","permalink":"https://chivier.github.io/2019/12/05/2021/Ubuntu-Hotspot-Creating-and-Configuring/","excerpt":"","text":"Okay, it’s a simple tutorial about how to create and configure hotspot in Ubuntu 19.10. Creating HotspotIn a GUI interface, creating hotspot has become quite simple in Ubuntu. Just like the picture showing below. Configuring Hotspot","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"https://chivier.github.io/tags/Network/"}]},{"title":"IPV6-Config in Ubuntu","slug":"2021/IPV6-Config-in-Ubuntu","date":"2019-12-03T02:30:49.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/12/03/2021/IPV6-Config-in-Ubuntu/","link":"","permalink":"https://chivier.github.io/2019/12/03/2021/IPV6-Config-in-Ubuntu/","excerpt":"Linux is a simple OS, and you can almost define every system configure as you like. Today’s problem is about IPV6. In Windows or Mac, ipv6 config is done automaticlly by the system. However, in Linux, it’s a little hard to do such work. You have to change some system-conf file manually.","text":"Linux is a simple OS, and you can almost define every system configure as you like. Today’s problem is about IPV6. In Windows or Mac, ipv6 config is done automaticlly by the system. However, in Linux, it’s a little hard to do such work. You have to change some system-conf file manually. Step 1Install some dependencies is required: 1sudo apt install miredo Step 2Modify file /etc/default/ufw 1sudo gedit /etc/default/ufw And change IPV6=no to IPV6=yes. If IPV6 has already changed into yes, just skip this step. Step 3Restart the system serivce: 1sudo invoke-rc.d networking restart Step 4 (Optional)There is something more we have to do if you are connecting into ethernet like your education-network. 1sudo gedit /etc/sysctl.d/10-ipv6-privacy.conf Change 12net.ipv6.conf.all.use_tempaddr &#x3D; 2net.ipv6.conf.default.use_tempaddr &#x3D; 2 into 12net.ipv6.conf.all.use_tempaddr &#x3D; 0net.ipv6.conf.default.use_tempaddr &#x3D; 0 And then refresh your configures: 1sudo sysctl --system","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux tricks","slug":"Linux/Linux-tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"https://chivier.github.io/tags/Network/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://chivier.github.io/tags/Ubuntu/"}]},{"title":"Md-quick-show","slug":"2021/Md-quick-show","date":"2019-11-26T02:56:07.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2019/11/26/2021/Md-quick-show/","link":"","permalink":"https://chivier.github.io/2019/11/26/2021/Md-quick-show/","excerpt":"花里胡哨工具集 - 001关于新坑： 这里挖了一个新坑，这一个系列叫做Fansy tools合集，用来介绍各种各样玄妙的工具～～～","text":"花里胡哨工具集 - 001关于新坑： 这里挖了一个新坑，这一个系列叫做Fansy tools合集，用来介绍各种各样玄妙的工具～～～ 综述介绍今天介绍的主要是我们的一套工具链： reveal.js 引擎 Maekdown 语法分析 基于Python的转换器 听到这里，大部分人还没有明白我们到底想做些什么。 这里说明清楚： 我们的工具是一个讲Markdown快捷转换成HTML可展示页面的工具 使用流程是这样的 配置环境我们的环境需求如下两样东西： Mdast提供的markdown语法分析 reveal.js提供的引擎 下载方法： 1234git clone https://github.com/hakimel/reveal.js.gitnpm install -g remark-clinpm install -g remark-preset-wooorm 使用方法具体的转换工具在： 1git clone https://github.com/Chivier/Md-quick-show 运行方法： 1python heading.py 之后输入markdown文件名就可以得到一个index.html文件 复制index.html到reveal.js即可 Future work后面有空会将他完全部署到服务器上，这样就有一个网页，大家拖拽Markdown上传，就可以直接进行展示了。","categories":[{"name":"Tools","slug":"Tools","permalink":"https://chivier.github.io/categories/Tools/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"https://chivier.github.io/tags/Tools/"}]},{"title":"Advancing on X86 Assembly 2 - Programming Skills in Detail","slug":"2021/Advancing-on-X86-Assembly-2-Programming-Skills-in-Detail","date":"2019-11-22T11:45:40.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/11/22/2021/Advancing-on-X86-Assembly-2-Programming-Skills-in-Detail/","link":"","permalink":"https://chivier.github.io/2019/11/22/2021/Advancing-on-X86-Assembly-2-Programming-Skills-in-Detail/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Advancing on X86 Assembly 1 - Registers & Memory","slug":"2021/Advancing-on-X86-Assembly-1-Registers-Memory","date":"2019-11-15T01:30:04.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/11/15/2021/Advancing-on-X86-Assembly-1-Registers-Memory/","link":"","permalink":"https://chivier.github.io/2019/11/15/2021/Advancing-on-X86-Assembly-1-Registers-Memory/","excerpt":"对于X86的汇编我们的认识框架是这样的： 认识寄存器，认识内存管理模式（确定数据存储位置） 了解存取模式（确定数据存取方法） 学习基本运算指令 多过程的处理 IO指令和中断 协处理器指令","text":"对于X86的汇编我们的认识框架是这样的： 认识寄存器，认识内存管理模式（确定数据存储位置） 了解存取模式（确定数据存取方法） 学习基本运算指令 多过程的处理 IO指令和中断 协处理器指令 寄存器通用寄存器 General-Purpose Registers (GPR) The 8 GPRs are: Accumulator register (AX). Used in arithmetic operations Counter register (CX). Used in shift/rotate instructions and loops. Data register (DX). Used in arithmetic operations and I/O operations. Base register (BX). Used as a pointer to data (located in segment register DS, when in segmented mode). Stack Pointer register (SP). Pointer to the top of the stack. Stack Base Pointer register (BP). Used to point to the base of the stack. Source Index register (SI). Used as a pointer to a source in stream operations. Destination Index register (DI). Used as a pointer to a destination in stream operations. 专用寄存器有三个专用的寄存器：IP、SP、FLAGS IP（RIP、EIP）： 指令指针，指向下一条运行的指令 SP（RSP、ESP）： 堆栈指针。通过指针存取堆栈存储器中的数据 RFLAGS： Position 0. CF : Carry Flag. Set if the last arithmetic operation carried (addition) or borrowed (subtraction) a bit beyond the size of the register. This is then checked when the operation is followed with an add-with-carry or subtract-with-borrow to deal with values too large for just one register to contain. 2. PF : Parity Flag. Set if the number of set bits in the least significant byte is a multiple of 2. 4. AF : Adjust Flag. Carry of Binary Code Decimal (BCD) numbers arithmetic operations. 6. ZF : Zero Flag. Set if the result of an operation is Zero (0). 7. SF : Sign Flag. Set if the result of an operation is negative. 8. TF : Trap Flag. Set if step by step debugging. 9. IF : Interruption Flag. Set if interrupts are enabled. 10. DF : Direction Flag. Stream direction. If set, string operations will decrement their pointer rather than incrementing it, reading memory backwards. 11. OF : Overflow Flag. Set if signed arithmetic operations result in a value too large for the register to contain. 12-13. IOPL : I/O Privilege Level field (2 bits). I/O Privilege Level of the current process. 14. NT : Nested Task flag. Controls chaining of interrupts. Set if the current process is linked to the next process. 16. RF : Resume Flag. Response to debug exceptions. 17. VM : Virtual-8086 Mode. Set if in 8086 compatibility mode. 18. AC : Alignment Check. Set if alignment checking of memory references is done. 19. VIF : Virtual Interrupt Flag. Virtual image of IF. 20. VIP : Virtual Interrupt Pending flag. Set if an interrupt is pending. 21. ID : Identification Flag. Support for CPUID instruction if can be set. 段寄存器The 6 Segment Registers are: Stack Segment (SS). Pointer to the stack. Code Segment (CS). Pointer to the code. Data Segment (DS). Pointer to the data. Extra Segment (ES). Pointer to extra data (‘E’ stands for ‘Extra’). F Segment (FS). Pointer to more extra data (‘F’ comes after ‘E’). G Segment (GS). Pointer to still more extra data (‘G’ comes after ‘F’). Memory Management不论何种寻址模式，我们基本上的框架都算是基于segment address + offset address进行计算的，每个segment address对应1MB空间，例如： 2000H — 起始地址：20000H ～ 种植地址：2FFFFH 加上偏移就可以定位具体的位置。 实模式寻址实模式寻址就是直接的由base address + offset得到 默认的组合有： 保护模式寻址保护模式的寻址模式其实是一种扩张性质的描述方法： 上面的这一张图里面就交代了**全局描述符表(GDT)**的结构。 G 表示粒度，G=1，界限值以4KB为单位，G=0，以字节为单位。 AV位：Available for use by system software，提供给系统软件使用。可用于指示段是否有效。AV=0，段有效；AV=1，段有效。 D位：指示保护模式下或实模式下80386~Core2指令如何访问寄存器和存储器数据。 如果D=0，则指令与8086~80286兼容，是16位指令。在默认情况下，用16位偏移地址和16位寄存器。这种模式通常称为16位指令模式或DOS模式。如果D=1，则指示32位指令模式、32位段。 P：P=0，段不在内存中；P=1，段在内存中。 DPL：描述符特权级，取值0~3，确定段的特权级，为任务允许访问该段的最低特权级。 S：S=1表示该描述符为代码或数据段描述符；S=0，表示该描述符为系统段描述符。 Type：段的类型（与段描述符类型相关）。 平展模式不分页不分段直接访问的模式 Something about Moving Data 就MOV指令而言：不允许段寄存器到段寄存器的MOV指令。CS不能作为MOV指令的目的操作数。","categories":[{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/categories/Programming-language/"},{"name":"Assembly","slug":"Programming-language/Assembly","permalink":"https://chivier.github.io/categories/Programming-language/Assembly/"}],"tags":[{"name":"Assembly","slug":"Assembly","permalink":"https://chivier.github.io/tags/Assembly/"}]},{"title":"Latex Package Management in Ubuntu","slug":"2021/Latex-Package-Management-in-Ubuntu","date":"2019-11-10T14:07:48.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/11/10/2021/Latex-Package-Management-in-Ubuntu/","link":"","permalink":"https://chivier.github.io/2019/11/10/2021/Latex-Package-Management-in-Ubuntu/","excerpt":"上次确实介绍了一些关于Linux Latex的基本使用，但是过多的Package让人头皮发麻，所以今天就介绍与点简单的package处理方法。","text":"上次确实介绍了一些关于Linux Latex的基本使用，但是过多的Package让人头皮发麻，所以今天就介绍与点简单的package处理方法。 方法一：简单粗暴讲道理，与其考虑缺这缺那，不如全部安装。所以 1sudo apt-get install texlive-full 至此，问题全部解决 方法二：高级工具这里介绍一下一个LaTeX Package管理工具：tlmgr 这个工具安装可以直接apt-get进行安装处理 使用第一步是进入你的package管理目录，这个在之前的Blog里面有提到。 在该目录同级的位置，执行： 1tlmgr init-usertree 可能会需要sudo 我们之后就可以进行package的简单安装： 1tlmgr install &#123;$package_name&#125; 同样，可能也需要sudo 至此，问题全部解决","categories":[{"name":"Others","slug":"Others","permalink":"https://chivier.github.io/categories/Others/"},{"name":"Latex","slug":"Others/Latex","permalink":"https://chivier.github.io/categories/Others/Latex/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Latex","slug":"Latex","permalink":"https://chivier.github.io/tags/Latex/"}]},{"title":"Linux QQ Bug Fix","slug":"2021/Linux-QQ-Bug-Fix","date":"2019-11-09T06:10:45.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/11/09/2021/Linux-QQ-Bug-Fix/","link":"","permalink":"https://chivier.github.io/2019/11/09/2021/Linux-QQ-Bug-Fix/","excerpt":"As Tecent Inc. has updated their QQ for linux. Although this project is really silly and out-of-date, we have to admit that this version of QQ is one of the stablest version in Linux.","text":"As Tecent Inc. has updated their QQ for linux. Although this project is really silly and out-of-date, we have to admit that this version of QQ is one of the stablest version in Linux. SolutionHowever, there are still many silly bugs need us to fix by ourselves. For example, when you have changed your GTK panel style, QQ would become very fragile. So we have to use some special method. First of all, we need to create a new file: 1sudo gedit /usr/bin/qq And then, input the following code: 1234#!/bin/shexport GDK_NATIVE_WINDOWS=truecd /usr/share/tencent/qq/./qq Finally, a friendly hints here — never click too fast, it will shut your QQ down.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux tricks","slug":"Linux/Linux-tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"},{"name":"Linux Software","slug":"Linux-Software","permalink":"https://chivier.github.io/tags/Linux-Software/"}]},{"title":"Shut Auto-discovering devices","slug":"2021/Shut-Auto-discovering-devices","date":"2019-09-22T12:35:39.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2019/09/22/2021/Shut-Auto-discovering-devices/","link":"","permalink":"https://chivier.github.io/2019/09/22/2021/Shut-Auto-discovering-devices/","excerpt":"","text":"Well, you may say, ‘Hey, Chivier, It’s really convenient that Ubuntu can automatically add new web-devices like printers, scanners. Why are you going to shut it down?’ First I wanna say that, it’s UNSAFE. In many special places, maybe they will have some strange devices which are covered up just like printers. For example, I wanna hack into your computer, I bought something just like a printer and use some tricks to pack it up, and your computer may recognize it as a printer. However, I will program some dirty thing into auto setup program. And now, get it? Second, it will generate many useless messages into my computer. Many many use less HTTP GET requests and responses. It’s awful when you are catching packets in wireshark or something else. So, let’s figure out how to shut this function down. Fist step is to modify the configure file. 1vim /etc/cups/cups-browsed.conf Add BrowseProtocols none and BrowseRemoteProtocols none. Second run following. 12service cups-browsed restartservice cups restart When you wanna to turn this function on, just do something reverse~","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux tricks","slug":"Linux/Linux-tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"}]},{"title":"程序设计资源","slug":"2021/程序设计资源","date":"2019-09-10T08:15:06.000Z","updated":"2021-12-23T04:47:04.000Z","comments":true,"path":"2019/09/10/2021/程序设计资源/","link":"","permalink":"https://chivier.github.io/2019/09/10/2021/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%B5%84%E6%BA%90/","excerpt":"C语言程序设计资料程序设计相关资料","text":"C语言程序设计资料程序设计相关资料 Beginning C++17, 5th Edition Beginning Programming with C For Dummies, 2nd Edition C Primer Plus, 6th Edition C++ Primer Plus, 6th Edition C程序设计(第四版).谭浩强 the_c_programming_language_2","categories":[{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/categories/Programming-language/"},{"name":"C","slug":"Programming-language/C","permalink":"https://chivier.github.io/categories/Programming-language/C/"}],"tags":[{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/tags/Programming-language/"},{"name":"C","slug":"C","permalink":"https://chivier.github.io/tags/C/"}]},{"title":"电路习题资源","slug":"2021/电路习题资源","date":"2019-06-10T02:55:15.000Z","updated":"2021-12-23T04:47:04.000Z","comments":true,"path":"2019/06/10/2021/电路习题资源/","link":"","permalink":"https://chivier.github.io/2019/06/10/2021/%E7%94%B5%E8%B7%AF%E4%B9%A0%E9%A2%98%E8%B5%84%E6%BA%90/","excerpt":"","text":"习题集 slides","categories":[{"name":"Electronic","slug":"Electronic","permalink":"https://chivier.github.io/categories/Electronic/"}],"tags":[{"name":"Electronic","slug":"Electronic","permalink":"https://chivier.github.io/tags/Electronic/"},{"name":"Circuits","slug":"Circuits","permalink":"https://chivier.github.io/tags/Circuits/"}]},{"title":"Android Shadowsocks","slug":"2021/Android-Shadowsocks","date":"2019-05-28T11:09:23.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/05/28/2021/Android-Shadowsocks/","link":"","permalink":"https://chivier.github.io/2019/05/28/2021/Android-Shadowsocks/","excerpt":"Android Shadowsocks.","text":"Android Shadowsocks. Shadowsocks","categories":[{"name":"Android","slug":"Android","permalink":"https://chivier.github.io/categories/Android/"},{"name":"Android tricks","slug":"Android/Android-tricks","permalink":"https://chivier.github.io/categories/Android/Android-tricks/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://chivier.github.io/tags/Web/"},{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://chivier.github.io/tags/Shadowsocks/"}]},{"title":"COD-LAB-CPU","slug":"2021/COD-LAB-CPU","date":"2019-05-28T11:09:04.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/05/28/2021/COD-LAB-CPU/","link":"","permalink":"https://chivier.github.io/2019/05/28/2021/COD-LAB-CPU/","excerpt":"计算机组成原理系列实验，流水线CPU。附代码。","text":"计算机组成原理系列实验，流水线CPU。附代码。","categories":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/categories/COD/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Verilog","slug":"Verilog","permalink":"https://chivier.github.io/tags/Verilog/"}]},{"title":"COD-LAB-Multicycle","slug":"2021/COD-LAB-Multicycle","date":"2019-05-25T02:58:44.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/05/25/2021/COD-LAB-Multicycle/","link":"","permalink":"https://chivier.github.io/2019/05/25/2021/COD-LAB-Multicycle/","excerpt":"计算机组成原理系列实验，多周期CPU。附代码。","text":"计算机组成原理系列实验，多周期CPU。附代码。","categories":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/categories/COD/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Verilog","slug":"Verilog","permalink":"https://chivier.github.io/tags/Verilog/"}]},{"title":"COD-LAB4-VGA","slug":"2021/COD-LAB4-VGA","date":"2019-05-25T02:58:18.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/05/25/2021/COD-LAB4-VGA/","link":"","permalink":"https://chivier.github.io/2019/05/25/2021/COD-LAB4-VGA/","excerpt":"计算机组成原理系列实验，VGA画图实验。附代码。","text":"计算机组成原理系列实验，VGA画图实验。附代码。","categories":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/categories/COD/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Verilog","slug":"Verilog","permalink":"https://chivier.github.io/tags/Verilog/"}]},{"title":"COD-LAB3-Regfiles","slug":"2021/COD-LAB3-Regfiles","date":"2019-05-25T02:57:50.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/05/25/2021/COD-LAB3-Regfiles/","link":"","permalink":"https://chivier.github.io/2019/05/25/2021/COD-LAB3-Regfiles/","excerpt":"计算机组成原理系列实验，FSM。附代码。","text":"计算机组成原理系列实验，FSM。附代码。","categories":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/categories/COD/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Verilog","slug":"Verilog","permalink":"https://chivier.github.io/tags/Verilog/"}]},{"title":"COD-LAB2-FSM","slug":"2021/COD-LAB2-FSM","date":"2019-05-25T02:57:30.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/05/25/2021/COD-LAB2-FSM/","link":"","permalink":"https://chivier.github.io/2019/05/25/2021/COD-LAB2-FSM/","excerpt":"计算机组成原理系列实验，FSM。附代码。","text":"计算机组成原理系列实验，FSM。附代码。","categories":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/categories/COD/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Verilog","slug":"Verilog","permalink":"https://chivier.github.io/tags/Verilog/"}]},{"title":"COD-LAB1-ALU","slug":"2021/COD-LAB1-ALU","date":"2019-05-25T02:34:05.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/05/25/2021/COD-LAB1-ALU/","link":"","permalink":"https://chivier.github.io/2019/05/25/2021/COD-LAB1-ALU/","excerpt":"计算机组成原理系列实验，实验一，ALU。附代码。","text":"计算机组成原理系列实验，实验一，ALU。附代码。","categories":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/categories/COD/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Verilog","slug":"Verilog","permalink":"https://chivier.github.io/tags/Verilog/"}]},{"title":"COD Casual Disscussion 1","slug":"2021/COD-Casual-Disscussion-1","date":"2019-05-14T07:30:46.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/05/14/2021/COD-Casual-Disscussion-1/","link":"","permalink":"https://chivier.github.io/2019/05/14/2021/COD-Casual-Disscussion-1/","excerpt":"","text":"ISA选用MIPS指令集 MIPS:无互锁流水级的微处理器 (Microprocessor without Interlocked Piped Stages) MIPS指令字格式： R-type:arithmetic instruction I-type:data transfer, arithmetic instruction(如addi) J-type:branch instruction(conditional &amp; unconditional)","categories":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/categories/COD/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Latex in Ubuntu","slug":"2021/Latex-in-Ubuntu","date":"2019-05-14T02:57:06.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/05/14/2021/Latex-in-Ubuntu/","link":"","permalink":"https://chivier.github.io/2019/05/14/2021/Latex-in-Ubuntu/","excerpt":"在Ubuntu下安装中文Latex以及安装package的教程～","text":"在Ubuntu下安装中文Latex以及安装package的教程～ 安装latex可以简单的直接再应用商店里面随便搜索一款latex的编辑器，就可以解决大部分问题。但是缺点在于不够灵活，设置僵硬。推荐还是按下面的步骤进行。 安装Latex中文环境和TexStudio个人推荐的tex编辑器是TexStudio，确实十分好用，按F5就可以直接生成pdf再旁边，随点随用，两边同步。 安装如下： 1234sudo apt-get install texlivesudo apt-get install texlive-xetexsudo apt-get install texlive-lang-chinesesudo apt-get install texstudio 就完成了所有安装。 但是进入texstudio之后并不能直接使用，需要我们调整一些设置，再Option栏里的Configure TexStudio...里的Build选项，我们需要将Default的编译方式转为Xelatex。这样才可以完成配置。 新包安装latex里，我们会使用各种package以满足我们的需求。Ubuntu下配置包方法如下。 配置package文件都位于： 1/usr/share/texlive/texmf-dist/tex/latex 我们进入CTAN网站下载需要的包：CTAN 下载之后复制到之前所说的目录里，最后再运行： 1sudo texhash 之后就可以顺利使用了 插入代码对于CS的同学，论文中插入代码必不可少，优雅的插入代码也十分关键。 一般我们先生命风格，再添加代码。 这里以插入verilog代码作为例子 12345678910111213141516171819202122\\definecolor&#123;dkgreen&#125;&#123;rgb&#125;&#123;0,0.6,0&#125;\\definecolor&#123;gray&#125;&#123;rgb&#125;&#123;0.5,0.5,0.5&#125;\\definecolor&#123;mauve&#125;&#123;rgb&#125;&#123;0.58,0,0.82&#125;\\definecolor&#123;vgreen&#125;&#123;RGB&#125;&#123;104,180,104&#125;\\definecolor&#123;vblue&#125;&#123;RGB&#125;&#123;49,49,255&#125;\\definecolor&#123;vorange&#125;&#123;RGB&#125;&#123;255,143,102&#125;\\lstdefinestyle&#123;verilog-style&#125;&#123; language=Verilog, basicstyle=\\small\\ttfamily, breaklines=true, showstringspaces=false, columns=flexible, keywordstyle=\\color&#123;vblue&#125;, identifierstyle=\\color&#123;black&#125;, commentstyle=\\color&#123;vgreen&#125;, numbers=left, numberstyle=\\tiny\\color&#123;black&#125;, numbersep=7pt, tabsize=4, literate=*&#123;:&#125;&#123;&#123;\\textcolor&#123;black&#125;&#123;:&#125;&#125;&#125;1&#125; 1\\lstinputlisting[style=&#123;verilog-style&#125;,caption=&#123;....v&#125;]&#123;...&#125; 插入MIPS汇编的方法有些特殊，CTAN没有官方的sty文件，民间有一个可以用得很顺的版本：Latex-mips MathType输入数学公式符号表：Math Symbol 模板网Templates","categories":[{"name":"Others","slug":"Others","permalink":"https://chivier.github.io/categories/Others/"},{"name":"Latex","slug":"Others/Latex","permalink":"https://chivier.github.io/categories/Others/Latex/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Latex","slug":"Latex","permalink":"https://chivier.github.io/tags/Latex/"}]},{"title":"Operating System Concept - 2","slug":"2021/Operating-System-Concept-2","date":"2019-05-14T00:53:40.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2019/05/14/2021/Operating-System-Concept-2/","link":"","permalink":"https://chivier.github.io/2019/05/14/2021/Operating-System-Concept-2/","excerpt":"","text":"ThreadBenefits Responsiveness. Multithreading an interactive application may allow a program to continue running even if part of it is blocked or is performing a lengthy operation, thereby increasing responsiveness to the user. Resource sharing. Processes can only share resources through techniques such as shared memory and message passing. Economy. Allocating memory and resources for process creation is costly. Scalability. The benefits of multithreading can be even greater in a multiprocessor architecture, where threads may be running in parallel on different processing cores. A single-threaded process can run on only one processor, regardless how many are available. We explore this issue further in the following section. Multithreading ModelsMany-to-One Model The many-to-one model maps many user-level threads to one kernel thread. Thread management is done by the thread library in user space,so it is efficient. However, the entireprocess will block if a thread makes a blocking system call. Also, because only one thread can access the kernel at a time, multiple threads are unable to run in parallel on multi-core systems. One-to-One Model Provide more concurrency than the many-to-one model by allowing another thread to run when a thread makes a blocking system call. Allow multiple threads to run in parallel on multiprocessors. Drawbacks: overhead of creating kernel threads can burden the performance of an application. Many-to-Many Model A balance between concurrency and developing. Many-to-one model: easy to develop, bad concurrency. One-to-one mode: great concurrency, hard to develop. Developers have to pay much attentions on how many system threads to create since the number of threads is strictly limited. (In this model, the number of kernel threads is smaller than the number of user threads.) CPU SchedulingConcept of SchedulingIn a single-processor system, only one process can run at a time. Others must wait until the CPU is free and can be rescheduled. $\\rightarrow$ Waste of time. With multiprogramming, we try to use this time productively. Several processes are kept in memory at one time. When one process has to wait, the operating system takes the CPU away from that process and gives the CPU to another process. Whenever the CPU becomes idle, the operating system must select one of the processes in the ready queue to be executed. The selection process is carried out by the short-term scheduler, or CPU scheduler. The scheduler selects a process from the processes in memory that are ready to execute and allocates the CPU to that process. Preemptive or Non-preemptive书中并没有很好的总结，中文描述更好理解： 可剥夺式(可抢占式Preemptive): 当有比正在运行的进程优先级更高的进程就绪时,系统可强行剥夺正在运行进程的CPU,提供给具有更高优先级的进程使用。 不可剥夺式(不可抢占式Non-preemptive ): 某一进程被调度运行后,除非由于它自身的原因不能运行,否则一直运行下去。 CPU-scheduling decisions may take place under the following four circumstances: When a process switches from the running state to the waiting state When a process switches from the running state to the ready state When a process switches from the waiting state to the ready state When a process terminates When scheduling takes place only under circumstances 1 and 4, we say that the scheduling scheme is non-preemptive or cooperative. Otherwise,it is preemptive. Scheduling Algorithms","categories":[{"name":"Operating System","slug":"Operating-System","permalink":"https://chivier.github.io/categories/Operating-System/"},{"name":"Concepts","slug":"Operating-System/Concepts","permalink":"https://chivier.github.io/categories/Operating-System/Concepts/"}],"tags":[{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Ubuntu 开机加速","slug":"2021/Ubuntu-开机加速","date":"2019-05-13T23:33:09.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2019/05/14/2021/Ubuntu-开机加速/","link":"","permalink":"https://chivier.github.io/2019/05/14/2021/Ubuntu-%E5%BC%80%E6%9C%BA%E5%8A%A0%E9%80%9F/","excerpt":"啊啊啊，真的等不及了……开机慢死了怎么破～","text":"啊啊啊，真的等不及了……开机慢死了怎么破～ 开机时间分析我们需要加速开机流程，受限最重要的是知道那些地方影响了开机速度。我们利用systemd-analyse blame命令来观察具体那些流程较慢： 1systemd-analyse blame 看出来了吧，第一项巨慢无比，不能忍，掐掉。 掐掉？掐掉之前，稳妥一点的做法是搜索一下，这一开机启动service的作用，确认没有恶劣影响之后我们可以关闭： 1systemctl mask xx.service 至此，开机加速任务完成。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux tricks","slug":"Linux/Linux-tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"}]},{"title":"Logic-谓词演算-2","slug":"2021/Logic-谓词演算-2","date":"2019-04-23T00:01:39.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2019/04/23/2021/Logic-谓词演算-2/","link":"","permalink":"https://chivier.github.io/2019/04/23/2021/Logic-%E8%B0%93%E8%AF%8D%E6%BC%94%E7%AE%97-2/","excerpt":"","text":"谓词演算语义解释域和项解释解释域:非空集合M具有 K中每个个体常元$c_i$，M中都有对应的$\\overline{c_i}$ K中每个运算符$f_i^n$，M中都有对应的n元运算符$\\overline{f_i^n}​$ K中每个谓词$R_i^n$，M中都有对应n元关系的$\\overline{R_i^n}​$ 具有这三类映射的集合才被成为K的解释域 例子： 参考汪芳庭的《数理逻辑》中Page82的例子。同时证明了，只有解释域中才可以说明K中公式的真假。 我们之前定义过K中的项集构造： 变元和常元是项 若$t_1,…,t_n$是项，则$f_i^n(t_1,…,t_n)$也是项 我们类似定义出我们的项解释$\\varphi:T\\rightarrow M$： $\\varphi(x_i)=\\varphi_0(x_i),,\\varphi(c_i)=\\overline{c_i}$ 若$\\varphi(t_1),…,\\varphi(t_n)$已经定义好，那么 $\\varphi(f_i^n(t_1,…,t_n))=\\overline{f_i^n}(\\varphi(t_1),…,\\varphi(t_n))$（保运算性） 总结为： 解释域完成了常元、运算符、谓词的映射 项解释完成了变元的映射 这样M中所有元素都有了相对应的映射。 解释域M下我们的所有发项解释集合记作$\\Phi_M$ 项解释的变元变通：x是某个给定的个体变元，y是任意的个体变元，$\\varphi,,\\varphi’ \\in \\Phi_M$ 使得：$y\\neq x ,\\Rightarrow , \\varphi(y)=\\varphi’(y)$，则$\\varphi’$叫$\\varphi$的变通。 通俗来说，变通，顾名思义，就是说明再特定变量x上采取变通的方式，只有变量x的解释产生变化，其余变量保持不变。 公式的赋值函数公式的赋值函数解释域M给定，p是K中任一公式 按下面的方式定义的$|p|:\\Phi_M \\rightarrow Z_2​$叫公式的赋值函数： 对于任意项解释$\\varphi$， p为原子公式$R_i^n(t_1,…,t_n)​$时，令$$|p|(\\varphi)=\\begin{cases}1,\\quad if,(\\overline{t_1},\\overline{t_2},…,\\overline{t_n})\\in \\overline{R^n_i} \\\\0,\\quad if,(\\overline{t_1},\\overline{t_2},…,\\overline{t_n})\\notin \\overline{R^n_i}\\end{cases}$$规定原子公式的赋值 $p=\\neg q​$ 或 $p=q\\rightarrow r​$$$|\\neg q| (\\varphi) = \\neg |q| (\\varphi) \\\\|q \\rightarrow r| (\\varphi) = |q| (\\varphi) \\rightarrow |r| (\\varphi)$$规定对于$\\neg$和$\\rightarrow$的保运算性 $p=\\forall q​$$$|\\forall x q|(\\varphi)=\\begin{cases}1,\\quad if,\\varphi任意一个x变通\\varphi’都有|q|(\\varphi’)=1\\\\0,\\quad otherwise\\end{cases}$$ 规定全称 闭式语义特征语义等性M是K的解释域$\\varphi,\\psi \\in \\Phi_M$ 如果项t中任一变元x都有$\\varphi(x) = \\psi(x)​$，则$\\varphi(t) = \\psi(t)​$ 如果p中任意一个自由变元x都有$\\varphi(x) = \\psi(x)$，则$|p|(\\varphi) = |p|(\\psi)$ 恒真恒假推论法如果M解释域下任一一种指派都使得p的语义为1则p恒真，类似的我们也可以知道恒假 $p$中所有的变元为$x_1,x_2,…,x_n$，则$\\forall x_1 \\forall x_2 … \\forall x_n p$记作$p’$，成为全称闭式 对于这一类有如下两条重要关系： $$|p|_M = 1 \\Leftrightarrow |p’|_M = 1$$ $$|p|_M = 0 \\Leftrightarrow |p’|_M = 0$$ 语义推论和有效式模型： M为K的解释域，M是公式集$\\Gamma$的模型是指$\\Gamma$中每一个公式M中都恒真，即$$r \\in \\Gamma \\Rightarrow |r|_M = 1$$语义推论：类似与语法推论，$\\Gamma \\models p$解释为，当所有$\\Gamma$中元素都解释为真的时候，p解释也为恒真 结论关系：$$\\Gamma \\models p \\Leftrightarrow \\Gamma \\models p’$$ 语义语法关联K可靠性$$\\vdash p \\Rightarrow \\models p$$ K完全性$$\\models p \\Rightarrow \\vdash p$$","categories":[{"name":"Maths","slug":"Maths","permalink":"https://chivier.github.io/categories/Maths/"},{"name":"Logic","slug":"Maths/Logic","permalink":"https://chivier.github.io/categories/Maths/Logic/"}],"tags":[{"name":"Maths","slug":"Maths","permalink":"https://chivier.github.io/tags/Maths/"},{"name":"Logic","slug":"Logic","permalink":"https://chivier.github.io/tags/Logic/"}]},{"title":"Instructions","slug":"2021/Instructions","date":"2019-04-22T23:41:54.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/04/23/2021/Instructions/","link":"","permalink":"https://chivier.github.io/2019/04/23/2021/Instructions/","excerpt":"参考使用，Hexo使用指令","text":"参考使用，Hexo使用指令 目录信息栏加入： 1toc: true 字体12&lt;font color=0x0099ff&gt;&lt;/font&gt; 更多字体设置：Font Help 更多颜色信息：Font Color 下载文件1[File name](\\Download\\...) 图片插入1&lt;img src=&quot;process.png&quot; width=&quot;80%&quot; height=&quot;80%&quot;&gt; pdf 插入1&#123;% pdf ./Repoet.pdf %&#125;","categories":[{"name":"Blog","slug":"Blog","permalink":"https://chivier.github.io/categories/Blog/"},{"name":"Hexo","slug":"Blog/Hexo","permalink":"https://chivier.github.io/categories/Blog/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://chivier.github.io/tags/Hexo/"},{"name":"Blog","slug":"Blog","permalink":"https://chivier.github.io/tags/Blog/"}]},{"title":"Rust-Shell-Project","slug":"2021/Rust-Shell-Project","date":"2019-04-22T06:34:46.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2019/04/22/2021/Rust-Shell-Project/","link":"","permalink":"https://chivier.github.io/2019/04/22/2021/Rust-Shell-Project/","excerpt":"Rust项目——Rust编写Shell。一个用Rust写的Shell。","text":"Rust项目——Rust编写Shell。一个用Rust写的Shell。 Position项目位置： Rust shell Functions功能介绍： 这里只是使用Rust写了一个简单的Shell，功能十分简陋，主要功能 简单的bash shell命令 简单的健壮性处理，无视多余的空格、回车、tab等字符 支持环境变量导出和修改 支持管道 支持基本文件重定向 支持alias和unalias 增加showalias命令输出所有的alias 编写流程基本框架本Shell主要参考： Build a Sell in Rust Rust shell google 基本框架由该博客提供： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061fn main()&#123; loop &#123; print!(&quot;&gt; &quot;); stdout().flush(); let mut input = String::new(); stdin().read_line(&amp;mut input).unwrap(); // must be peekable so we know when we are on the last command let mut commands = input.trim().split(&quot; | &quot;).peekable(); let mut previous_command = None; while let Some(command) = commands.next() &#123; let mut parts = command.trim().split_whitespace(); let command = parts.next().unwrap(); let args = parts; match command &#123; &quot;exit&quot; =&gt; return, command =&gt; &#123; let stdin = previous_command .map_or( Stdio::inherit(), |output: Child| Stdio::from(output.stdout.unwrap()) ); let stdout = if commands.peek().is_some() &#123; // there is another command piped behind this one // prepare to send output to the next command Stdio::piped() &#125; else &#123; // there are no more commands piped behind this one // send output to shell stdout Stdio::inherit() &#125;; let output = Command::new(command) .args(args) .stdin(stdin) .stdout(stdout) .spawn(); match output &#123; Ok(output) =&gt; &#123; previous_command = Some(output); &#125;, Err(e) =&gt; &#123; previous_command = None; eprintln!(&quot;&#123;&#125;&quot;, e); &#125;, &#125;; &#125; &#125; &#125; if let Some(mut final_command) = previous_command &#123; // block until the final command has finished final_command.wait(); &#125; &#125;&#125; 这作为基本框架。 框架缺陷第一，该框架支持命令过少，很多问题无法解决 第二，cd指令不能正常使用 第三，export指令无效 第四，无法使用alias 等等…… 环境变量处理环境变量我采取了自己构建的方法，虽然export指令失效，但是我们的env指令可以正常执行。 构建HashMap解决 alias解决方法同上 cd利用Command库特殊指令修改目录位置，这条指令必须做在shell指令之外单独处理 cicada扩展实际上Rust有一个名为cicada的crate，可以执行学大多数的shell指令，但是该crate有许多未知bug，而且输入输出方法过于简化，倒置无法执行带有’\\n’的指令，还是需要由自己重新构建","categories":[{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/categories/Rust/"},{"name":"Rust Project","slug":"Rust/Rust-Project","permalink":"https://chivier.github.io/categories/Rust/Rust-Project/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/tags/Rust/"},{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/tags/Programming-language/"},{"name":"Shell","slug":"Shell","permalink":"https://chivier.github.io/tags/Shell/"}]},{"title":"Logic-形式算数-1","slug":"2021/Logic-形式算术1","date":"2019-04-16T00:27:57.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/04/16/2021/Logic-形式算术1/","link":"","permalink":"https://chivier.github.io/2019/04/16/2021/Logic-%E5%BD%A2%E5%BC%8F%E7%AE%97%E6%9C%AF1/","excerpt":"","text":"带等词的谓词演算等词公理 $$(E1) \\quad t \\approx t$$ $$(E2) \\quad t_k \\approx u \\rightarrow f_i^n (t_1,…,t_k,…,t_n) \\approx f_i^n (t_1,…,u,…,t_n)$$ $$(E3) \\quad t_k \\approx u \\rightarrow R_i^n (t_1,…,t_k,…,t_n) \\rightarrow R_i^n (t_1,…,u,…,t_n)$$ 如果M是E的模型，则等词$\\approx$可以解释为等价关系","categories":[{"name":"Maths","slug":"Maths","permalink":"https://chivier.github.io/categories/Maths/"},{"name":"Logic","slug":"Maths/Logic","permalink":"https://chivier.github.io/categories/Maths/Logic/"}],"tags":[{"name":"Maths","slug":"Maths","permalink":"https://chivier.github.io/tags/Maths/"},{"name":"Logic","slug":"Logic","permalink":"https://chivier.github.io/tags/Logic/"}]},{"title":"Logic-谓词演算-1","slug":"2021/Logic-谓词演算","date":"2019-04-16T00:27:57.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2019/04/16/2021/Logic-谓词演算/","link":"","permalink":"https://chivier.github.io/2019/04/16/2021/Logic-%E8%B0%93%E8%AF%8D%E6%BC%94%E7%AE%97/","excerpt":"","text":"基本元素基本集合谓词演算与命题演算不同之处在于公式定义上的区别，产生了新的命题元素：$\\forall$ 四个基本集合： 个体变元集$X$，个体常元集$C$，运算函数集$F$，谓词集$R$ 我们定义项集T为层次集合，$T_i​$为i次运算函数产生的项 原子公式集:$$Y = \\bigcup_\\text{i,n} ((R_i^n) \\times T \\times … \\times T)$$定义为原子公式集。原子公式就是指代形如$R_i^n(t_1,…,t_2)$。 基本公式公式定义： 原子公式是公式 若$p,q​$是公式，则$\\neg p​$，$p \\rightarrow q​$，$\\forall x_i p​$都是公式 前两条若干次变换 其他运算定义$$p \\vee q = \\neg p \\rightarrow q \\\\p \\wedge q = \\neg (p \\rightarrow \\neg q) \\\\p \\leftrightarrow q = (p \\rightarrow q) \\wedge (q \\rightarrow p) \\\\\\exists x_i p = \\neg \\forall x_i p$$ 定义了$\\vee\\ \\quad \\wedge \\quad \\leftrightarrow \\quad \\exists​$四种运算符 约束出现和自由出现变元的自由出现指变元$x$不在$\\forall x​$的范围内出现，反之叫约束出现 如果公式中没有自由出现的变元，则叫闭式 项t对p中x自由，完整的说法是“项t对于公式p中的x变元自由”，即用t取替换p中自由出现的x之后，所有的t变元还是自由的。等价于满足下面3条中任意一条： t是闭项（只有常元没有变元） x再p中不自由出现 x对p中x自由 符号p(x)表示公式，p(t)默认表示用t取代换所有的x 谓词演算K定义指有一下规定的功利和证明的公式集： 公理 (K1) $p \\rightarrow (q \\rightarrow p)​$ (K2) $(p \\rightarrow (q \\rightarrow r)) \\rightarrow ((p \\rightarrow q) \\rightarrow (p \\rightarrow r))$ (K3) $(\\neg p \\rightarrow \\neg q) \\rightarrow (q \\rightarrow p)$ (K4) $\\forall x ,p(x) \\rightarrow p(t) \\quad$其中t对p(x)中x自由 (K5) $\\forall x,(p \\rightarrow q) \\rightarrow (p \\rightarrow \\forall x ,q)\\quad$其中x不在p中自由出现 证明 p是公式，$\\Gamma$是公式集。p从$\\Gamma$可证，记作$\\Gamma \\vdash p$ 指： 从有限公式序列$p_1,…,p_n$有$p_n=p$并且每个k=1…n都有 $p_k \\in \\Gamma$ $p_k$是公理 $\\exists i,j&lt;k$使得$p_j = p_i \\rightarrow p_k$ （等价于：要有$p_k$，必须现有$p_i$和$p_i \\rightarrow p_k$） $\\exists j&lt;k$使得$p_k = \\forall x , p_j $ 永真式和定理如果K中命题再L中有对应的命题演算定理，且永真，则叫永真式 简而言之：L中也有的叫永真，永真式一定是定理，反之未必 $\\exists_1$规则如果项t对于p中x自由，则：$$\\vdash p (t) \\rightarrow \\exists x,p(x)$$ $\\exists_2$规则设$\\Gamma \\cup {p}\\vdash q​$其证明中Gen变元不在p中自由出现，x不在q中自由出现，则有$\\Gamma \\cup {\\exists x , p}\\vdash q​$，且出来x不增加其他Gen变元 注意：演绎定理、归谬律、反证律都可以使用，但是略有不同 演绎定理 若$\\Gamma \\vdash p \\rightarrow q​$则$\\Gamma \\cup {p} \\vdash q​$ 若$\\Gamma \\cup {p} \\vdash q$且证明中所用Gen变元不在p中自由出现，则不增加Gen变元就能使$\\Gamma \\vdash p \\rightarrow q$ 推论： p是闭式时$\\Gamma \\vdash p \\rightarrow q \\Leftrightarrow \\Gamma \\cup {p} \\vdash q$ 反证律若$\\Gamma \\cup {\\neg p} \\vdash q​$ 且$\\Gamma \\cup {\\neg p} \\vdash \\neg q​$切所用Gen变元不在p中自由出现，则不增加新的Gen变元就能使得$\\Gamma \\vdash p​$ 归谬律若$\\Gamma \\cup {p} \\vdash q​$ 且$\\Gamma \\cup {p} \\vdash \\neg q​$切所用Gen变元不在p中自由出现，则不增加新的Gen变元就能使得$\\Gamma \\vdash \\neg p​$ 注意演绎定理、归谬律、反证律说起来都是多了不增加新的Gen变元就能使得 子公式等价替换如果公式q是p的子公式：$p=…q…$ 公式$q’$替代$q$得到：$p’ = … q’ …$ 则 $\\Gamma \\vdash q \\leftrightarrow q’ \\Rightarrow \\Gamma \\vdash p \\leftrightarrow p’$ 对偶律将公式p表示为只含有原子公式以及$\\neg,\\vee,\\wedge,\\forall,\\exists​$的形式之后： 所有原子公式改为他们的否定 $\\wedge​$和$\\vee​$互换 $\\forall​$和$\\exists​$互换 新公式记为$p^​$则$$\\vdash p^ \\leftrightarrow \\neg p$$ 前束范式形如$Q_1x…Q_ny p​$的式子叫前束范式，其中$Q_i​$表示量词符号$\\forall​$或者$\\exists​$，一般的，我们将$Q​$的对偶符号记作$Q^*​$ 结论： 若y不在$p(x)​$中自由出现，则 $$\\vdash Qxp(x) \\leftrightarrow Qyp(y)$$ 若x不在p中自由出现，则 $$\\vdash (p\\rightarrow Qxq) \\leftrightarrow Qx(p\\rightarrow q)$$​ 若x不在q中自由出现，则$$\\vdash(Qxp \\rightarrow q) \\leftrightarrow Q^*x(p \\rightarrow q)$$ $$ \\vdash \\neg Q x p \\leftrightarrow Q^* x \\neg p $$ 用上述三条结论完成前束范式的变形，步骤： 利用好结论1和子公式替换，替换p中变元 利用结论2和3将量词移动 结论2用于移动量词在$\\rightarrow$两侧的情况 结论3用于移动再$\\neg$之后的情况 补充两个定义： $\\Pi_n$型前束范式：从$\\forall​$开始，从左往右改变n-1次词性 $\\Sigma_n$型前束范式：从$\\exists$开始，从左往右改变n-1次词性","categories":[{"name":"Maths","slug":"Maths","permalink":"https://chivier.github.io/categories/Maths/"},{"name":"Logic","slug":"Maths/Logic","permalink":"https://chivier.github.io/categories/Maths/Logic/"}],"tags":[{"name":"Maths","slug":"Maths","permalink":"https://chivier.github.io/tags/Maths/"},{"name":"Logic","slug":"Logic","permalink":"https://chivier.github.io/tags/Logic/"}]},{"title":"Operating System Concept - 1","slug":"2021/Operating-System-Concept-1","date":"2019-04-10T06:56:09.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2019/04/10/2021/Operating-System-Concept-1/","link":"","permalink":"https://chivier.github.io/2019/04/10/2021/Operating-System-Concept-1/","excerpt":"","text":"OS A piece of software that manages a computer, making computer’s hardwareresources accessible to software through a consistent set of interfaces. 并发(Concurrence) 共享(Sharing) 虚拟(Virtual) 异步(Asynchronism) 四项重要特征为OS的核心特征，也是我们进一步做得更好的核心挑战所在。 OS Functions CPU管理 进程/线程控制和管理 进程同步和互斥（mutual exclusion） 进程通信和死锁（dead lock） 处理器调度，作业调度和进程调度 存储管理 存储分配 存储共享 存储保护 地址转换 存储扩充 ⽂件管理 ⽬录管理 存取控制/保护 逻辑组织 物理组织 ⽂件存储空间管理 设备管理 设备分配 设备驱动 缓冲管理 ⽤户接口 命令接口 程序接口 图形接口 ⽹络与通信管理 OS Structure System calls provide an interface to the services made available by an operating system. Categories of System call: • Process control• File management• Device management• Information maintenance• Communications Simple StructureMS-DOSMS-DOS – written to provide the most functionality in the least space Not divided into modules Interfaces and levels of functionality not well separated UnixLimited by hardware functionality Original UNIX operating system consists of two separable parts: Systems programs The kernel Consists of everything below the system-call interface and above the physical hardware Provides the file system, CPU scheduling, memory management, and other operating-system functions; Many interacting functions for one level Layered Structure Operating system is divided many layers (levels) Each built on top of lower layers Bottom layer (layer 0) is hardware Highest layer (layer N) is the user interface 模块化，易于调试 Microkernel System Structure Moves as much from the kernel into “user” space as possible. 非基本的方法从内核中抽离，留下基本的方法。（基本：一般认为内存管理和通信功能是必须的基本方法） Benefits:• Easier to extend a microkernel• Easier to port the operating system to new architectures• More reliable (less code is running in kernel mode)• More secureDetriments:• Performance overhead of user space to kernel space communication Module basedMost modern operating systems implement kernelmodules• Uses object-oriented approach• Each core component is separate• Each talks to the others over known interfaces• Each is loadable as needed within the kernel 类似于layered structure，但是灵活性大大增长 Example: Scheduling classes File systems Loadable system calls Executable formats STREAMS modules Miscellaneous Device and bus drivers Hybrid Systems更为现代的设计方式都是采用混合模型 Virtual Machines分层方法逻辑可延伸为虚拟机概念。虚拟机的基本思想是单个计算机(CPU 、内存、磁盘、网卡等)的硬件抽象为几个不同的执行部件，从而造成一种”幻觉”，仿佛每个独立的执行环境都在自己的计算机上运行一样。 创建虚拟机有几个原因，最根本的是，在并行运行几个不同的执行环境(即不同的操作系统)时能够共享相同的硬件。 实现底层机器有两种模式:用户模式和内核模式。虚拟机软件可以运行在内核模式，因为它就是操作系统。虚拟机本身只能运行在用户模式。正如物理机器有两种模式一样，虚拟机也有两种模式。因此，必须有虚拟用户模式和虚拟内核模式，这两种模式都运行在物理用户模式。 优劣• Isolation from all other virtual machines. 保证安全• No disruption on normal system operation. 开发测试操作系统不需要中断正常操作系统的服务• Difficult to implement due to the effort required to provide an exact duplicate to the underlying machine 实例Vmware虚拟层是VMware 的核心，因为它将物理硬件抽象为独立的作为客户操作系统的虚拟机运行。每个虚拟机都有它自己的虚拟 CPU、内存、磁盘驱动、网络接口等。 Java 虚拟机 (JVM)Java 对象用类结构来描述; Java 程序由一个或多个类组成。对于每个 Java 类， Java编译器会生成与平台无关的字节码 (bytecode) 输出文件( .class ) ，它可运行在任何JVM 上。 JVM包括类加载器和执行与平台无关的字节码的Java解释器。JVM 通过执行垃圾收集(garbage collection ，回收不再使用的内存并返回给系统)来自动管理内存。 .NET.NET框架是一套包含了类库集舍、执行环境和软件开发平台的技术。这个平台允许基于.NET框架编程而不是针对任何特定平台。 .NET 框架的核心是公共语言运行时间 (CLR) CLR 是 .NET 虚拟机的实现 用 C#或者 VB.NET 编写的程序被编译为一种平台无关的中间语言(叫做微软中间语言 MS-IU 。这些被编译好的文件叫做组合 (assembly) ,它包含了 MS-IL 指令和元数据。它们的文件名后缀是.dll 或者.exeo 当要运行这些程序的时候， CLR 把这些组合加载进应用程序域 (Application Domain) 。 Process进程概念进程不只是程序代码，程序代码有时称为文本段(或代码段)**。进程还包括当前活动，通过程序计数器的值和处理器寄存器的内容来表示。另外，进程通常还包括进程堆栈段**(包括临时数据，如函数参数、返回地址和局部变量)和数据段(包括全局变量)。进程还可能包括堆 (heap) ，是在进程运行期间动态分配的内存。 英文解释更为简单： A process is a program in execution 进程在执行时产生许多进程是很常见的。 程序与进程之间的区别: “进程”是一个动态的概念:进程强调的是程序的一次“执行”过程,程序是一组有序指令的集合,在多道程序设计环境下,它不涉及“执行”,因此,是一个静态的概念; 不同的进程可以执行同一个程序:即使多个进程执行同一个程序,只要它们运行在不同的数据集合上,它们就是不同的进程; 每一个进程都有自己的生命期:当系统要完成某一项工作时,它就“创建”一个进程,程序执行完毕,系统就“撤销”这个进程,收回它所占用的资源。 进程状态进程在执行时会改变状态。进程状态在某种程度上是由当前活动所定义的。每个进程可能处于下列状态之一: 新的:进程正在被创建。 运行:指令正在被执行。 等待:进程等待某个事件的发生(如 IO 完成或收到信号)。 就绪:进程等待分配处理器。 终止:进程完成执行。 进程控制块每个进程在操作系统内用进程控制块 (process control block. PCB. 也称为任务控制块)来表示。 **进程状态:**状态可包括新的、就绪、运行、等待、停止等。 **程序计数器:**计数器表示进程要执行的下个指令的地址。 **CPU 寄存器:**根据计算机体系结构的不同，寄存器的数量和类型也不同。它们包括累加器、索引寄存器、堆战指针、通用寄存器和其他条件码信息寄存器。与程序计数器一起，这些状态信息在出现中断时也需要保存，以便进程以后能正确地继续执行。 **CPU 调度信息:**这类信息包括进程优先级、调度队列的指针和其他调度参数 **内存管理信息:**根据操作系统所使用的内存系统，这类信息包括基址和界限寄存器的值、页表或段表(见第 8 章)。 **记账信息:**这类信息包括 CPU 时间、实际使用时间、时间界限、记账数据、作业或进程数量等。 **I/O 状态信息:**这类信息包括分配给进程的 νo 设备列表、打开的文件列表等。简而言之， PCB 简单地作为这些信息的仓库，这些信息在进程与进程之间是不同的。 线程一个进程是一个只能进行单个执行线程的程序。 进程调度调度队列进程进入系统时，会被加到作业队列中，该队列包括系统中的所有进程。 讨论进程调度的常用表示方法是队列图 每个长方形表示一个队列。有两种队列:就绪队列和一组设备队列。圆形表示为队列服务的资源，箭头表示系统内进程的流向。 进程创建当进程创建新进程时，有两种执行可能: 父进程与子进程并发执行。 父进程等待，直到某个或全部子进程执行完。 新进程的地址空间也有两种可能: 子进程是父进程的复制品(具有与父进程相同的程序和数据)。 子进程装入另一个新程序。 Unix通过pid变量标记进程，fork（）函数创建进程。 fork的时候发生什么？=》执行到这一句的时候，一个进程被创建了，这个进程与父进程一样，拥有一套与父进程相同的变量，相同的一套代码，这里可以粗浅的理解为子进程又复制了一份main函数。这里返回一个子进程的进程号，大于0。（第一次fork） 通常，在系统调用fork()之后，一个进程会使用系统调用exec()，以用新程序来取代进程的内存雪间。系统调用exec()将二进制文件装入内存(消除了原来包含系统调用exec()的程序的内存映射)，并开始执行。采用这种方式，两个进程能相互通信，并能按各自的方法执行。父进程能创建更多的子进程，或者如果在子进程运行时没有什么可做，那么它采用系统调用wait()把自己移出就绪队列来等待子进程的终止。 子进程怎么执行： =》子进程从fork()的位置开始执行，也就是说前面的代码不走，但是拥有之前的变量以及变量的值，与父进程的值一样，这次fork()，返回值是0，所以在子进程里面直接执行了pid==0这一个分支，父进程里面并不执行这个分支的语句。这就为我们在写mian函数的时候怎么写子进程的程序提供了一个方法来隔离代码。 1234567891011121314#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;int main()&#123; pid_t pid[3]; int count = 0; pid[0] = fork(); pid[1] = fork(); pid[2] = fork(); printf(&quot;this is process\\n&quot;); return 0;&#125; 运行会输出8次this is a process 进程结束当进程完成执行最后的语句并使用系统调用exit()请求操作系统删除自身时，进程终止。这时，进程可以返回状态值(通常为整数)到父进程(通过系统调用wait()) 。所有进程资源(包括物理和虚拟内存、打开文件和 I/O 缓冲)会被操作系统释放。 有些系统，包括 VMS ，不允许子进程在父进程己终止的情况下存在。对于这类系统，如果一个进程终止(正常或不正常)，那么它的所有子进程也将终止。这种现象，称为级联终止( cascading termination) ，通常由操作系统进行。 调度程序进程调度算法的原则: (1)公平性。 (2)资源利用率(特别是CPU利用率)。 (3)响应时间 - 交互式系统情况。 (4)系统吞吐量 - 批处理系统。 (5)周转时间 – 从进程提交到进程完成的时间间隔。 (6)等待时间 – 在就绪队列中等待所花费的时间之和 通常对于批处理系统，进程更多地是被提交，而不是马上执行。这些进程被放到大容量存储设备(通常为磁盘)的缓冲地中，保存在那里以便以后执行。长期调度程序(long-term scheduler) 或作业调度程序 (job scheduler) 从该地中选择进程，并装入内存以准备执行。短期调度程序 (short-term scheduler) 或 CPU 调度程序从准备执行的进程中选择进程，并为之分配 CPU 。 这两个调度程序的主要差别是它们执行的频率。短期调度程序必须频繁地为CPU 选择新进程。","categories":[{"name":"Operating System","slug":"Operating-System","permalink":"https://chivier.github.io/categories/Operating-System/"},{"name":"Concepts","slug":"Operating-System/Concepts","permalink":"https://chivier.github.io/categories/Operating-System/Concepts/"}],"tags":[{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Rust-Learning-4","slug":"2021/Rust-Learning-4","date":"2019-04-09T02:47:23.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2019/04/09/2021/Rust-Learning-4/","link":"","permalink":"https://chivier.github.io/2019/04/09/2021/Rust-Learning-4/","excerpt":"Rust学习进阶。","text":"Rust学习进阶。 生命周期生命周期的主要目标是避免悬垂引用，它会导致程序引用了非预期引用的数据。 12345678910&#123; let r; &#123; let x = 5; r = &amp;x; &#125; println!(&quot;r: &#123;&#125;&quot;, r);&#125; 例如上面的程序 外部作用域声明了一个没有初值的变量 r，而内部作用域声明了一个初值为 5 的变量x。在内部作用域中，我们尝试将 r 的值设置为一个 x 的引用。接着在内部作用域结束后，尝试打印出 r 的值。这段代码不能编译因为 r 引用的值在尝试使用之前就离开了作用域。如下是错误信息： 12345678910error[E0597]: `x` does not live long enough --&gt; src/main.rs:7:5 |6 | r = &amp;x; | - borrow occurs here7 | &#125; | ^ `x` dropped here while still borrowed...10 | &#125; | - borrowed value needs to live until here Rust 编译器有一个 借用检查器（borrow checker），它比较作用域来确保所有的借用都是有效的。 12345678910&#123; let r; // ---------+-- &#x27;a // | &#123; // | let x = 5; // -+-- &#x27;b | r = &amp;x; // | | &#125; // -+ | // | println!(&quot;r: &#123;&#125;&quot;, r); // |&#125; // ---------+ 这里将 r 的生命周期标记为 &#39;a 并将 x 的生命周期标记为 &#39;b。如你所见，内部的 &#39;b 块要比外部的生命周期 &#39;a 小得多。在编译时，Rust 比较这两个生命周期的大小，并发现 r 拥有生命周期 &#39;a，不过它引用了一个拥有生命周期 &#39;b 的对象。程序被拒绝编译，因为生命周期 &#39;b 比生命周期 &#39;a 要小：被引用的对象比它的引用者存在的时间更短。 下面是一个资源借用的例子： 12345678fn main() &#123; let a = 100_i32; &#123; let x = &amp;a; &#125; // x 作用域结束 println!(&quot;&#123;&#125;&quot;, x);&#125; 编译时，我们会看到一个严重的错误提示： error: unresolved name x. 错误的意思是“无法解析 x 标识符”，也就是找不到 x , 这是因为像很多编程语言一样，Rust中也存在作用域概念，当资源离开离开作用域后，资源的内存就会被释放回收，当借用/引用离开作用域后也会被销毁，所以 x 在离开自己的作用域后，无法在作用域之外访问。 上面的涉及到几个概念： Owner: 资源的所有者 a Borrower: 资源的借用者 x Scope: 作用域，资源被借用/引用的有效期 强调下，无论是资源的所有者还是资源的借用/引用，都存在在一个有效的存活时间或区间，这个时间区间称为生命周期， 也可以直接以Scope作用域去理解。 所以上例子代码中的生命周期/作用域图示如下： 1234 &#123; a &#123; x &#125; * &#125;所有者 a: |________________________|借用者 x: |____| x &#x3D; &amp;a 访问 x: | 失败：访问 x 可以看到，借用者 x 的生命周期是资源所有者 a 的生命周期的子集。但是 x 的生命周期在第一个 &#125; 时结束并销毁，在接下来的 println! 中再次访问便会发生严重的错误。 我们来修正上面的例子： 123456789fn main() &#123; let a = 100_i32; &#123; let x = &amp;a; println!(&quot;&#123;&#125;&quot;, x); &#125; // x 作用域结束&#125; 这里我们仅仅把 println! 放到了中间的 &#123;&#125;, 这样就可以在 x的生命周期内正常的访问 x ，此时的Lifetime图示如下： 1234 &#123; a &#123; x * &#125; &#125;所有者 a: |________________________|借用者 x: |_________| x &#x3D; &amp;a 访问 x: | OK：访问 x 隐式Lifetime我们经常会遇到参数或者返回值为引用类型的函数： 123fn foo(x: &amp;str) -&gt; &amp;str &#123; x&#125; 上面函数在实际应用中并没有太多用处，foo 函数仅仅接受一个 &amp;str 类型的参数（x为对某个string类型资源Something的借用），并返回对资源Something的一个新的借用。 实际上，上面函数包含该了隐性的生命周期命名，这是由编译器自动推导的，相当于： 123fn foo&lt;&#x27;a&gt;(x: &amp;&#x27;a str) -&gt; &amp;&#x27;a str &#123; x&#125; 在这里，约束返回值的Lifetime必须大于或等于参数x的Lifetime。下面函数写法也是合法的： 123fn foo&lt;&#x27;a&gt;(x: &amp;&#x27;a str) -&gt; &amp;&#x27;a str &#123; &quot;hello, world!&quot;&#125; 为什么呢？这是因为字符串”hello, world!”的类型是&amp;&#39;static str，我们知道static类型的Lifetime是整个程序的运行周期，所以她比任意传入的参数的Lifetime&#39;a都要长，即&#39;static &gt;= &#39;a满足。 在上例中Rust可以自动推导Lifetime，所以并不需要程序员显式指定Lifetime &#39;a 。 &#39;a是什么呢？它是Lifetime的标识符，这里的a也可以用b、c、d、e、…，甚至可以用this_is_a_long_name等，当然实际编程中并不建议用这种冗长的标识符，这样会严重降低程序的可读性。foo后面的&lt;&#39;a&gt;为Lifetime的声明，可以声明多个，如&lt;&#39;a, &#39;b&gt;等等。 另外，除非编译器无法自动推导出Lifetime，否则不建议显式指定Lifetime标识符，会降低程序的可读性。 显式Lifetime当输入参数为多个借用/引用时会发生什么呢？ 1234567fn foo(x: &amp;str, y: &amp;str) -&gt; &amp;str &#123; if true &#123; x &#125; else &#123; y &#125;&#125; 这时候再编译，就没那么幸运了： 123error: missing lifetime specifier [E0106]fn foo(x: &amp;str, y: &amp;str) -&gt; &amp;str &#123; ^~~~ 编译器告诉我们，需要我们显式指定Lifetime标识符，因为这个时候，编译器无法推导出返回值的Lifetime应该是比 x长，还是比y长。虽然我们在函数中中用了 if true 确认一定可以返回x，但是要知道，编译器是在编译时候检查，而不是运行时，所以编译期间会同时检查所有的输入参数和返回值。 修复后的代码如下： 1234567fn foo&lt;&#x27;a&gt;(x: &amp;&#x27;a str, y: &amp;&#x27;a str) -&gt; &amp;&#x27;a str &#123; if true &#123; x &#125; else &#123; y &#125;&#125; Lifetime推导要推导Lifetime是否合法，先明确两点： 输出值（也称为返回值）依赖哪些输入值 输入值的Lifetime大于或等于输出值的Lifetime (准确来说：子集，而不是大于或等于) Lifetime推导公式： 当输出值R依赖输入值X Y Z …，当且仅当输出值的Lifetime为所有输入值的Lifetime交集的子集时，生命周期合法。 1Lifetime(R) ⊆ ( Lifetime(X) ∩ Lifetime(Y) ∩ Lifetime(Z) ∩ Lifetime(...) ) 对于例子1： 1234567fn foo&lt;&#x27;a&gt;(x: &amp;&#x27;a str, y: &amp;&#x27;a str) -&gt; &amp;&#x27;a str &#123; if true &#123; x &#125; else &#123; y &#125;&#125; 因为返回值同时依赖输入参数x和y，所以 12345Lifetime(返回值) ⊆ ( Lifetime(x) ∩ Lifetime(y) )即：&#39;a ⊆ (&#39;a ∩ &#39;a) &#x2F;&#x2F; 成立 定义多个Lifetime标识符那我们继续看个更复杂的例子，定义多个Lifetime标识符： 1234567fn foo&lt;&#x27;a, &#x27;b&gt;(x: &amp;&#x27;a str, y: &amp;&#x27;b str) -&gt; &amp;&#x27;a str &#123; if true &#123; x &#125; else &#123; y &#125;&#125; 先看下编译，又报错了： 12345678910&lt;anon&gt;:5:3: 5:4 error: cannot infer an appropriate lifetime for automatic coercion due to conflicting requirements [E0495]&lt;anon&gt;:5 y ^&lt;anon&gt;:1:1: 7:2 help: consider using an explicit lifetime parameter as shown: fn foo&lt;&#39;a&gt;(x: &amp;&#39;a str, y: &amp;&#39;a str) -&gt; &amp;&#39;a str&lt;anon&gt;:1 fn bar&lt;&#39;a, &#39;b&gt;(x: &amp;&#39;a str, y: &amp;&#39;b str) -&gt; &amp;&#39;a str &#123;&lt;anon&gt;:2 if true &#123;&lt;anon&gt;:3 x&lt;anon&gt;:4 &#125; else &#123;&lt;anon&gt;:5 y&lt;anon&gt;:6 &#125; 编译器说自己无法正确地推导返回值的Lifetime，读者可能会疑问，“我们不是已经指定返回值的Lifetime为&#39;a了吗？”。 这儿我们同样可以通过生命周期推导公式推导： 因为返回值同时依赖x和y，所以 12345Lifetime(返回值) ⊆ ( Lifetime(x) ∩ Lifetime(y) )即：&#39;a ⊆ (&#39;a ∩ &#39;b) &#x2F;&#x2F;不成立 很显然，上面我们根本没法保证成立。 所以，这种情况下，我们可以显式地告诉编译器&#39;b比&#39;a长（&#39;a是&#39;b的子集），只需要在定义Lifetime的时候, 在&#39;b的后面加上: &#39;a, 意思是&#39;b比&#39;a长，&#39;a是&#39;b的子集: 1234567fn foo&lt;&#39;a, &#39;b: &#39;a&gt;(x: &amp;&#39;a str, y: &amp;&#39;b str) -&gt; &amp;&#39;a str &#123; if true &#123; x &#125; else &#123; y &#125;&#125; 这里我们根据公式继续推导： 1234567条件：Lifetime(x) ⊆ Lifetime(y)推导：Lifetime(返回值) ⊆ ( Lifetime(x) ∩ Lifetime(y) )即：条件： &#39;a ⊆ &#39;b推导：&#39;a ⊆ (&#39;a ∩ &#39;b) &#x2F;&#x2F; 成立 上面是成立的，所以可以编译通过。 推导总结通过上面的学习相信大家可以很轻松完成Lifetime的推导，总之，记住两点： 输出值依赖哪些输入值。 推导公式。 Lifetime in struct上面我们更多讨论了函数中Lifetime的应用，在struct中Lifetime同样重要。 我们来定义一个Person结构体： 123struct Person &#123; age: &amp;u8,&#125; 编译时我们会得到一个error： 12&lt;anon&gt;:2:8: 2:12 error: missing lifetime specifier [E0106]&lt;anon&gt;:2 age: &amp;str, 之所以会报错，这是因为Rust要确保Person的Lifetime不会比它的age借用长，不然会出现Dangling Pointer的严重内存问题。所以我们需要为age借用声明Lifetime： 123struct Person&lt;&#x27;a&gt; &#123; age: &amp;&#x27;a u8,&#125; 不需要对Person后面的&lt;&#39;a&gt;感到疑惑，这里的&#39;a并不是指Person这个struct的Lifetime，仅仅是一个泛型参数而已，struct可以有多个Lifetime参数用来约束不同的field，实际的Lifetime应该是所有fieldLifetime交集的子集。例如： 123456fn main() &#123; let x &#x3D; 20_u8; let stormgbs &#x3D; Person &#123; age: &amp;x, &#125;;&#125; 这里，生命周期/Scope的示意图如下： 1234 &#123; x stormgbs * &#125;所有者 x: |________________________|所有者 stormgbs: |_______________| &#39;a借用者 stormgbs.age: |_______________| stormgbs.age &#x3D; &amp;x 既然&lt;&#39;a&gt;作为Person的泛型参数，所以在为Person实现方法时也需要加上&lt;&#39;a&gt;，不然： 12345impl Person &#123; fn print_age(&amp;self) &#123; println!(&quot;Person.age = &#123;&#125;&quot;, self.age); &#125;&#125; 报错： 123&lt;anon&gt;:5:6: 5:12 error: wrong number of lifetime parameters: expected 1, found 0 [E0107]&lt;anon&gt;:5 impl Person &#123; ^~~~~~ 正确的做法是： 12345impl&lt;&#x27;a&gt; Person&lt;&#x27;a&gt; &#123; fn print_age(&amp;self) &#123; println!(&quot;Person.age = &#123;&#125;&quot;, self.age); &#125;&#125; 这样加上&lt;&#39;a&gt;后就可以了。读者可能会疑问，为什么print_age中不需要加上&#39;a？这是个好问题。因为print_age的输出参数为()，也就是可以不依赖任何输入参数, 所以编译器此时可以不必关心和推导Lifetime。即使是fn print_age(&amp;self, other_age: &amp;i32) &#123;...&#125;也可以编译通过。 如果Person的方法存在输出值（借用）呢？ 12345impl&lt;&#x27;a&gt; Person&lt;&#x27;a&gt; &#123; fn get_age(&amp;self) -&gt; &amp;u8 &#123; self.age &#125;&#125; get_age方法的输出值依赖一个输入值&amp;self，这种情况下，Rust编译器可以自动推导为： 12345impl&lt;&#x27;a&gt; Person&lt;&#x27;a&gt; &#123; fn get_age(&amp;&#x27;a self) -&gt; &amp;&#x27;a u8 &#123; self.age &#125;&#125; 如果输出值（借用）依赖了多个输入值呢？ 123456789impl&lt;&#x27;a, &#x27;b&gt; Person&lt;&#x27;a&gt; &#123; fn get_max_age(&amp;&#x27;a self, p: &amp;&#x27;a Person) -&gt; &amp;&#x27;a u8 &#123; if self.age &gt; p.age &#123; self.age &#125; else &#123; p.age &#125; &#125;&#125; 类似之前的Lifetime推导章节，当返回值（借用）依赖多个输入值时，需显示声明Lifetime。和函数Lifetime同理。 其他 无论在函数还是在struct中，甚至在enum中，Lifetime理论知识都是一样的。希望大家可以慢慢体会和吸收，做到举一反三。","categories":[{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/categories/Programming-language/"},{"name":"Rust","slug":"Programming-language/Rust","permalink":"https://chivier.github.io/categories/Programming-language/Rust/"}],"tags":[{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/tags/Rust/"},{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/tags/Programming-language/"}]},{"title":"Rust-Learning-3","slug":"2021/Rust-Learning-3","date":"2019-04-07T14:26:44.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2019/04/07/2021/Rust-Learning-3/","link":"","permalink":"https://chivier.github.io/2019/04/07/2021/Rust-Learning-3/","excerpt":"Rust学习进阶。","text":"Rust学习进阶。 泛型两个只在名称和签名中类型有所不同的函数 123456789struct Point&lt;T&gt; &#123; x: T, y: T,&#125;fn main() &#123; let integer = Point &#123; x: 5, y: 10 &#125;; let float = Point &#123; x: 1.0, y: 4.0 &#125;;&#125; 用T表示泛型 12345678910struct Point&lt;T, U&gt; &#123; x: T, y: U,&#125;fn main() &#123; let both_integer = Point &#123; x: 5, y: 10 &#125;; let both_float = Point &#123; x: 1.0, y: 4.0 &#125;; let integer_and_float = Point &#123; x: 5, y: 4.0 &#125;;&#125; 如果有不同类型需求，需要这样用U 枚举也可以拥有多个泛型类型。第九章使用过的 Result 枚举定义就是一个这样的例子： 1234enum Result&lt;T, E&gt; &#123; Ok(T), Err(E),&#125; Result 枚举有两个泛型类型，T 和 E。Result 有两个成员：Ok，它存放一个类型 T 的值，而 Err 则存放一个类型 E 的值。这个定义使得 Result 枚举能很方便的表达任何可能成功（返回 T 类型的值）也可能失败（返回 E 类型的值）的操作。 12345impl Point&lt;f32&gt; &#123; fn distance_from_origin(&amp;self) -&gt; f32 &#123; (self.x.powi(2) + self.y.powi(2)).sqrt() &#125;&#125; 这样可以为不同的类型单独设计不同的方法 trait使用trait定义一个特征： 123trait HasArea &#123; fn area(&amp;self) -&gt; f64;&#125; trait里面的函数可以没有函数体，实现代码交给具体实现它的类型去补充： 1234567891011121314151617181920struct Circle &#123; x: f64, y: f64, radius: f64,&#125;impl HasArea for Circle &#123; fn area(&amp;self) -&gt; f64 &#123; std::f64::consts::PI * (self.radius * self.radius) &#125;&#125;fn main() &#123; let c = Circle &#123; x: 0.0f64, y: 0.0f64, radius: 1.0f64, &#125;; println!(&quot;circle c has an area of &#123;&#125;&quot;, c.area());&#125; trait与泛型 我们了解了Rust中trait的定义和使用，接下来我们介绍一下它的使用场景，从中我们可以窥探出接口这特性带来的惊喜 我们知道泛型可以指任意类型，但有时这不是我们想要的，需要给它一些约束。 泛型的trait约束1234use std::fmt::Debug;fn foo&lt;T: Debug&gt;(s: T) &#123; println!(&quot;&#123;:?&#125;&quot;, s);&#125; Debug是Rust内置的一个trait，为”{:?}”实现打印内容，函数foo接受一个泛型作为参数，并且约定其需要实现`Debug 多trait约束可以使用多个trait对泛型进行约束： 12345use std::fmt::Debug;fn foo&lt;T: Debug + Clone&gt;(s: T) &#123; s.clone(); println!(&quot;&#123;:?&#125;&quot;, s);&#125; &lt;T: Debug + Clone&gt;中Debug和Clone使用+连接，标示泛型T需要同时实现这两个trait。 where关键字约束的trait增加后，代码看起来就变得诡异了，这时候需要使用where从句： 12345678910111213141516171819202122use std::fmt::Debug;fn foo&lt;T: Clone, K: Clone + Debug&gt;(x: T, y: K) &#123; x.clone(); y.clone(); println!(&quot;&#123;:?&#125;&quot;, y);&#125;// where 从句fn foo&lt;T, K&gt;(x: T, y: K) where T: Clone, K: Clone + Debug &#123; x.clone(); y.clone(); println!(&quot;&#123;:?&#125;&quot;, y);&#125;// 或者fn foo&lt;T, K&gt;(x: T, y: K) where T: Clone, K: Clone + Debug &#123; x.clone(); y.clone(); println!(&quot;&#123;:?&#125;&quot;, y);&#125; trait与内置类型内置类型如：i32, i64等也可以添加trait实现，为其定制一些功能： 1234567891011trait HasArea &#123; fn area(&amp;self) -&gt; f64;&#125;impl HasArea for i32 &#123; fn area(&amp;self) -&gt; f64 &#123; *self as f64 &#125;&#125;5.area(); 这样的做法是有限制的。Rust 有一个“孤儿规则”：当你为某类型实现某 trait 的时候，必须要求类型或者 trait 至少有一个是在当前 crate 中定义的。你不能为第三方的类型实现第三方的 trait 。 在调用 trait 中定义的方法的时候，一定要记得让这个 trait 可被访问。 1234let mut f = std::fs::File::open(&quot;foo.txt&quot;).ok().expect(&quot;Couldn’t open foo.txt&quot;);let buf = b&quot;whatever&quot;; // buf: &amp;[u8; 8]let result = f.write(buf);# result.unwrap(); 这里是错误： 123error: type &#96;std::fs::File&#96; does not implement any method in scope named &#96;write&#96;let result &#x3D; f.write(buf); ^~~~~~~~~~ 我们需要先use这个Write trait： 123456use std::io::Write;let mut f = std::fs::File::open(&quot;foo.txt&quot;).expect(&quot;Couldn’t open foo.txt&quot;);let buf = b&quot;whatever&quot;;let result = f.write(buf);# result.unwrap(); // ignore the error 这样就能无错误地编译了。 trait的默认方法12345trait Foo &#123; fn is_valid(&amp;self) -&gt; bool; fn is_invalid(&amp;self) -&gt; bool &#123; !self.is_valid() &#125;&#125; is_invalid是默认方法，Foo的实现者并不要求实现它，如果选择实现它，会覆盖掉它的默认行为。 trait的继承1234567trait Foo &#123; fn foo(&amp;self);&#125;trait FooBar : Foo &#123; fn foobar(&amp;self);&#125; 这样FooBar的实现者也要同时实现Foo： 123456789struct Baz;impl Foo for Baz &#123; fn foo(&amp;self) &#123; println!(&quot;foo&quot;); &#125;&#125;impl FooBar for Baz &#123; fn foobar(&amp;self) &#123; println!(&quot;foobar&quot;); &#125;&#125; derive属性Rust提供了一个属性derive来自动实现一些trait，这样可以避免重复繁琐地实现他们，能被derive使用的trait包括：Clone, Copy, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd 123456#[derive(Debug)]struct Foo;fn main() &#123; println!(&quot;&#123;:?&#125;&quot;, Foo);&#125; impl Trait在版本1.26 开始，Rust提供了impl Trait的写法，作为和Scala 对等的既存型别(Existential Type)的写法。 在下面这个写法中，fn foo()将返回一个实作了Trait的trait。 123456789//beforefn foo() -&gt; Box&lt;Trait&gt; &#123; // ...&#125;//afterfn foo() -&gt; impl Trait &#123; // ...&#125; 相较于1.25 版本以前的写法，新的写法会在很多场合中更有利于开发和执行效率。 impl Trait 的普遍用例1234567891011trait Trait &#123; fn method(&amp;self);&#125;impl Trait for i32 &#123; // implementation goes here&#125;impl Trait for f32 &#123; // implementation goes here&#125; 利用Box 会意味：即便回传的内容是固定的，但也会使用到动态内存分配。利用impl Trait 的写法可以避免便用Box。 123456789//beforefn foo() -&gt; Box&lt;Trait&gt; &#123; Box::new(5) as Box&lt;Trait&gt;&#125;//afterfn foo() -&gt; impl Trait &#123; 5&#125; 其他受益的用例闭包: 123456789// beforefn foo() -&gt; Box&lt;Fn(i32) -&gt; i32&gt; &#123; Box::new(|x| x + 1)&#125;// afterfn foo() -&gt; impl Fn(i32) -&gt; i32 &#123; |x| x + 1&#125; 传参： 12345// beforefn foo&lt;T: Trait&gt;(x: T) &#123;// afterfn foo(x: impl Trait) &#123;","categories":[{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/categories/Programming-language/"},{"name":"Rust","slug":"Programming-language/Rust","permalink":"https://chivier.github.io/categories/Programming-language/Rust/"}],"tags":[{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/tags/Rust/"},{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/tags/Programming-language/"}]},{"title":"Rust-Learning-2","slug":"2021/Rust-Learning-2","date":"2019-04-05T09:31:34.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2019/04/05/2021/Rust-Learning-2/","link":"","permalink":"https://chivier.github.io/2019/04/05/2021/Rust-Learning-2/","excerpt":"Rust学习篇，介绍Rust的基础知识。","text":"Rust学习篇，介绍Rust的基础知识。 结构体123456struct User &#123; username: String, email: String, sign_in_count: u64, active: bool,&#125; 一旦定义了结构体后，为了使用它，通过为每个字段指定具体值来创建这个结构体的 实例。 123456let user1 = User &#123; email: String::from(&quot;someone@example.com&quot;), username: String::from(&quot;someusername123&quot;), active: true, sign_in_count: 1,&#125;; 特殊写法变量与字段同名时的字段初始化简写语法 12345678fn build_user(email: String, username: String) -&gt; User &#123; User &#123; email, username, active: true, sign_in_count: 1, &#125;&#125; 结构体更新语法（struct update syntax） 1234567let user2 = User &#123; email: String::from(&quot;another@example.com&quot;), username: String::from(&quot;anotherusername567&quot;), active: user1.active, sign_in_count: user1.sign_in_count,&#125;; 可以简单写成： 12345let user2 = User &#123; email: String::from(&quot;another@example.com&quot;), username: String::from(&quot;anotherusername567&quot;), ..user1&#125;; 无命名字段 我们叫做元组结构体（tuple structs） 12345struct Color(i32, i32, i32);struct Point(i32, i32, i32);let black = Color(0, 0, 0);let origin = Point(0, 0, 0); 我们也可以定义一个没有任何字段的结构体！它们被称为 类单元结构体（unit-like structs） 结构体例子1234567891011121314151617struct Rectangle &#123; width: u32, height: u32,&#125;fn main() &#123; let rect1 = Rectangle &#123; width: 30, height: 50 &#125;; println!( &quot;The area of the rectangle is &#123;&#125; square pixels.&quot;, area(&amp;rect1) );&#125;fn area(rectangle: &amp;Rectangle) -&gt; u32 &#123; rectangle.width * rectangle.height&#125; 让我们来试试！现在 println! 宏调用看起来像 println!(&quot;rect1 is &#123;:?&#125;&quot;, rect1); 这样。在 &#123;&#125; 中加入 :? 指示符告诉 println! 我们想要使用叫做 Debug 的输出格式。Debug 是一个 trait，它允许我们以一种对开发者有帮助的方式打印结构体，以便当我们调试代码时能看到它的值。为此，在结构体定义之前加上 # derive(Debug)] 注解。 1234567891011#[derive(Debug)]struct Rectangle &#123; width: u32, height: u32,&#125;fn main() &#123; let rect1 = Rectangle &#123; width: 30, height: 50 &#125;; println!(&quot;rect1 is &#123;:?&#125;&quot;, rect1);&#125; 1rect1 is Rectangle &#123; width: 30, height: 50 &#125; 方法语法方法方法 与函数类似：它们使用 fn 关键字和名称声明，可以拥有参数和返回值，同时包含在某处调用该方法时会执行的代码。不过方法与函数是不同的，因为它们在结构体的上下文中被定义（或者是枚举或 trait 对象的上下文，将分别在第六章和第十七章讲解），并且它们第一个参数总是 self，它代表调用该方法的结构体实例。 1234567891011121314151617181920#[derive(Debug)]struct Rectangle &#123; width: u32, height: u32,&#125;impl Rectangle &#123; fn area(&amp;self) -&gt; u32 &#123; self.width * self.height &#125;&#125;fn main() &#123; let rect1 = Rectangle &#123; width: 30, height: 50 &#125;; println!( &quot;The area of the rectangle is &#123;&#125; square pixels.&quot;, rect1.area() );&#125; 方法语法（method syntax）在 Rectangle 实例上调用 area 方法。方法语法获取一个实例并加上一个点号，后跟方法名、圆括号以及任何参数。 关联impl 块的另一个有用的功能是：允许在 impl 块中定义 不 以 self 作为参数的函数。这被称为 关联函数（associated functions），因为它们与结构体相关联。它们仍是函数而不是方法，因为它们并不作用于一个结构体的实例。你已经使用过 String::from 关联函数了。 12345impl Rectangle &#123; fn square(size: u32) -&gt; Rectangle &#123; Rectangle &#123; width: size, height: size &#125; &#125;&#125; 使用结构体名和 :: 语法来调用这个关联函数：比如 let sq = Rectangle::square(3);。这个方法位于结构体的命名空间中：:: 语法用于关联函数和模块创建的命名空间。第七章会讲到模块。 枚举类型可以通过在代码中定义一个 IpAddrKind 枚举来表现这个概念并列出可能的 IP 地址类型，V4 和 V6。这被称为枚举的 成员（variants）： 12345enum IpAddrKind &#123; V4, V6,&#125; 枚举值 可以像这样创建 IpAddrKind 两个不同成员的实例： 12let four = IpAddrKind::V4;let six = IpAddrKind::V6; 注意枚举的成员位于其标识符的命名空间中，并使用两个冒号分开。这么设计的益处是现在 IpAddrKind::V4 和 IpAddrKind::V6 都是 IpAddrKind 类型的。例如，接着可以定义一个函数来获取任何 IpAddrKind： 12fn route(ip_type: IpAddrKind) &#123; &#125; 现在可以使用任一成员来调用这个函数： 12route(IpAddrKind::V4);route(IpAddrKind::V6); 使用枚举甚至还有更多优势。进一步考虑一下我们的 IP 地址类型，目前没有一个存储实际 IP 地址 数据 的方法；只知道它是什么 类型 的。 12345678910111213141516171819enum IpAddrKind &#123; V4, V6,&#125;struct IpAddr &#123; kind: IpAddrKind, address: String,&#125;let home = IpAddr &#123; kind: IpAddrKind::V4, address: String::from(&quot;127.0.0.1&quot;),&#125;;let loopback = IpAddr &#123; kind: IpAddrKind::V6, address: String::from(&quot;::1&quot;),&#125;; 用枚举替代结构体还有另一个优势：每个成员可以处理不同类型和数量的数据。IPv4 版本的 IP 地址总是含有四个值在 0 和 255 之间的数字部分。如果我们想要将 V4 地址存储为四个 u8 值而 V6 地址仍然表现为一个 String，这就不能使用结构体了。枚举则可以轻易处理的这个情况： 123456789enum IpAddr &#123; V4(u8, u8, u8, u8), V6(String),&#125;let home = IpAddr::V4(127, 0, 0, 1);let loopback = IpAddr::V6(String::from(&quot;::1&quot;)); 12345678impl Message &#123; fn call(&amp;self) &#123; // 在这里定义方法体 &#125;&#125;let m = Message::Write(String::from(&quot;hello&quot;));m.call(); 有一个非常重要的枚举类型：Option&lt;T&gt; Option文档 match控制流123456789101112131415enum Coin &#123; Penny, Nickel, Dime, Quarter,&#125;fn value_in_cents(coin: Coin) -&gt; u32 &#123; match coin &#123; Coin::Penny =&gt; 1, Coin::Nickel =&gt; 5, Coin::Dime =&gt; 10, Coin::Quarter =&gt; 25, &#125;&#125; 一个分支有两个部分：一个模式和一些代码。第一个分支的模式是值 Coin::Penny 而之后的 =&gt; 运算符将模式和将要运行的代码分开。这里的代码就仅仅是值 1。每一个分支之间使用逗号分隔。 1234567891011fn value_in_cents(coin: Coin) -&gt; u32 &#123; match coin &#123; Coin::Penny =&gt; &#123; println!(&quot;Lucky penny!&quot;); 1 &#125;, Coin::Nickel =&gt; 5, Coin::Dime =&gt; 10, Coin::Quarter =&gt; 25, &#125;&#125; 如果想要在分支中运行多行代码，可以使用大括号。 123456789101112131415161718192021222324252627#[derive(Debug)] // 这样可以可以立刻看到州的名称enum UsState &#123; Alabama, Alaska, // --snip--&#125;enum Coin &#123; Penny, Nickel, Dime, Quarter(UsState),&#125;fn value_in_cents(coin: Coin) -&gt; u32 &#123; match coin &#123; Coin::Penny =&gt; 1, Coin::Nickel =&gt; 5, Coin::Dime =&gt; 10, Coin::Quarter(state) =&gt; &#123; println!(&quot;State quarter from &#123;:?&#125;!&quot;, state); 25 &#125;, &#125;&#125; 如果调用 value_in_cents(Coin::Quarter(UsState::Alaska))，coin 将是 Coin::Quarter(UsState::Alaska)。当将值与每个分支相比较时，没有分支会匹配，直到遇到 Coin::Quarter(state)。这时，state 绑定的将会是值 UsState::Alaska。接着就可以在 println! 表达式中使用这个绑定了，像这样就可以获取 Coin 枚举的 Quarter 成员中内部的州的值。 match枚举必须写齐全match 还有另一方面需要讨论。考虑一下 plus_one 函数的这个版本，它有一个 bug 并不能编译： 123456fn plus_one(x: Option&lt;i32&gt;) -&gt; Option&lt;i32&gt; &#123; match x &#123; Some(i) &#x3D;&gt; Some(i + 1), &#125;&#125; 我们没有处理 None 的情况，所以这些代码会造成一个 bug。幸运的是，这是一个 Rust 知道如何处理的 bug。如果尝试编译这段代码，会得到这个错误： 123456error[E0004]: non-exhaustive patterns: &#96;None&#96; not covered --&gt; |6 | match x &#123; | ^ pattern &#96;None&#96; not covered Rust 知道我们没有覆盖所有可能的情况甚至知道哪些模式被忘记了！Rust 中的匹配是 穷尽的（exhaustive）：必须穷举到最后的可能性来使代码有效。特别的在这个 Option&lt;T&gt; 的例子中，Rust 防止我们忘记明确的处理 None 的情况，这使我们免于假设拥有一个实际上为空的值，这造成了之前提到过的价值亿万的错误。 match通配符Rust 也提供了一个模式用于不想列举出所有可能值的场景。例如，u8 可以拥有 0 到 255 的有效的值，如果我们只关心 1、3、5 和 7 这几个值，就并不想必须列出 0、2、4、6、8、9 一直到 255 的值。所幸我们不必这么做：可以使用特殊的模式 _ 替代： 123456789let some_u8_value &#x3D; 0u8;match some_u8_value &#123; 1 &#x3D;&gt; println!(&quot;one&quot;), 3 &#x3D;&gt; println!(&quot;three&quot;), 5 &#x3D;&gt; println!(&quot;five&quot;), 7 &#x3D;&gt; println!(&quot;seven&quot;), _ &#x3D;&gt; (),&#125; _ 模式会匹配所有的值。通过将其放置于其他分支之后，_ 将会匹配所有之前没有指定的可能的值。() 就是 unit 值，所以 _ 的情况什么也不会发生。因此，可以说我们想要对 _ 通配符之前没有列出的所有可能的值不做任何处理。 if let 简洁控制流if let 语法让我们以一种不那么冗长的方式结合 if 和 let，来处理只匹配一个模式的值而忽略其他模式的情况。考虑示例 6-6 中的程序，它匹配一个 Option&lt;u8&gt; 值并只希望当值为 3 时执行代码： 12345let some_u8_value = Some(0u8);match some_u8_value &#123; Some(3) =&gt; println!(&quot;three&quot;), _ =&gt; (),&#125; 等价于下面的代码 123if let Some(3) = some_u8_value &#123; println!(&quot;three&quot;);&#125; 也可以加上一处else以对操作进行扩展 可以在 if let 中包含一个 else。else 块中的代码与 match 表达式中的 _ 分支块中的代码相同，这样的 match 表达式就等同于 if let 和 else。回忆一下示例 6-4 中 Coin 枚举的定义，其 Quarter 成员也包含一个 UsState 值。如果想要计数所有不是 25 美分的硬币的同时也报告 25 美分硬币所属的州，可以使用这样一个 match 表达式： 123456let mut count = 0;match coin &#123; Coin::Quarter(state) =&gt; println!(&quot;State quarter from &#123;:?&#125;!&quot;, state), _ =&gt; count += 1,&#125; 或者可以使用这样的 if let 和 else 表达式： 1234567let mut count = 0;if let Coin::Quarter(state) = coin &#123; println!(&quot;State quarter from &#123;:?&#125;!&quot;, state);&#125; else &#123; count += 1;&#125; 包、crate、模块让我们聊聊 模块 与 crate。下面是一个总结： crate 是一个二进制或库项目。 crate 根（crate root）是一个用来描述如何构建 crate 的文件。 带有 Cargo.toml 文件的 包 用以描述如何构建一个或多个 crate。一个包中至多可以有一个库项目。 一个包可以带有零个或一个库 crate 和任意多个二进制 crate。一个包中必须带有至少一个（库或者二进制）crate。 如果包同时包含 src/main.rs 和 src/lib.rs，那么它带有两个 crate：一个库和一个二进制项目，同名。如果只有其中之一，则包将只有一个库或者二进制 crate。包可以带有多个二进制 crate，需将其文件置于 src/bin 目录；每个文件将是一个单独的二进制 crate。 模块首先讲讲模块。模块允许我们将代码组织起来。下面的代码定义了名为 sound 的模块，其包含名为 guitar 的函数。 123456789mod sound &#123; fn guitar() &#123; // 函数体 &#125;&#125;fn main() &#123;&#125; 这里定义了两个函数，guitar 和 main。guitar 函数定义于 mod 块中。这个块定义了 sound 模块。 为了将代码组织到模块层次体系中，可以将模块嵌套进其他模块，如示例 7-2 所示： 文件名: src/main.rs 123456789101112131415161718mod sound &#123; mod instrument &#123; mod woodwind &#123; fn clarinet() &#123; // 函数体 &#125; &#125; &#125; mod voice &#123; &#125;&#125;fn main() &#123;&#125; 在 “包和 crate 用来创建库和二进制项目” 部分提到 src/main.rs 和 src/lib.rs 被称为 crate 根。他们被称为 crate 根是因为这两个文件在 crate 模块树的根组成了名为 crate 模块。所以示例 7-2 中，有如示例 7-3 所示的模块树： 123456crate└── sound ├── instrument │ └── woodwind └── voice 如果想要调用函数，需要知道其 路径。“路径” 是 “名称”（“name”） 的同义词，不过它用于文件系统语境。另外，函数、结构体和其他项可能会有多个指向相同项的路径，所以 “名称” 这个概念不太准确。 路径 可以有两种形式： 绝对路径（absolute path）从 crate 根开始，以 crate 名或者字面值 crate 开头。 相对路径（relative path）从当前模块开始，以 self、super 或当前模块的标识符开头。 绝对路径和相对路径都后跟一个或多个由双冒号（::）分割的标识符。 模块私有性之前我们讨论到模块的语法和组织代码的用途。Rust 采用模块还有另一个原因：模块是 Rust 中的 私有性边界（privacy boundary）。如果你希望函数或结构体是私有的，将其放入模块。私有性规则有如下： 所有项（函数、方法、结构体、枚举、模块和常量）默认是私有的。 可以使用 pub 关键字使项变为公有。 不允许使用定义于当前模块的子模块中的私有代码。 允许使用任何定义于父模块或当前模块中的代码。 换句话说，对于没有 pub 关键字的项，当你从当前模块向 “下” 看时是私有的，不过当你向 “上” 看时是公有的。再一次想象一下文件系统：如果你没有某个目录的权限，则无法从父目录中查看其内容。如果有该目录的权限，则可以查看其中的目录和任何父目录。 现在的错误表明 clarinet 函数是私有的。私有性规则适用于结构体、枚举、函数和方法以及模块。 在 clarinet 函数前增加 pub 关键字使其变为公有，如示例 7-8 所示： 文件名: src/main.rs 12345678910111213141516mod sound &#123; pub mod instrument &#123; pub fn clarinet() &#123; // 函数体 &#125; &#125;&#125;fn main() &#123; // 绝对路径 crate::sound::instrument::clarinet(); // 相对路径 sound::instrument::clarinet();&#125; 也可以使用 super 开头来构建相对路径。这么做类似于文件系统中以 .. 开头：该路径从 父 模块开始而不是当前模块。这在例如示例 7-9 这样的情况下有用处，在这里 clarinet 函数通过指定以 super 开头的路径调用 breathe_in 函数： 文件名: src/lib.rs 12345678910mod instrument &#123; fn clarinet() &#123; super::breathe_in(); &#125;&#125;fn breathe_in() &#123; // 函数体&#125; clarinet 函数位于 instrument 模块中，所以可以使用 super 进入 instrument 的父模块，也就是根 crate。从这里可以找到 breathe_in。成功！ 你可能想要使用 super 开头的相对路而不是以 crate 开头的绝对路径的原因是 super 可能会使修改有着不同模块层级结构的代码变得更容易，如果定义项和调用项的代码被一同移动的话。例如，如果我们决定将 instrument 模块和 breathe_in 函数放入 sound 模块中，这时我们只需增加 sound 模块即可，如示例 7-10 所示。 文件名: src/lib.rs 1234567891011mod sound &#123; mod instrument &#123; fn clarinet() &#123; super::breathe_in(); &#125; &#125; fn breathe_in() &#123; // 函数体 &#125;&#125; 结构体和枚举类型的pub12345678910111213141516171819202122232425mod plant &#123; pub struct Vegetable &#123; pub name: String, id: i32, &#125; impl Vegetable &#123; pub fn new(name: &amp;str) -&gt; Vegetable &#123; Vegetable &#123; name: String::from(name), id: 1, &#125; &#125; &#125;&#125;fn main() &#123; let mut v = plant::Vegetable::new(&quot;squash&quot;); v.name = String::from(&quot;butternut squash&quot;); println!(&quot;&#123;&#125; are delicious&quot;, v.name); // 如果将如下行取消注释代码将无法编译: // println!(&quot;The ID is &#123;&#125;&quot;, v.id);&#125; 1234567891011mod menu &#123; pub enum Appetizer &#123; Soup, Salad, &#125;&#125;fn main() &#123; let order1 = menu::Appetizer::Soup; let order2 = menu::Appetizer::Salad;&#125; use 缩短关键路径123456789101112131415mod sound &#123; pub mod instrument &#123; pub fn clarinet() &#123; // 函数体 &#125; &#125;&#125;use crate::sound::instrument;fn main() &#123; instrument::clarinet(); instrument::clarinet(); instrument::clarinet();&#125; 123456789101112131415161718192021mod sound &#123; pub mod instrument &#123; pub fn clarinet() &#123; // 函数体 &#125; &#125;&#125;mod performance_group &#123; use crate::sound::instrument; pub fn clarinet_trio() &#123; instrument::clarinet(); instrument::clarinet(); instrument::clarinet(); &#125;&#125;fn main() &#123; performance_group::clarinet_trio();&#125; 示例 7-13 中，你可能会好奇为什么指定 use crate::sound::instrument 接着在 main 中调用 instrument::clarinet，而不是如示例 7-16 所示的有相同行为的代码： 文件名: src/main.rs 12345678910111213141516mod sound &#123; pub mod instrument &#123; pub fn clarinet() &#123; &#x2F;&#x2F; 函数体 &#125; &#125;&#125;use crate::sound::instrument::clarinet;fn main() &#123; clarinet(); clarinet(); clarinet();&#125; 示例 7-16: 通过 use 将 clarinet 函数引入作用域，这是不推荐的 对于函数来说，通过 use 指定函数的父模块接着指定父模块来调用方法被认为是习惯用法。这么做而不是像示例 7-16 那样通过 use 指定函数的路径，清楚的表明了函数不是本地定义的，同时仍最小化了指定全路径时的重复。 对于结构体、枚举和其它项，通过 use 指定项的全路径是习惯用法。例如，示例 7-17 展示了将标准库中 HashMap 结构体引入作用域的习惯用法。 as关键字将两个同名类型引入同一作用域这个问题还有另一个解决办法：可以通过在 use 后加上 as 和一个新名称来为此类型指定一个新的本地名称。示例 7-20 展示了另一个编写示例 7-19 中代码的方法，通过 as 重命名了其中一个 Result 类型。 文件名: src/lib.rs 1234567use std::fmt::Result;use std::io::Result as IoResult;fn function1() -&gt; Result &#123;&#125;fn function2() -&gt; IoResult&lt;()&gt; &#123;&#125; pub use当使用 use 关键字将名称导入作用域时，在新作用域中可用的名称是私有的。如果希望调用你编写的代码的代码能够像你一样在其自己的作用域内引用这些类型，可以结合 pub 和 use。这个技术被称为 “重导出”（re-exporting），因为这样做将项引入作用域并同时使其可供其他代码引入自己的作用域。 例如，示例 7-21 展示了示例 7-15 中的代码将 performance_group 的 use 变为 pub use 的版本。 12345678910111213141516171819202122mod sound &#123; pub mod instrument &#123; pub fn clarinet() &#123; // 函数体 &#125; &#125;&#125;mod performance_group &#123; pub use crate::sound::instrument; pub fn clarinet_trio() &#123; instrument::clarinet(); instrument::clarinet(); instrument::clarinet(); &#125;&#125;fn main() &#123; performance_group::clarinet_trio(); performance_group::instrument::clarinet();&#125; 外部包在 Cargo.toml 中加入 rand 依赖告诉了 Cargo 要从 https://crates.io 下载 rand 和其依赖，并使其可在项目代码中使用。 接着，为了将 rand 定义引入项目包的作用域，加入一行 use，它以 rand 包名开头并列出了需要引入作用域的项。回忆一下第二章的 “生成一个随机数” 部分，我们曾将 Rng trait 引入作用域并调用了 rand::thread_rng 函数： 12345use rand::Rng;fn main() &#123; let secret_number = rand::thread_rng().gen_range(1, 101);&#125; 注意标准库（std）对于你的包来说也是外部 crate。因为标准库随 Rust 语言一同分发，无需修改 Cargo.toml 来引入 std，不过需要通过 use 将标准库中定义的项引入项目包的作用域中来引用它们，比如 HashMap： 1use std::collections::HashMap; 这是一个以标注库 crate 名 std 开头的绝对路径。 通用集合类型vectorvector 允许我们在一个单独的数据结构中储存多于一个的值，它在内存中彼此相邻地排列所有的值。vector 只能储存相同类型的值。 创建vector1let v: Vec&lt;i32&gt; = Vec::new(); 1let v = vec![1, 2, 3]; vec！为Rust自带的宏 更新vector123456let mut v = Vec::new();v.push(5);v.push(6);v.push(7);v.push(8); vector作用域丢弃 vector 时也会丢弃其所有元素 类似于任何其他的 struct，vector 在其离开作用域时会被释放，如示例 8-4 所标注的： 1234567&#123; let v &#x3D; vec![1, 2, 3, 4]; &#x2F;&#x2F; 处理变量 v&#125; &#x2F;&#x2F; &lt;- 这里 v 离开作用域并被丢弃 示例 8-4：展示 vector 和其元素于何处被丢弃 当 vector 被丢弃时，所有其内容也会被丢弃，这意味着这里它包含的整数将被清理。这可能看起来非常直观，不过一旦开始使用 vector 元素的引用，情况就变得有些复杂了。 读取vector元素的方法现在你知道如何创建、更新和销毁 vector 了，接下来的一步最好了解一下如何读取它们的内容。有两种方法引用 vector 中储存的值。为了更加清楚的说明这个例子，我们标注这些函数返回的值的类型。 展示了访问 vector 中一个值的两种方式，索引语法或者 get 方法： 123456789let v = vec![1, 2, 3, 4, 5];let third: &amp;i32 = &amp;v[2];println!(&quot;The third element is &#123;&#125;&quot;, third);match v.get(2) &#123; Some(third) =&gt; println!(&quot;The third element is &#123;&#125;&quot;, third), None =&gt; println!(&quot;There is no third element.&quot;),&#125; 这里有两个需要注意的地方。首先，我们使用索引值 2 来获取第三个元素，索引是从 0 开始的。其次，这两个不同的获取第三个元素的方式分别为：使用 &amp; 和 [] 返回一个引用；或者使用 get 方法以索引作为参数来返回一个 Option&lt;&amp;T&gt;。 遍历 vector 中的元素如果想要依次访问 vector 中的每一个元素，我们可以遍历其所有的元素而无需通过索引一次一个的访问。示例 8-8 展示了如何使用 for 循环来获取 i32 值的 vector 中的每一个元素的不可变引用并将其打印： 12345let v &#x3D; vec![100, 32, 57];for i in &amp;v &#123; println!(&quot;&#123;&#125;&quot;, i);&#125; 示例 8-8：通过 for 循环遍历 vector 的元素并打印 我们也可以遍历可变 vector 的每一个元素的可变引用以便能改变他们。示例 8-9 中的 for 循环会给每一个元素加 50： 12345let mut v &#x3D; vec![100, 32, 57];for i in &amp;mut v &#123; *i +&#x3D; 50;&#125; 示例8-9：遍历 vector 中元素的可变引用 为了修改可变引用所指向的值，在使用 += 运算符之前必须使用解引用运算符（*）获取 i 中的值。第十五章会详细介绍 *。 使用枚举来储存多种类型在本章的开始，我们提到 vector 只能储存相同类型的值。这是很不方便的；绝对会有需要储存一系列不同类型的值的用例。幸运的是，枚举的成员都被定义为相同的枚举类型，所以当需要在 vector 中储存不同类型值时，我们可以定义并使用一个枚举！ 例如，假如我们想要从电子表格的一行中获取值，而这一行的有些列包含数字，有些包含浮点值，还有些是字符串。我们可以定义一个枚举，其成员会存放这些不同类型的值，同时所有这些枚举成员都会被当作相同类型，那个枚举的类型。接着可以创建一个储存枚举值的 vector，这样最终就能够储存不同类型的值了。示例 8-10 展示了其用例： 123456789101112enum SpreadsheetCell &#123; Int(i32), Float(f64), Text(String),&#125;let row = vec![ SpreadsheetCell::Int(3), SpreadsheetCell::Text(String::from(&quot;blue&quot;)), SpreadsheetCell::Float(10.12),]; String新建String1let mut s = String::new(); 这新建了一个叫做 s 的空的字符串，接着我们可以向其中装载数据。通常字符串会有初始数据，因为我们希望一开始就有这个字符串。为此，可以使用 to_string 方法，它能用于任何实现了 Display trait 的类型，字符串字面值也实现了它。示例 8-12 展示了两个例子。 123456let data = &quot;initial contents&quot;;let s = data.to_string();// 该方法也可直接用于字符串字面值：let s = &quot;initial contents&quot;.to_string(); 1let s = String::from(&quot;initial contents&quot;); 实际上，from方法和to_string方法并没有本质区别 更新String12let mut s = String::from(&quot;foo&quot;);s.push_str(&quot;bar&quot;); 示例 8-15：使用 push_str 方法向 String 附加字符串 slice 1234let mut s1 = String::from(&quot;foo&quot;);let s2 = &quot;bar&quot;;s1.push_str(s2);println!(&quot;s2 is &#123;&#125;&quot;, s2); 示例 8-16：将字符串 slice 的内容附加到 String 后使用它 12let mut s = String::from(&quot;lo&quot;);s.push(&#x27;l&#x27;); 示例 8-17：使用 push 将一个字符加入 String 值中 使用 + 运算符或 format! 宏拼接字符串 通常你会希望将两个已知的字符串合并在一起。一种办法是像这样使用 + 运算符，如示例 8-18 所示。 123let s1 = String::from(&quot;Hello, &quot;);let s2 = String::from(&quot;world!&quot;);let s3 = s1 + &amp;s2; // 注意 s1 被移动了，不能继续使用 示例 8-18：使用 + 运算符将两个 String 值合并到一个新的 String 值中 如果想要级联多个字符串，+ 的行为就显得笨重了： 12345let s1 = String::from(&quot;tic&quot;);let s2 = String::from(&quot;tac&quot;);let s3 = String::from(&quot;toe&quot;);let s = s1 + &quot;-&quot; + &amp;s2 + &quot;-&quot; + &amp;s3; 这时 s 的内容会是 “tic-tac-toe”。在有这么多 + 和 &quot; 字符的情况下，很难理解具体发生了什么。对于更为复杂的字符串链接，可以使用 format! 宏： 12345let s1 = String::from(&quot;tic&quot;);let s2 = String::from(&quot;tac&quot;);let s3 = String::from(&quot;toe&quot;);let s = format!(&quot;&#123;&#125;-&#123;&#125;-&#123;&#125;&quot;, s1, s2, s3); 索引字符串在很多语言中，通过索引来引用字符串中的单独字符是有效且常见的操作。然而在 Rust 中，如果你尝试使用索引语法访问 String 的一部分，会出现一个错误。考虑一下如示例 8-19 中所示的无效代码。 123let s1 &#x3D; String::from(&quot;hello&quot;);let h &#x3D; s1[0]; 示例 8-19：尝试对字符串使用索引语法 会导致如下错误： 12345678error[E0277]: the trait bound &#96;std::string::String: std::ops::Index&lt;&#123;integer&#125;&gt;&#96; is not satisfied --&gt; |3 | let h &#x3D; s1[0]; | ^^^^^ the type &#96;std::string::String&#96; cannot be indexed by &#96;&#123;integer&#125;&#96; | &#x3D; help: the trait &#96;std::ops::Index&lt;&#123;integer&#125;&gt;&#96; is not implemented for &#96;std::string::String&#96; 错误和提示说明了全部问题：Rust 的字符串不支持索引。 字节、标量值和字形簇！天呐！ 这引起了关于 UTF-8 的另外一个问题：从 Rust 的角度来讲，事实上有三种相关方式可以理解字符串：字节、标量值和字形簇（最接近人们眼中 字母 的概念）。 比如这个用梵文书写的印度语单词 “नमस्ते”，最终它储存在 vector 中的 u8 值看起来像这样： 123[224, 164, 168, 224, 164, 174, 224, 164, 184, 224, 165, 141, 224, 164, 164,224, 165, 135] 这里有 18 个字节，也就是计算机最终会储存的数据。如果从 Unicode 标量值的角度理解它们，也就像 Rust 的 char 类型那样，这些字节看起来像这样： 12[&#39;न&#39;, &#39;म&#39;, &#39;स&#39;, &#39;्&#39;, &#39;त&#39;, &#39;े&#39;] 这里有六个 char，不过第四个和第六个都不是字母，它们是发音符号本身并没有任何意义。最后，如果以字形簇的角度理解，就会得到人们所说的构成这个单词的四个字母： 12[&quot;न&quot;, &quot;म&quot;, &quot;स्&quot;, &quot;ते&quot;] 字符串 slice 索引字符串通常是一个坏点子，因为字符串索引应该返回的类型是不明确的：字节值、字符、字形簇或者字符串 slice。因此，如果你真的希望使用索引创建字符串 slice 时 Rust 会要求你更明确一些。为了更明确索引并表明你需要一个字符串 slice，相比使用 [] 和单个值的索引，可以使用 [] 和一个 range 来创建含特定字节的字符串 slice： 1234let hello &#x3D; &quot;Здравствуйте&quot;;let s &#x3D; &amp;hello[0..4]; 这里，s 会是一个 &amp;str，它包含字符串的头四个字节。早些时候，我们提到了这些字母都是两个字节长的，所以这意味着 s 将会是 “Зд”。 如果获取 &amp;hello[0..1] 会发生什么呢？答案是：在运行时会 panic，就跟访问 vector 中的无效索引时一样： 12thread &#39;main&#39; panicked at &#39;byte index 1 is not a char boundary; it is inside &#39;З&#39; (bytes 0..2) of &#96;Здравствуйте&#96;&#39;, src&#x2F;libcore&#x2F;str&#x2F;mod.rs:2188:4 你应该小心谨慎的使用这个操作，因为这么做可能会使你的程序崩溃。 遍历字符串的方法幸运的是，这里还有其他获取字符串元素的方式。 如果你需要操作单独的 Unicode 标量值，最好的选择是使用 chars 方法。对 “नमस्ते” 调用 chars 方法会将其分开并返回六个 char 类型的值，接着就可以遍历其结果来访问每一个元素了： 1234for c in &quot;नमस्ते&quot;.chars() &#123; println!(&quot;&#123;&#125;&quot;, c);&#125; 这些代码会打印出如下内容： 1234567नमस्ते bytes 方法返回每一个原始字节，这可能会适合你的使用场景： 1234for b in &quot;नमस्ते&quot;.bytes() &#123; println!(&quot;&#123;&#125;&quot;, b);&#125; 这些代码会打印出组成 String 的 18 个字节： 123456224164&#x2F;&#x2F; --snip--165135 不过请记住有效的 Unicode 标量值可能会由不止一个字节组成。 从字符串中获取字形簇是很复杂的，所以标准库并没有提供这个功能。crates.io 上有些提供这样功能的 crate。 Hash map新建Hash123456use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(&quot;Blue&quot;), 10);scores.insert(String::from(&quot;Yellow&quot;), 50); 新建哈希 map 并插入一些键值对 另一个构建哈希 map 的方法是使用一个元组的 vector 的 collect 方法 123456use std::collections::HashMap;let teams = vec![String::from(&quot;Blue&quot;), String::from(&quot;Yellow&quot;)];let initial_scores = vec![10, 50];let scores: HashMap&lt;_, _&gt; = teams.iter().zip(initial_scores.iter()).collect(); 这里 HashMap&lt;_, _&gt; 类型注解是必要的，因为可能 collect 很多不同的数据结构，而除非显式指定否则 Rust 无从得知你需要的类型。但是对于键和值的类型参数来说，可以使用下划线占位，而 Rust 能够根据 vector 中数据的类型推断出 HashMap 所包含的类型。 哈希 map 和所有权对于像 i32 这样的实现了 Copy trait 的类型，其值可以拷贝进哈希 map。对于像 String 这样拥有所有权的值，其值将被移动而哈希 map 会成为这些值的所有者 12345678use std::collections::HashMap;let field_name = String::from(&quot;Favorite color&quot;);let field_value = String::from(&quot;Blue&quot;);let mut map = HashMap::new();map.insert(field_name, field_value);// 这里 field_name 和 field_value 不再有效， 访问哈希 map 中的值可以通过 get 方法并提供对应的键来从哈希 map 中获取值 123456789use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(&quot;Blue&quot;), 10);scores.insert(String::from(&quot;Yellow&quot;), 50);let team_name = String::from(&quot;Blue&quot;);let score = scores.get(&amp;team_name); 这里，score 是与蓝队分数相关的值，应为 Some(10)。因为 get 返回 Option&lt;V&gt;，所以结果被装进 Some；如果某个键在哈希 map 中没有对应的值，get 会返回 None。 可以使用与 vector 类似的方式来遍历哈希 map 中的每一个键值对，也就是 for 循环： 1234567891011use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(&quot;Blue&quot;), 10);scores.insert(String::from(&quot;Yellow&quot;), 50);for (key, value) in &amp;scores &#123; println!(&quot;&#123;&#125;: &#123;&#125;&quot;, key, value);&#125; 更新哈希 map覆盖一个值如果我们插入了一个键值对，接着用相同的键插入一个不同的值，与这个键相关联的旧值将被替换。即便示例 8-24 中的代码调用了两次 insert，哈希 map 也只会包含一个键值对，因为两次都是对蓝队的键插入的值： 123456789use std::collections::HashMap;let mut scores &#x3D; HashMap::new();scores.insert(String::from(&quot;Blue&quot;), 10);scores.insert(String::from(&quot;Blue&quot;), 25);println!(&quot;&#123;:?&#125;&quot;, scores); 示例 8-24：替换以特定键储存的值 这会打印出 &#123;&quot;Blue&quot;: 25&#125;。原始的值 10 则被覆盖了。 没有对应值时插入我们经常会检查某个特定的键是否有值，如果没有就插入一个值。为此哈希 map 有一个特有的 API，叫做 entry，它获取我们想要检查的键作为参数。entry 函数的返回值是一个枚举，Entry，它代表了可能存在也可能不存在的值。比如说我们想要检查黄队的键是否关联了一个值。如果没有，就插入值 50，对于蓝队也是如此。使用 entry API 的代码看起来像示例 8-25 这样： 123456789use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(&quot;Blue&quot;), 10);scores.entry(String::from(&quot;Yellow&quot;)).or_insert(50);scores.entry(String::from(&quot;Blue&quot;)).or_insert(50);println!(&quot;&#123;:?&#125;&quot;, scores);","categories":[{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/categories/Programming-language/"},{"name":"Rust","slug":"Programming-language/Rust","permalink":"https://chivier.github.io/categories/Programming-language/Rust/"}],"tags":[{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/tags/Rust/"},{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/tags/Programming-language/"}]},{"title":"Rust-Learning-1","slug":"2021/Rust-Learning-1","date":"2019-04-05T07:31:34.000Z","updated":"2021-12-23T04:47:00.000Z","comments":true,"path":"2019/04/05/2021/Rust-Learning-1/","link":"","permalink":"https://chivier.github.io/2019/04/05/2021/Rust-Learning-1/","excerpt":"Rust学习篇，介绍Rust的基础知识。","text":"Rust学习篇，介绍Rust的基础知识。 基本概念变量变量默认是不可改变的（immutable） 1let x = 5; 可变： 1let mut x = 5; 不允许对常量使用 mut。常量不光默认不能变，它总是不能变。声明常量使用 const 关键字而不是 let，并且 必须 注明值的类型。 1const MAX_POINTS: u32 = 100_000; 新变量会 隐藏 之前的变量 123456fn main() &#123; let x = 5; let x = x + 1; let x = x * 2; println!(&quot;The value of x is: &#123;&#125;&quot;, x);&#125; 变量类型标量类型标量（scalar）类型代表一个单独的值。Rust 有四种基本的标量类型：整型、浮点型、布尔类型和字符类型。你可能在其他语言中见过它们。让我们深入了解它们在 Rust 中是如何工作的。 整型 整数 是一个没有小数部分的数字。我们在第二章使用过 u32 整数类型。该类型声明表明，它关联的值应该是一个占据 32 比特位的无符号整数（有符号整数类型以 i 开头而不是 u）。 Rust 中的整型 长度 有符号 无符号 8-bit i8 u8 16-bit i16 u16 32-bit i32 u32 64-bit i64 u64 arch isize usize Rust 中的整型字面值 数字字面值 例子 Decimal 98_222 Hex 0xff Octal 0o77 Binary 0b1111_0000 Byte (u8 only) b&#39;A&#39; 浮点类型Rust 也有两个原生的 浮点数（floating-point numbers）类型，它们是带小数点的数字。Rust 的浮点数类型是 f32 和 f64。默认类型是 f64。 bool类型正如其他大部分编程语言一样，Rust 中的布尔类型有两个可能的值：true 和 false。Rust 中的布尔类型使用 bool 表示。 字符类型目前为止只使用到了数字，不过 Rust 也支持字母。Rust 的 char 类型是语言中最原生的字母类型，如下代码展示了如何使用它。（注意 char 由单引号指定，不同于字符串使用双引号。） 12345fn main() &#123; let c = &#x27;z&#x27;; let z = &#x27;ℤ&#x27;; let heart_eyed_cat = &#x27;😻&#x27;;&#125; 复合类型元组123fn main() &#123; let tup: (i32, f64, u8) = (500, 6.4, 1);&#125; tup 变量绑定到整个元组上，因为元组是一个单独的复合元素。为了从元组中获取单个值，可以使用模式匹配（pattern matching）来解构（destructure）元组值，像这样： 12345fn main() &#123; let tup = (500, 6.4, 1); let (x, y, z) = tup; println!(&quot;The value of y is: &#123;&#125;&quot;, y);&#125; 访问元组元素使用. 123456789fn main() &#123; let x: (i32, f64, u8) = (500, 6.4, 1); let five_hundred = x.0; let six_point_four = x.1; let one = x.2;&#125; 数组123fn main() &#123; let a = [1, 2, 3, 4, 5];&#125; 与元组不同，数组中的每个元素的类型必须相同。Rust 中的数组与一些其他语言中的数组不同，因为 Rust 中的数组是固定长度的：一旦声明，它们的长度不能增长或缩小。 1let a: [i32; 5] = [1, 2, 3, 4, 5]; [type:number]用于表示数组的类型 访问方式同C，用中括号 String 类型1let s = String::from(&quot;hello&quot;); 可以 修改此类字符串 ： 123456let mut s = String::from(&quot;hello&quot;);s.push_str(&quot;, world!&quot;); // push_str() 在字符串后追加字面值println!(&quot;&#123;&#125;&quot;, s); // 将打印 `hello, world!` 函数fn 关键字，它用来声明新函数 例子： 1234567fn main() &#123; another_function(5);&#125;fn another_function(x: i32) &#123; println!(&quot;The value of x is: &#123;&#125;&quot;, x);&#125; 语句和表达式12345678910fn main() &#123; let x = 5; let y = &#123; let x = 3; x + 1 &#125;; println!(&quot;The value of y is: &#123;&#125;&quot;, y);&#125; 分号视作是语句的结束，如果没有分号结尾，我们默认认为最后的语句用于作为返回值。 函数如果有返回值的话我们需要使用-&gt;用于表示返回值类型。 123456789fn five() -&gt; i32 &#123; 5&#125;fn main() &#123; let x = five(); println!(&quot;The value of x is: &#123;&#125;&quot;, x);&#125; 控制流分支123456789fn main() &#123; let number = 3; if number &lt; 5 &#123; println!(&quot;condition was true&quot;); &#125; else &#123; println!(&quot;condition was false&quot;); &#125;&#125; 12345678910fn main() &#123; let condition = true; let number = if condition &#123; 5 &#125; else &#123; 6 &#125;; println!(&quot;The value of number is: &#123;&#125;&quot;, number);&#125; 需要注意的是如果使用下面的赋值分支，我们每个分支内部的返回值类型都需要设置为同一类型。 循环loop12345fn main() &#123; loop &#123; println!(&quot;again!&quot;); &#125;&#125; loop用于执行死循环，可以用break跳出循环 12345678910111213fn main() &#123; let mut counter = 0; let result = loop &#123; counter += 1; if counter == 10 &#123; break counter * 2; &#125; &#125;; assert_eq!(result, 20);&#125; break的用法不同与我们的C，有返回值 while1234567891011fn main() &#123; let mut number = 3; while number != 0 &#123; println!(&quot;&#123;&#125;!&quot;, number); number = number - 1; &#125; println!(&quot;LIFTOFF!!!&quot;);&#125; for123456fn main() &#123; let a = [10, 20, 30, 40, 50]; for element in a.iter() &#123; println!(&quot;the value is: &#123;&#125;&quot;, element); &#125; 123456fn main() &#123; for number in (1..4).rev() &#123; println!(&quot;&#123;&#125;!&quot;, number); &#125; println!(&quot;LIFTOFF!!!&quot;);&#125; 所有权作为Rust独有的新概念 Rust 中的每一个值都有一个被称为其 所有者（owner）的变量。 值有且只有一个所有者。 当所有者（变量）离开作用域，这个值将被丢弃。 作用域（scope）这个变量从声明的点开始直到当前 作用域 结束时都是有效的。 12345&#123; // s 在这里无效, 它尚未声明 let s = &quot;hello&quot;; // 从此处起，s 是有效的 // 使用 s&#125; // 此作用域已结束，s 不再有效 变量与数据交互移动12let s1 = String::from(&quot;hello&quot;);let s2 = s1; 此时s1失效，不再有用 我们称作s1被移到s2中 克隆1234let s1 = String::from(&quot;hello&quot;);let s2 = s1.clone();println!(&quot;s1 = &#123;&#125;, s2 = &#123;&#125;&quot;, s1, s2); 此时s1和s2都是有效的 拷贝1234let x = 5;let y = x;println!(&quot;x = &#123;&#125;, y = &#123;&#125;&quot;, x, y); 没有调用 clone，不过 x 依然有效且没有被移动到 y 中 Rust 有一个叫做 Copy trait 的特殊注解，可以用在类似整型这样的存储在栈上的类型上（第十章详细讲解 trait）。如果一个类型拥有 Copy trait，一个旧的变量在将其赋值给其他变量后仍然可用。 如下是一些 Copy 的类型： 所有整数类型，比如 u32。 布尔类型，bool，它的值是 true 和 false。 所有浮点数类型，比如 f64。 字符类型，char。 元组，当且仅当其包含的类型也都是 Copy 的时候。比如，(i32, i32) 是 Copy 的，但 (i32, String) 就不是。 例子123456789101112131415161718192021fn main() &#123; let s = String::from(&quot;hello&quot;); // s 进入作用域 takes_ownership(s); // s 的值移动到函数里 ... // ... 所以到这里不再有效 let x = 5; // x 进入作用域 makes_copy(x); // x 应该移动函数里， // 但 i32 是 Copy 的，所以在后面可继续使用 x&#125; // 这里, x 先移出了作用域，然后是 s。但因为 s 的值已被移走， // 所以不会有特殊操作fn takes_ownership(some_string: String) &#123; // some_string 进入作用域 println!(&quot;&#123;&#125;&quot;, some_string);&#125; // 这里，some_string 移出作用域并调用 `drop` 方法。占用的内存被释放fn makes_copy(some_integer: i32) &#123; // some_integer 进入作用域 println!(&quot;&#123;&#125;&quot;, some_integer);&#125; // 这里，some_integer 移出作用域。不会有特殊操作 12345678910111213141516171819202122232425fn main() &#123; let s1 = gives_ownership(); // gives_ownership 将返回值 // 移给 s1 let s2 = String::from(&quot;hello&quot;); // s2 进入作用域 let s3 = takes_and_gives_back(s2); // s2 被移动到 // takes_and_gives_back 中, // 它也将返回值移给 s3&#125; // 这里, s3 移出作用域并被丢弃。s2 也移出作用域，但已被移走， // 所以什么也不会发生。s1 移出作用域并被丢弃fn gives_ownership() -&gt; String &#123; // gives_ownership 将返回值移动给 // 调用它的函数 let some_string = String::from(&quot;hello&quot;); // some_string 进入作用域. some_string // 返回 some_string 并移出给调用的函数&#125;// takes_and_gives_back 将传入字符串并返回该值fn takes_and_gives_back(a_string: String) -&gt; String &#123; // a_string 进入作用域 a_string // 返回 a_string 并移出给调用的函数&#125; 变量的所有权总是遵循相同的模式：将值赋给另一个变量时移动它。当持有堆中数据值的变量离开作用域时，其值将通过 drop 被清理掉，除非数据被移动为另一个变量所有。 在每一个函数中都获取所有权并接着返回所有权有些啰嗦。如果我们想要函数使用一个值但不获取所有权该怎么办呢？如果我们还要接着使用它的话，每次都传进去再返回来就有点烦人了，除此之外，我们也可能想返回函数体中产生的一些数据。我们可以使用元组来返回多个值。 12345678910111213fn main() &#123; let s1 = String::from(&quot;hello&quot;); let (s2, len) = calculate_length(s1); println!(&quot;The length of &#x27;&#123;&#125;&#x27; is &#123;&#125;.&quot;, s2, len);&#125;fn calculate_length(s: String) -&gt; (String, usize) &#123; let length = s.len(); // len() 返回字符串的长度 (s, length)&#125; 引用和借用一般引用1234567891011fn main() &#123; let s1 = String::from(&quot;hello&quot;); let len = calculate_length(&amp;s1); println!(&quot;The length of &#x27;&#123;&#125;&#x27; is &#123;&#125;.&quot;, s1, len);&#125;fn calculate_length(s: &amp;String) -&gt; usize &#123; s.len()&#125; 注意我们传递 &amp;s1 给 calculate_length，同时在函数定义中，我们获取 &amp;String 而不是 String。 这些 &amp; 符号就是 引用，它们允许你使用值但不获取其所有权。 1234fn calculate_length(s: &amp;String) -&gt; usize &#123; // s 是对 String 的引用 s.len()&#125; // 这里，s 离开了作用域。但因为它并不拥有引用值的所有权， // 所以什么也不会发生 我们将获取引用作为函数参数称为 借用（borrowing）。正如现实生活中，如果一个人拥有某样东西，你可以从他那里借来。当你使用完毕，必须还回去。我们尝试修改借用的变量是不可能的。 可变引用123456789fn main() &#123; let mut s = String::from(&quot;hello&quot;); change(&amp;mut s);&#125;fn change(some_string: &amp;mut String) &#123; some_string.push_str(&quot;, world&quot;);&#125; 不过可变引用有一个很大的限制：在特定作用域中的特定数据有且只有一个可变引用。 这个限制的好处是 Rust 可以在编译时就避免数据竞争。数据竞争（data race）类似于竞态条件，它可由这三个行为造成： 两个或更多指针同时访问同一数据。 至少有一个指针被用来写入数据。 没有同步数据访问的机制。 一如既往，可以使用大括号来创建一个新的作用域，以允许拥有多个可变引用，只是不能 同时 拥有. 123456let mut s = String::from(&quot;hello&quot;);let r1 = &amp;mut s;let r2 = &amp;mut s;//ERRORprintln!(&quot;&#123;&#125;, &#123;&#125;&quot;, r1, r2); 类似的规则也存在于同时使用可变与不可变引用中。我们不能同时有可变和不可变的引用。 1234567let mut s = String::from(&quot;hello&quot;);let r1 = &amp;s; // no problemlet r2 = &amp;s; // no problemlet r3 = &amp;mut s; // BIG PROBLEMprintln!(&quot;&#123;&#125;, &#123;&#125;, and &#123;&#125;&quot;, r1, r2, r3); 悬垂引用在具有指针的语言中，很容易通过释放内存时保留指向它的指针而错误地生成一个 悬垂指针（dangling pointer），所谓悬垂指针是其指向的内存可能已经被分配给其它持有者。相比之下，在 Rust 中编译器确保引用永远也不会变成悬垂状态：当你拥有一些数据的引用，编译器确保数据不会在其引用之前离开作用域。 123456789fn main() &#123; let reference_to_nothing = dangle();&#125;fn dangle() -&gt; &amp;String &#123; let s = String::from(&quot;hello&quot;); &amp;s&#125; 错误信息引用了一个我们还未介绍的功能：生命周期（lifetimes）。 因为 s 是在 dangle 函数内创建的，当 dangle 的代码执行完毕后，s 将被释放。不过我们尝试返回它的引用。这意味着这个引用会指向一个无效的 String，这可不对！Rust 不会允许我们这么做。 这里的解决方法是直接返回 String： 12345fn no_dangle() -&gt; String &#123; let s = String::from(&quot;hello&quot;); s&#125; 引用的规则 让我们概括一下之前对引用的讨论： 在任意给定时间，要么 只能有一个可变引用，要么 只能有多个不可变引用。 引用必须总是有效。 Slice类型字符串 slice（string slice）是 String 中一部分值的引用，它看起来像这样： 12345let s &#x3D; String::from(&quot;hello world&quot;);let hello &#x3D; &amp;s[0..5];let world &#x3D; &amp;s[6..11]; 这类似于引用整个 String 不过带有额外的 [0..5] 部分。它不是对整个 String 的引用，而是对部分 String 的引用。start..end 语法代表一个以 start 开头并一直持续到但不包含 end 的 range。如果需要包含 end，可以使用 ..= 而不是 ..： 12345let s &#x3D; String::from(&quot;hello world&quot;);let hello &#x3D; &amp;s[0..&#x3D;4];let world &#x3D; &amp;s[6..&#x3D;10]; 一个真正获取 部分 字符串的办法。不过，我们可以返回单词结尾的索引。 如果想要从第一个索引（0）开始，可以不写两个点号之前的值 如果 slice 包含 String 的最后一个字节，也可以舍弃尾部的数字 在记住所有这些知识后，让我们重写 first_word 来返回一个 slice。“字符串 slice” 的类型声明写作 &amp;str： 文件名: src/main.rs 123456789101112fn first_word(s: &amp;String) -&gt; &amp;str &#123; let bytes = s.as_bytes(); for (i, &amp;item) in bytes.iter().enumerate() &#123; if item == b&#x27; &#x27; &#123; return &amp;s[0..i]; &#125; &#125; &amp;s[..]&#125; 123456789fn main() &#123; let mut s = String::from(&quot;hello world&quot;); let word = first_word(&amp;s); s.clear(); // error! println!(&quot;the first word is: &#123;&#125;&quot;, word);&#125; 123456789101112131415fn main() &#123; let my_string = String::from(&quot;hello world&quot;); // first_word 中传入 `String` 的 slice let word = first_word(&amp;my_string[..]); let my_string_literal = &quot;hello world&quot;; // first_word 中传入字符串字面值的 slice let word = first_word(&amp;my_string_literal[..]); // 因为字符串字面值 **就是** 字符串 slice， // 这样写也可以，即不使用 slice 语法！ let word = first_word(my_string_literal);&#125; 123let a = [1, 2, 3, 4, 5];let slice = &amp;a[1..3]; 这个 slice 的类型是 &amp;[i32]。它跟字符串 slice 的工作方式一样，通过存储第一个集合元素的引用和一个集合总长度。你可以对其他所有集合使用这类 slice。","categories":[{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/categories/Programming-language/"},{"name":"Rust","slug":"Programming-language/Rust","permalink":"https://chivier.github.io/categories/Programming-language/Rust/"}],"tags":[{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/tags/Rust/"},{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/tags/Programming-language/"}]},{"title":"Linux入门资源","slug":"2021/Linux-入门资源","date":"2019-04-01T19:38:12.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/04/02/2021/Linux-入门资源/","link":"","permalink":"https://chivier.github.io/2019/04/02/2021/Linux-%E5%85%A5%E9%97%A8%E8%B5%84%E6%BA%90/","excerpt":"","text":"命令行？入门教程视频USTC-Linux教程 命令查询命令查询网站 Shell脚本教程 鸟哥PDF下载Linux-Basic Linux-web 个人觉得为了快速达到使用目的 还是实践一下来得快～","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Ubuntu设置默认打开方式","slug":"2021/Ubuntu设置默认打开方式","date":"2019-03-25T20:40:17.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2019/03/26/2021/Ubuntu设置默认打开方式/","link":"","permalink":"https://chivier.github.io/2019/03/26/2021/Ubuntu%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E6%89%93%E5%BC%80%E6%96%B9%E5%BC%8F/","excerpt":"Ubuntu使用技巧，认定默认打开方式。","text":"Ubuntu使用技巧，认定默认打开方式。 Ubuntu保存文件类型打开方式主要又两个配置文件决定： /etc/gnome/defaults.list 保存了全局的打开方式 /.local/share/applications/mimeapps.list 保存了个人的打开方式（局部个人设置） 也有版本是/.local/share/applications/defaults.list 一般情况下都推荐如下操作： 拷贝.desktop至/.local/share/applications 添加默认设置内容 默认设置内容编写是这样的： 类型=软件 类型参见右击文件Properties中的Type中的括号中内容，软件为XXX.desktop（之前的博客中有介绍如何创建desktop）","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux tricks","slug":"Linux/Linux-tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"}]},{"title":"Create shortcut in Ubuntu","slug":"2021/Create-shortcut-in-Ubuntu","date":"2019-03-25T20:28:01.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/03/26/2021/Create-shortcut-in-Ubuntu/","link":"","permalink":"https://chivier.github.io/2019/03/26/2021/Create-shortcut-in-Ubuntu/","excerpt":"在Linux下创建快捷方式的小技巧。当然现在19.04版本之后，我们可以更简单的通过右击目标文件，点击创建连接就可以创建一个新的快捷方式了。","text":"在Linux下创建快捷方式的小技巧。当然现在19.04版本之后，我们可以更简单的通过右击目标文件，点击创建连接就可以创建一个新的快捷方式了。 Method 1: Copy oneOpen /usr/share/applications. Look for the program you want to create the shortcut. Copy it. Method 2: Create .desktop file1sudo vim /usr/share/applications/eclipse.desktop And then input: 12345678910[Desktop Entry] Encoding=UTF-8 Name=eclipseComment=Eclipse IDE Exec=/opt/eclipse/eclipse # Where your program isIcon=/opt/eclipse/icon.xpm Terminal=falseStartupNotify=true Type=Application Categories=Application;Development; And then we can copy Method 3 ln -srun 1ln -s &#x27;Origin program&#x27; &#x27;Your Destination&#x27;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux tricks","slug":"Linux/Linux-tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-tricks/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"}]},{"title":"8086 Quick Start","slug":"2021/8086-Quick-Start","date":"2019-03-18T22:17:17.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/03/19/2021/8086-Quick-Start/","link":"","permalink":"https://chivier.github.io/2019/03/19/2021/8086-Quick-Start/","excerpt":"安装emu8086 并在该环境下写简单的汇编程序。一个快速上手的教程。旨在实用，旨在实用。","text":"安装emu8086 并在该环境下写简单的汇编程序。一个快速上手的教程。旨在实用，旨在实用。 Install emu8086下载地址：EMU8086 Download 安装自行解决～ 官方教程：8086set Registers通用寄存器 AX accumulator register (AH / AL) BX base address register （ BH / BL）. CX 计数寄存器 count register（分为 CH / CL ）. DX 数据寄存器 data register （分为 DH / DL）. SI 源变址寄存器 source index register. DI 目的变址寄存器 destination index register. BP 基址指针寄存器 base pointer. SP 堆栈寄存器 stack pointer. 段寄存器 CS 代码段寄存器，用来存放当前正在运行的指令 DS 数据段寄存器，用来存放当前运行程序所用的数据 ES 附加段寄存器，由程序员决定用途 SS 堆栈段寄存器，指出堆栈所在区域 上面说了两类，接下来说寄存器使用： 通用寄存器直接当做变量使用 段寄存器用于标志代码块 举例： 123456789ASSUME CS:CODE,DS:DATADATA SEGMENT ...;标注变量DATA ENDSCODE SEGMENT ...;写代码的部分CODE ENDS 变量和赋值例子： 123456789101112ASSUME CS:CODE,DS:DATADATA SEGMENT A DB 0 B DB 100DATA ENDS...MOV AL, A ;取变量ADD AL, 1MOV A, AL ;存变量... 这样我们可以存取变量并且完成赋值 数组数组简而言之，我们用一段连续的地址进行实现： 12345DATA SEGMENT ARR DB 48h, 65h, 6Ch, 6Ch, 6Fh, 00h STRING DB &#39;Hello&#39;, 0 REPEAT DB 5 DUP(9)DATA ENDS 这几种都是合法的数组定义初始化方法，A是一一赋值；B是字符串定义，需要注意一下我们有结尾0；C是重复定义，含义为5个9 对于数组取值： 12345MOV AL, ARR[3] ;下标取值，注意，下标从0开始标记MOV SI, 3MOV AL, ARR[SI] 指针既然有了数组，为实现某些简单操作，我们也自然希望有指针这种东西 有两种主要的实现方式： LEA 123MOV AL, VAR1 ;AL &#x3D; VAR1LEA BX, VAR1 ;BX &#x3D; &amp;VAR1MOV BYTE PTR [BX], 44H ;*BX &#x3D; 44H 注意一下BYTE PTR的必要性，表示按字节读数据，不能少 OFFSET 123MOV AL, VAR1 ;AL &#x3D; VAR1MOV BX, OFFSET VAR1 ;BX &#x3D; &amp;VAR1MOV BYTE PTR [BX], 44H ;*BX &#x3D; 44H 分支基本定义完成之后我们进入下一步：if语句的实现 8086中比较僵硬，实现是两句配套使用 第一句是固定的： 1CMP OP1,OP2 结果是寄存在寄存器之中的Flag的CF、ZF、OF、AF、PF这几个标志位，具体是： ZF=1，表示两个操作数相等 假如把操作数看成无符号数： CF=1，有进位或借位，cmp是减操作，故可看做是借位，即说明op1&lt;op2 CF=0，无借位，需判断ZF是否为0，若为0，说明op1和op2不相等，即op1&gt;op2 假如把操作数看成有符号数： 若SF=0，OF=0，说明此时值为正数，无溢出，直观的看出op1&gt;op2 若SF=1，OF=0，说明此时值为负数，无溢出，直观的看出op1&lt;op2 若SF=0，OF=1，说明此时值为正数，有溢出，即op1&lt;op2 若SF=1，OF=1，说明此时值为负数，有溢出，即op1&gt;op2 为什吗会说溢出是因为cmp比较实质失去计算OP1-OP2再将它和0进行比较得到 第二句为判定条件+跳转标签： 有了分支跳转，自然就有了循环操作，因为判定跳转标签就可以实现循环。 函数（子程序）关于子程序的使用，不同于C/C++等高级语言，我们必须将即将使用的寄存器进行保存。 直接上例子： 1234567SUB PROC NEAR ;beginning of SUB PUSH AL ;保护寄存器 PUSH BL ... POP BL POP AL ;还原寄存器SUB ENDP ;ending of SUB 我们这样可以简单的实现子程序的编写 当然也有另外一种保护寄存器的方法： 1234567SUB PROC NEAR ;beginning of SUB MOV STAL,AL ;保护寄存器 MOV STBL,BL ... MOV BL,STAL MOV AL,STBL ;还原寄存器SUB ENDP ;ending of SUB 两种方法各有优劣，前者使用需要注意PUSH和POP的顺序，因为我们是在往栈立存取数据，所以POP顺序和PUSH顺序需要倒置；后者使用便捷随意，但是局限性是不可以进行递归，即不能二次调用，除非手动用数组进行寄存变量；总之个人推荐第一种。 系统中断有些特殊的操作只能以来系统中断进行完成，例如：PRINT等 INT中断表 常见的是输入、输出 但是这些我们在EMU8086.INC中有简便操作 源码是在EMU8086.INC源码可以自由下载浏览 这样输入输出只要一句话就可以完成，下面给一个简单的例子，源自asm_tutorial： 12345678910111213141516171819202122232425262728293031; demonstrate scan_num, print_num, pthis;----------------------------------------include &#39;emu8086.inc&#39;ORG 100hLEA SI, msg1 ; ask for the numberCALL print_string ;CALL scan_num ; get number in CX.MOV AX, CX ; copy the number to AX.; print the following string:CALL pthisDB 13, 10, &#39;You have entered: &#39;, 0CALL print_num ; print number in AX.RET ; return to operating system.; datamsg1 DB &#39;Enter the number: &#39;, 0; macros to define procsDEFINE_SCAN_NUMDEFINE_PRINT_STRINGDEFINE_PRINT_NUMDEFINE_PRINT_NUM_UNS ; required for print_num.DEFINE_PTHISEND ; directive to stop the compiler. 关于很多人好奇的计时，可以给一套模板供大家简便使用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657MARKTIME PROC NEAR MOV STAH,AH MOV STBH,BH MOV STCL,CL MOV STCH,CH MOV STDL,DL MOV AH,2CH INT 21H MOV STM,CL MOV STS,DH MOV STSS,DL MOV STH,CH MOV AH,STAH MOV CL,STCL MOV CH,STCH MOV DH,STDH MOV DL,STDL RET MARKTIME ENDPPRINTTIME PROC NEAR MOV STAH,AH MOV STBH,BH MOV STCL,CL MOV STCH,CH MOV STDL,DL MOV AH,2CH INT 21H SUB CH,STH SUB CL,STM SUB DH,STS SUB DL,STSS MOV AX,60 MUL CH ADD AL,CL MOV CX,AX MOV AX,60 MUL CL ADD AL,DH PRINT &quot;TIME: &quot; CALL PRINT_NUM_UNS PUTC &#39;.&#39; MOV AX,0 MOV AL,DL CALL PRINT_NUM_UNS PRINT &quot; S&quot; MOV AH,STAH MOV CL,STCL MOV CH,STCH MOV DH,STDH MOV DL,STDL RETPRINTTIME ENDP 两者配套使用。","categories":[{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/categories/Programming-language/"},{"name":"Assembly","slug":"Programming-language/Assembly","permalink":"https://chivier.github.io/categories/Programming-language/Assembly/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Assembly","slug":"Assembly","permalink":"https://chivier.github.io/tags/Assembly/"}]},{"title":"Git使用速成","slug":"2021/Git使用速成","date":"2019-03-16T22:18:17.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/03/17/2021/Git使用速成/","link":"","permalink":"https://chivier.github.io/2019/03/17/2021/Git%E4%BD%BF%E7%94%A8%E9%80%9F%E6%88%90/","excerpt":"简单的Git使用，速成教程。","text":"简单的Git使用，速成教程。 Git使用安装git命令行下使用：sudo apt-get install git 即可 创建版本库先创建一个空目录： 在该目录下运行 git init 添加文件和上传使用git add file1.txt可以上传文件 但是最后需要添加git commit -m &quot;add 1 file.&quot;才可以完成上传 git status用于查看状态 git diff用于对比差异 删除文件git rm可以用于删除文件 版本回退git log用于查看所有版本的信息 git reset --hard HEAD^用于退回上一个版本，HEAD代表当前版本，HEAD^表示上一个版本，HEAD~x之前x个版本 git reflog用于调查历史命令 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD &lt;file&gt;，就回到了场景1，第二步按场景1操作 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退一节，不过前提是没有推送到远程库 设置远程仓库设置远程仓库git remote add origin git@github.com:michaelliao/learngit.git git push -u origin master第一次提交 之后git push origin master即可 创建与合并分支123$ git branch dev$ git checkout devSwitched to branch &#39;dev&#39; 这样就切换到了dev分支 查看分支：git branch 创建分支：git branch &lt;name&gt; 切换分支：git checkout &lt;name&gt; 创建+切换分支：git checkout -b &lt;name&gt; 合并某分支到当前分支：git merge &lt;name&gt; 删除分支：git branch -d &lt;name&gt; 创建标签 命令git tag &lt;tagname&gt;用于新建一个标签，默认为HEAD，也可以指定一个commit id； 命令git tag -a &lt;tagname&gt; -m &quot;blablabla...&quot;可以指定标签信息； 命令git tag可以查看所有标签。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Git","slug":"Git","permalink":"https://chivier.github.io/tags/Git/"}]},{"title":"Bash-in-Linux","slug":"2021/Bash-in-Linux","date":"2019-02-18T13:17:17.000Z","updated":"2021-12-23T04:46:56.000Z","comments":true,"path":"2019/02/18/2021/Bash-in-Linux/","link":"","permalink":"https://chivier.github.io/2019/02/18/2021/Bash-in-Linux/","excerpt":"Bashbash shell 是我们在linux中常用的一个shell程序，在这里我给大家简单介绍一下。本教程以实例为主。","text":"Bashbash shell 是我们在linux中常用的一个shell程序，在这里我给大家简单介绍一下。本教程以实例为主。 bash的hotkey这里简单说几个bash里面神奇的小玩法： Up/Down：键盘的上/下键可以访问之前你输入过的命令，比如在重新编译某一个程序的时候，你就不要重新输入一遍命令，而是直接先按上再回车就OK啦 Tab：自动补全，Tab键可以推测你即将输入的内容，并且达到自动完成的功能，大大减少我们输入命令的时间 alias：别名设置，偷懒神器，例如事前我们用过的ls -al我们可以利用alias showprivacy=&#39;ls -al&#39;从而使得我们可以用showprivacy代替之前的命令 Wildcard：通配符，我们可以用例如ls -l /usr/bin/X*的方法得到所有以X开头的文件和目录 Ctrl+u Ctrl+k：方便快速删除的神器，前者为删除光标之前的所有字符（不含光标处）。后者为删除光标以及光标之后的所有字符 Ctrl+a Ctrl+e：相当于home 和end Ctrl+Shift+C Ctrl+Shift+V：复制和粘贴，因为Ctrl+C用于中断程序 命令查询type [-tpa] name命令用于确认name是否为一条bash命令，或者是alias别名的一条命令 不加任何选项与参数时，type 会显示出 name 是外部指令还是 bash 内置指令 -t ：当加入 -t 参数时，type 会将 name 以下面这些字眼显示出他的意义：file ：表示为外部指令alias ：表示该指令为命令别名所设置的名称builtin ：表示该指令为 bash 内置的指令功能 -p ：如果后面接的 name 为外部指令时，才会显示完整文件名； -a ：会由 PATH 变量定义的路径中，将所有含 name 的指令都列出来，包含 alias echo与变量Linux中除了别名，为了简单的设置一些路径名或文件名，我们会设置一些变量 例如 email=’xxx@qq.com’ 但是下一次使用的时候就应该加上$,$email才表示你的变量的内容 其他其他常见的命令大家可以参考很多Ubuntu的教程，这里简单介绍了几条使用的快捷键和命名。真正用好bash shell还需要时间磨炼。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"开机流程","slug":"2021/开机流程-1","date":"2019-01-08T22:17:17.000Z","updated":"2021-12-23T04:47:04.000Z","comments":true,"path":"2019/01/09/2021/开机流程-1/","link":"","permalink":"https://chivier.github.io/2019/01/09/2021/%E5%BC%80%E6%9C%BA%E6%B5%81%E7%A8%8B-1/","excerpt":"分析计算机开机的流程，详解附代码。","text":"分析计算机开机的流程，详解附代码。 0 环境不同的计算机开机的流程是有微小差异的。显然的，大型并行的计算机和小型计算机开机的流程是不同的。同事，不同操作系统开机运行什么样的程序也是有区别的。这里我选择的是 Intel 80x86 CPU操作模式，和 Linux 0.11 内核。 1 BIOS启动计算机的运行离不开程序，加电的一瞬间，计算机内存（准确的说这里是指RAM）中最初是空的。CPU中的逻辑电路设计是执行我们内存中的程序的，而不是软盘中的程序。最初我们启动BIOS显然是不可能靠软件方法的，其实是靠硬件启动的。 1.1 BIOS启动原理硬件角度看，Intel 80x86 系列CPU可以分别可以在16位实模式和32位保护模式下运行。为保证兼容，所有Intel 80x86 系列CPU设计都是加电直接进入16位实模式的。同时，CPU硬件逻辑设计为瞬间强行将CS的值置为0xF000,IP的值置为0xFFF0。这样CS：IP就指向了0xFFFF0的位置。我们硬件设计的时候也将BIOS的入口地址设置为0xFFFF0。 1.2 BIOS启动BIOS的程序被固化在计算机主机板上一块较小的ROM的芯片中。通常，不同主机板的BIOS是不同的。就我们选取的BIOS为例 Intel 80x86 CPU操作模式，和 Linux 0.11 内核的环境下，我们的BIOS程序也只有8K，所占的地址在0xFE000~0xFFFFF。BIOS程序运行的时候，显示器上会显示显卡、内存的各种信息，表示BIOS程序在依次检测显卡、内存等。其中有一项boot对于系统至关重要要——BIOS在内存中建立中断向量表和中断服务程序。BIOS会在内存开始的位置0x00000用1KB的内存(0x00000~0x003FF)构建中断向量表。 2 加载程序2.1 加载引导程序CPU通过收到BIOS传来的int0x19的中断向量，指向0x0E6F2，这里是int0x19指向的地址，BIOS程序从这里开始进行两项工作“找到硬/软盘”以及“加载第一扇区”。BIOS将0号磁头的对应盘里面的0磁道第一扇区的内容复制到0x07C00处，这里就是Linux0.11的引导程序。 2.2 加载setup我们的引导程序bootsec导入内存之后，第一件重要的事情是规划内存。bootsect程序中有一段分别规定了BOOTSEG、INITSEG、SETUPSEG等常量，表示setup的扇区数、加载位置，启动扇区的位置等等。这样规划好之后，bootsect会将自己复制到0x07C000到0x90000处。这一段是这样的： 1234567891011entry startstart: mov ax,#BOOTSEG mov ds,ax mov ax,#INITSEG mov es,ax mov cx,#256 sub si,si sub di,di rep movw 这里ds（0x07C0）和si（0x0000）联合使用起来，组成了原地址0x7C00。es和di联合构成0x90000，mov cx这里正好决定了大小 本次复制之后我们进行下一阶段： 12345 rep movw jmpi go,INITSEGgo: mov ax,cs mov ds,ax 这里我们执行跳转，CS变成0x9000，IP从0x9000转到go处。从现在起我们的操作系统完成了转移，不在完全依赖BIOS了，可以根据自己的意志进行移动。 由于bootsect复制的新的位置，之前修改了CS，现在轮到DS、ES、SS、和SP了： 123456go: mov ax,cs mov ds,ax mov ed,ax! put stack at 0x9ff00 mov ss,ax mov sp,#0xFF00 这里通过ax，用CS的值去修改其他寄存器的值。数据段寄存器、附加段寄存器、栈基址寄存器全部设置为代码段寄存器的位置（CS），并且将栈顶指针设置为偏移地址0xFF00的地方。这题我们可以开始加载setup程序了。 我们首先执行的是int0x13，但我们要先指定扇区加载的内存位置等信息，即传参： 1234567891011load_setup: mov dx,#0x0000 mov cx,#0x0002 mov bx,#0x0200 mov ax,#0x0200 + SUPERLEN int 0x13 jnc ok_load_setup mov dx,#0x0000 mov ax,#0x0000 int 0x13 j load_setup 完成传参后执行int0x13。全部完成这些之后我们已经从软盘里面加载了5个扇区的代码。 2.3 加载system模块加载完setup之后我们还是用类似之前的方法再来加载第三部分的代码，反复调用int0x13。这部分代码较长，开机的时候我们会显示**”Loading system …”**的信息，我们会在这里加载240个扇区的信息。我们最后还会在bootsect中执行一个小任务：确认根设备号。 加载完成3个部分之后，我们bootsect功德圆满，然后我们回去执行下一步的setup程序。 跳转依赖bootsect中的： 1jmpi 0, SETUPSEG 2.4 提取机器系统数据setup程序开始的第一件事情就是利用BIOS中的中断服务提取内核运行所需要的机器系统数据，其中包括贯标位置，显示页面等数据。并且还在int0x41还有int0x46上硬盘参数表。将他们存放在其他位置。 位置在boot/setup.s里面的： 12345678910111213141516 mov ax, #INITSEG mov ds, as mov ah, #0x03 xor bh, bh int 0x10 mov [0],dx !get memory size (extended memory,KB) mov ah, #0x88 int 0x15 mov [2],axmov cx, #0x10mov ax, #0x00repstosb... 这些步骤之后我们完成的实际上是将Linux0.11从实模式转到了保护模式。 3 转向32位模式，准备main函数3.1 将system移动到内存起始地址为0x00000在这些之前我们先要关闭中断，防止以外情况，在setup.s中有一行cli关闭了中断。setup再将0x10000的内核复制到0x00000的位置。DS和ES配合完成内核移位的任务。这里其实是为我们下一步破旧立新做准备。 3.2 设置中断我们这里会建立新的中断模式，通过setup程序自己提供的数据信息去完成初始化。 12345678910111213141516171819202122232425262728end_move: mov ax,#SETUPSEG mov ds,ax lidt idt_48 lgdt gdt_48 ... gdt: .word 0,0,0,0 .word 0x07FF .word 0x0000 .word 0x9A00 .word 0x00C0 .word 0x07FF .word 0x0000 .word 0x9200 .word 0x00C0 idt_48: .word 0 .word 0,0 gdt_48: .word 0x800 .word 512 + gdt,0x9 ... 3.3 打开A20，实现32位寻址这里将我们的寻址模式进行改动，最大地址从0xFFFFF扩展到了0xFFFFFFFF。 12345678call empty_8042mov a1,#0xD1out #0x64,alcall empty_8042mov al,#0xDF !A20 onout #0x60,alcall empty_8042.. 3.4 准备head.ssetup对8259A进行重编程。这里有一点很难理解，在我们设置GDT之后有一句跳转语句： 1jmpi 0,8 这里需要声明，8是保护模式的选择符，这样成就可以理解了。 3.5 执行head.shead.s中，我们完成了很多很多任务，例如将SS转32为的esp，对IDT重新设置和构建，调整DS、ES，检测数学协调处理器等等。之后我们将main函数的执行入口地址压给CS：EIP。这样我们可以开始运行main了。 4 设置根设备和硬盘4.1 进行规划我们开始使用32字的机器的时候设置了drive_info实在init/main.c里面执行的： 12345678#define DRIVE_INFO (*(struct drive_info *)0x90080)#define ORIG_ROOT_DEV (*(struct short *)0x901FC)...void main (void)&#123; ROOT_DEV = ORIG_ROOT_DEV; drive_info = DRIVE_INFO;&#125; 接下来我们会设置缓冲区、虚拟盘、主内存等各自的存储位置。 4.2 设置虚拟盘空间并初始化5 建立人机交互界面以及外设的中断服务挂载我们加载完操作系统并不完全算完成了开机，要真正的使用我们还要加载外设。Linux中的ttyinit函数就是为了完成字符设备的初始化工作。 12345void tty (void)&#123; rs_init (); con_init ();&#125; 其中我们对串口进行设置的代码是rs_init() 123456789voidrs_init (void)&#123; set_intr_gate (0x24, rs1_interrupt); set_intr_gate (0x23, rs2_interrupt); init (tty_table[1].read_q.data); init (tty_table[2].read_q.data); outb (inb_p (0x21) &amp; 0xE7, 0x21);&#125; 之后我们依次完成显示器、键盘等设置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#define ORIG_X (*(unsigned char *)0x90000)#define ORIG_Y (*(unsigned char *)0x90001)#define ORIG_VIDEO_PAGE (*(unsigned short *)0x90004)#define ORIG_VIDEO_MODE ((*(unsigned short *)0x90006) &amp; 0xff)#define ORIG_VIDEO_COLS (((*(unsigned short *)0x90006) &amp; 0xff00) &gt;&gt; 8)#define ORIG_VIDEO_LINES (25)#define ORIG_VIDEO_EGA_AX (*(unsigned short *)0x90008)#define ORIG_VIDEO_EGA_BX (*(unsigned short *)0x9000a)#define ORIG_VIDEO_EGA_CX (*(unsigned short *)0x9000c)#define VIDEO_TYPE_MDA 0x10 #define VIDEO_TYPE_CGA 0x11 #define VIDEO_TYPE_EGAM 0x20 #define VIDEO_TYPE_EGAC 0x21 #define NPAR 16...voidcon_init (void)&#123; register unsigned char a; char *display_desc = &quot;????&quot;; char *display_ptr; video_num_columns = ORIG_VIDEO_COLS; video_size_row = video_num_columns * 2; video_num_lines = ORIG_VIDEO_LINES; video_page = (unsigned char)ORIG_VIDEO_PAGE; video_erase_char = 0x0720; if (ORIG_VIDEO_MODE == 7) &#123; video_mem_start = 0xb0000; video_port_reg = 0x3b4; video_port_val = 0x3b5; if ((ORIG_VIDEO_EGA_BX &amp; 0xff) != 0x10) &#123; video_type = VIDEO_TYPE_EGAM; video_mem_end = 0xb8000; display_desc = &quot;EGAm&quot;; &#125; else &#123; video_type = VIDEO_TYPE_MDA; video_mem_end = 0xb2000; display_desc = &quot;*MDA&quot;; &#125; &#125; else &#123; video_mem_start = 0xb8000; video_port_reg = 0x3d4; video_port_val = 0x3d5; if ((ORIG_VIDEO_EGA_BX &amp; 0xff) != 0x10) &#123; video_type = VIDEO_TYPE_EGAC; video_mem_end = 0xbc000; display_desc = &quot;EGAc&quot;; &#125; else &#123; video_type = VIDEO_TYPE_CGA; video_mem_end = 0xba000; display_desc = &quot;*CGA&quot;; &#125; &#125; display_ptr = ((char *) video_mem_start) + video_size_row - 8; while (*display_desc) &#123; *display_ptr++ = *display_desc++; display_ptr++; &#125; origin = video_mem_start; scr_end = video_mem_start + video_num_lines * video_size_row; top = 0; bottom = video_num_lines; gotoxy (ORIG_X, ORIG_Y); set_trap_gate (0x21, &amp;keyboard_interrupt); outb_p ((unsigned char)(inb_p (0x21) &amp; 0xfd), 0x21); a = inb_p (0x61); outb_p ((unsigned char)(a | 0x80), 0x61); outb (a, 0x61); &#125; 最后我们还有一项任务就是激活Process0。此时才算真正完成了开机任务！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Linux的权限","slug":"2021/Linux的权限问题","date":"2019-01-01T23:17:17.000Z","updated":"2021-12-23T04:46:58.000Z","comments":true,"path":"2019/01/02/2021/Linux的权限问题/","link":"","permalink":"https://chivier.github.io/2019/01/02/2021/Linux%E7%9A%84%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98/","excerpt":"简单介绍Ubuntu下的文件权限系统。","text":"简单介绍Ubuntu下的文件权限系统。 使用者Linux中，使用文件的对象一般为三类，[u],[g],[o]。分别为user，group和others。网上的解释很多，但是这里我声明一下～最好理解的方式还是英文原意最合适： u - user who owns the file g - the group to which the user belongs o - others a - (u+g+o) anyone 权限观察文件的权限可以使用命令： ls -al 这里的第二列使我们关心的，即文件权限。 第一个字母代表文件类型： 当为[ d ]则是目录 当为[ - ]则是文件 若是[ l ]则表示为链接文件 若是[ b ]则表示可随机存取设备 若是[ c ]则表示一次性读取设备 之后每三个字母一组表示权限，从前往后分别为u、g、o的权限。 r = 4 w = 2 x = 1 - = 0 这个在chmod命令使用的时候会用到。 对于文件，含义是： r (read) : 可读 w (write) : 可写 x (excute) : 可以执行 对于目录而言，含义略有不同： r : 可以读目录以及其中的文件 w : 对于目录而言，写的含义略微广一点，包含下面几条 ​ 创建新的文件与目录；​ 删已经存在的文件与目录（不论该文件的权限为何！）​ 将已存在的文件或目录进行更名；​ 搬移该目录内的文件、目录位置。 x : 因为对于一个目录而言，我们不存在什么是否可以执行的问题，这里代表该目录能否“打开” 即用cd命令能否打开 权限修改关于权限的修改问题，我们讨论下面三个命令： chown chgrp chmod 其中chmod用的是最多，下面一一介绍。 chgrp同样，chgrp用于修改group。 格式为 chgrp [-r] new_group_name dir/file_name 其中-r开关表示是否对子目录和子文件内容进行修改。 chownchown顾名思义，是我们修改user的命令。 格式为 chown [-r] new_user_name1[:new_user_name2:...] dir/file_name 其中-r开关表示是否对子目录和子文件内容进行修改。 与上面不同的是一个文件可以有多个owner，因此我们可以用：进行分割。 chmodchmod对权限的具体内容进行了修改。 格式为 chmod [-r] xyz dir/file_name xyz都是0~7的数字，就是将rwx-的字符根据之前给出的权值对应，给出我们希望的权限目标。 有一些简单的方式用于微调： 命令 对象 操作 操作内容 文件 chomod u/g/o/a +/-/= rwx- w文件名 直接给出几个具体的例子： chmod u=rwx,go=rx .bashrc chmod a+w .bashrc 一些常用的权限： Setting Numerical Meaning -rw------- (600) Only the owner has read and write permissions. -rw-r--r-- (644) Only the owner has read and write permissions; the group and others have read only. -rwx------ (700) Only the owner has read, write, and execute permissions. -rwxr-xr-x (755) The owner has read, write, and execute permissions; the group and others have only read and execute. -rwx--x--x (711) The owner has read, write, and execute permissions; the group and others have only execute. -rw-rw-rw- (666) Everyone can read and write to the file. (Becareful with these permissions.) -rwxrwxrwx (777) Everyone can read, write, and execute. (Again, this permissions setting can be hazardous.)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"}]},{"title":"Hello World","slug":"2021/hello-world","date":"2018-12-01T12:17:17.000Z","updated":"2021-12-23T04:47:02.000Z","comments":true,"path":"2018/12/01/2021/hello-world/","link":"","permalink":"https://chivier.github.io/2018/12/01/2021/hello-world/","excerpt":"Hexo default file","text":"Hexo default file Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Blog","slug":"Blog","permalink":"https://chivier.github.io/categories/Blog/"},{"name":"Hexo","slug":"Blog/Hexo","permalink":"https://chivier.github.io/categories/Blog/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://chivier.github.io/tags/Hexo/"},{"name":"Blog","slug":"Blog","permalink":"https://chivier.github.io/tags/Blog/"}]}],"categories":[{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/categories/Develop/"},{"name":"Develop/Applications","slug":"Develop/Develop-Applications","permalink":"https://chivier.github.io/categories/Develop/Develop-Applications/"},{"name":"Develop/Applications","slug":"Develop-Applications","permalink":"https://chivier.github.io/categories/Develop-Applications/"},{"name":"Parallel/Cuda","slug":"Develop-Applications/Parallel-Cuda","permalink":"https://chivier.github.io/categories/Develop-Applications/Parallel-Cuda/"},{"name":"Develop/Applications/Lammps","slug":"Develop-Applications/Parallel-Cuda/Develop-Applications-Lammps","permalink":"https://chivier.github.io/categories/Develop-Applications/Parallel-Cuda/Develop-Applications-Lammps/"},{"name":"Parallel","slug":"Parallel","permalink":"https://chivier.github.io/categories/Parallel/"},{"name":"Study","slug":"Parallel/Study","permalink":"https://chivier.github.io/categories/Parallel/Study/"},{"name":"Parallel/MPI","slug":"Parallel/Study/Parallel-MPI","permalink":"https://chivier.github.io/categories/Parallel/Study/Parallel-MPI/"},{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/categories/Linux/"},{"name":"Tricks","slug":"Linux/Tricks","permalink":"https://chivier.github.io/categories/Linux/Tricks/"},{"name":"Tools","slug":"Linux/Tricks/Tools","permalink":"https://chivier.github.io/categories/Linux/Tricks/Tools/"},{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/categories/Compiler/"},{"name":"LLVM","slug":"Compiler/LLVM","permalink":"https://chivier.github.io/categories/Compiler/LLVM/"},{"name":"Dataflow","slug":"Compiler/LLVM/Dataflow","permalink":"https://chivier.github.io/categories/Compiler/LLVM/Dataflow/"},{"name":"DARTS","slug":"Compiler/LLVM/Dataflow/DARTS","permalink":"https://chivier.github.io/categories/Compiler/LLVM/Dataflow/DARTS/"},{"name":"Cuda","slug":"Cuda","permalink":"https://chivier.github.io/categories/Cuda/"},{"name":"Parallel","slug":"Cuda/Parallel","permalink":"https://chivier.github.io/categories/Cuda/Parallel/"},{"name":"Develop","slug":"Cuda/Parallel/Develop","permalink":"https://chivier.github.io/categories/Cuda/Parallel/Develop/"},{"name":"Tools","slug":"Tools","permalink":"https://chivier.github.io/categories/Tools/"},{"name":"Develop","slug":"Tools/Develop","permalink":"https://chivier.github.io/categories/Tools/Develop/"},{"name":"Graphics","slug":"Develop/Graphics","permalink":"https://chivier.github.io/categories/Develop/Graphics/"},{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/categories/Architechture/"},{"name":"Parallel","slug":"Architechture/Parallel","permalink":"https://chivier.github.io/categories/Architechture/Parallel/"},{"name":"Compiler","slug":"Architechture/Compiler","permalink":"https://chivier.github.io/categories/Architechture/Compiler/"},{"name":"FP","slug":"Architechture/Compiler/FP","permalink":"https://chivier.github.io/categories/Architechture/Compiler/FP/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://chivier.github.io/categories/Tensorflow/"},{"name":"Cuda","slug":"Tensorflow/Cuda","permalink":"https://chivier.github.io/categories/Tensorflow/Cuda/"},{"name":"Deeplearning","slug":"Tensorflow/Cuda/Deeplearning","permalink":"https://chivier.github.io/categories/Tensorflow/Cuda/Deeplearning/"},{"name":"Qemu","slug":"Linux/Qemu","permalink":"https://chivier.github.io/categories/Linux/Qemu/"},{"name":"Compiler","slug":"Linux/Qemu/Compiler","permalink":"https://chivier.github.io/categories/Linux/Qemu/Compiler/"},{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/categories/Rust/"},{"name":"Develop","slug":"Rust/Develop","permalink":"https://chivier.github.io/categories/Rust/Develop/"},{"name":"DSL","slug":"Rust/Develop/DSL","permalink":"https://chivier.github.io/categories/Rust/Develop/DSL/"},{"name":"Dataflow","slug":"Architechture/Dataflow","permalink":"https://chivier.github.io/categories/Architechture/Dataflow/"},{"name":"DSL","slug":"Compiler/DSL","permalink":"https://chivier.github.io/categories/Compiler/DSL/"},{"name":"Docker","slug":"Docker","permalink":"https://chivier.github.io/categories/Docker/"},{"name":"Tutorial","slug":"Docker/Tutorial","permalink":"https://chivier.github.io/categories/Docker/Tutorial/"},{"name":"Translator","slug":"Compiler/Translator","permalink":"https://chivier.github.io/categories/Compiler/Translator/"},{"name":"linux","slug":"linux","permalink":"https://chivier.github.io/categories/linux/"},{"name":"ubuntu","slug":"linux/ubuntu","permalink":"https://chivier.github.io/categories/linux/ubuntu/"},{"name":"ICS","slug":"ICS","permalink":"https://chivier.github.io/categories/ICS/"},{"name":"TA","slug":"ICS/TA","permalink":"https://chivier.github.io/categories/ICS/TA/"},{"name":"Work","slug":"Work","permalink":"https://chivier.github.io/categories/Work/"},{"name":"UI","slug":"Work/UI","permalink":"https://chivier.github.io/categories/Work/UI/"},{"name":"LLVM","slug":"LLVM","permalink":"https://chivier.github.io/categories/LLVM/"},{"name":"Compiler","slug":"LLVM/Compiler","permalink":"https://chivier.github.io/categories/LLVM/Compiler/"},{"name":"DSL","slug":"LLVM/DSL","permalink":"https://chivier.github.io/categories/LLVM/DSL/"},{"name":"Windows","slug":"Windows","permalink":"https://chivier.github.io/categories/Windows/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/categories/System/"},{"name":"Linux Tricks","slug":"Linux/Linux-Tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-Tricks/"},{"name":"Linux Learning","slug":"Linux/Linux-Learning","permalink":"https://chivier.github.io/categories/Linux/Linux-Learning/"},{"name":"Linux tricks","slug":"Linux/Linux-tricks","permalink":"https://chivier.github.io/categories/Linux/Linux-tricks/"},{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/categories/Programming-language/"},{"name":"Assembly","slug":"Programming-language/Assembly","permalink":"https://chivier.github.io/categories/Programming-language/Assembly/"},{"name":"Others","slug":"Others","permalink":"https://chivier.github.io/categories/Others/"},{"name":"Latex","slug":"Others/Latex","permalink":"https://chivier.github.io/categories/Others/Latex/"},{"name":"C","slug":"Programming-language/C","permalink":"https://chivier.github.io/categories/Programming-language/C/"},{"name":"Electronic","slug":"Electronic","permalink":"https://chivier.github.io/categories/Electronic/"},{"name":"Android","slug":"Android","permalink":"https://chivier.github.io/categories/Android/"},{"name":"Android tricks","slug":"Android/Android-tricks","permalink":"https://chivier.github.io/categories/Android/Android-tricks/"},{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/categories/COD/"},{"name":"Operating System","slug":"Operating-System","permalink":"https://chivier.github.io/categories/Operating-System/"},{"name":"Concepts","slug":"Operating-System/Concepts","permalink":"https://chivier.github.io/categories/Operating-System/Concepts/"},{"name":"Maths","slug":"Maths","permalink":"https://chivier.github.io/categories/Maths/"},{"name":"Logic","slug":"Maths/Logic","permalink":"https://chivier.github.io/categories/Maths/Logic/"},{"name":"Blog","slug":"Blog","permalink":"https://chivier.github.io/categories/Blog/"},{"name":"Hexo","slug":"Blog/Hexo","permalink":"https://chivier.github.io/categories/Blog/Hexo/"},{"name":"Rust Project","slug":"Rust/Rust-Project","permalink":"https://chivier.github.io/categories/Rust/Rust-Project/"},{"name":"Rust","slug":"Programming-language/Rust","permalink":"https://chivier.github.io/categories/Programming-language/Rust/"}],"tags":[{"name":"Develop","slug":"Develop","permalink":"https://chivier.github.io/tags/Develop/"},{"name":"Develop/Applications","slug":"Develop-Applications","permalink":"https://chivier.github.io/tags/Develop-Applications/"},{"name":"Parallel/Cuda","slug":"Parallel-Cuda","permalink":"https://chivier.github.io/tags/Parallel-Cuda/"},{"name":"Develop/Applications/Lammps","slug":"Develop-Applications-Lammps","permalink":"https://chivier.github.io/tags/Develop-Applications-Lammps/"},{"name":"Parallel","slug":"Parallel","permalink":"https://chivier.github.io/tags/Parallel/"},{"name":"Study","slug":"Study","permalink":"https://chivier.github.io/tags/Study/"},{"name":"Parallel/MPI","slug":"Parallel-MPI","permalink":"https://chivier.github.io/tags/Parallel-MPI/"},{"name":"Linux","slug":"Linux","permalink":"https://chivier.github.io/tags/Linux/"},{"name":"Tools","slug":"Tools","permalink":"https://chivier.github.io/tags/Tools/"},{"name":"Tricks","slug":"Tricks","permalink":"https://chivier.github.io/tags/Tricks/"},{"name":"LLVM","slug":"LLVM","permalink":"https://chivier.github.io/tags/LLVM/"},{"name":"Compiler","slug":"Compiler","permalink":"https://chivier.github.io/tags/Compiler/"},{"name":"Dataflow","slug":"Dataflow","permalink":"https://chivier.github.io/tags/Dataflow/"},{"name":"DARTS","slug":"DARTS","permalink":"https://chivier.github.io/tags/DARTS/"},{"name":"Cuda","slug":"Cuda","permalink":"https://chivier.github.io/tags/Cuda/"},{"name":"Graphics","slug":"Graphics","permalink":"https://chivier.github.io/tags/Graphics/"},{"name":"Architechture","slug":"Architechture","permalink":"https://chivier.github.io/tags/Architechture/"},{"name":"FP","slug":"FP","permalink":"https://chivier.github.io/tags/FP/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://chivier.github.io/tags/Tensorflow/"},{"name":"Deeplearning","slug":"Deeplearning","permalink":"https://chivier.github.io/tags/Deeplearning/"},{"name":"Qemu","slug":"Qemu","permalink":"https://chivier.github.io/tags/Qemu/"},{"name":"Rust","slug":"Rust","permalink":"https://chivier.github.io/tags/Rust/"},{"name":"DSL","slug":"DSL","permalink":"https://chivier.github.io/tags/DSL/"},{"name":"Docker","slug":"Docker","permalink":"https://chivier.github.io/tags/Docker/"},{"name":"Tutorial","slug":"Tutorial","permalink":"https://chivier.github.io/tags/Tutorial/"},{"name":"Translator","slug":"Translator","permalink":"https://chivier.github.io/tags/Translator/"},{"name":"linux","slug":"linux","permalink":"https://chivier.github.io/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://chivier.github.io/tags/ubuntu/"},{"name":"TA","slug":"TA","permalink":"https://chivier.github.io/tags/TA/"},{"name":"ICS","slug":"ICS","permalink":"https://chivier.github.io/tags/ICS/"},{"name":"Work","slug":"Work","permalink":"https://chivier.github.io/tags/Work/"},{"name":"UI","slug":"UI","permalink":"https://chivier.github.io/tags/UI/"},{"name":"Windows","slug":"Windows","permalink":"https://chivier.github.io/tags/Windows/"},{"name":"Softwares","slug":"Softwares","permalink":"https://chivier.github.io/tags/Softwares/"},{"name":"System","slug":"System","permalink":"https://chivier.github.io/tags/System/"},{"name":"Linux Tricks","slug":"Linux-Tricks","permalink":"https://chivier.github.io/tags/Linux-Tricks/"},{"name":"Network","slug":"Network","permalink":"https://chivier.github.io/tags/Network/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://chivier.github.io/tags/Ubuntu/"},{"name":"Assembly","slug":"Assembly","permalink":"https://chivier.github.io/tags/Assembly/"},{"name":"Latex","slug":"Latex","permalink":"https://chivier.github.io/tags/Latex/"},{"name":"Linux Software","slug":"Linux-Software","permalink":"https://chivier.github.io/tags/Linux-Software/"},{"name":"Programming language","slug":"Programming-language","permalink":"https://chivier.github.io/tags/Programming-language/"},{"name":"C","slug":"C","permalink":"https://chivier.github.io/tags/C/"},{"name":"Electronic","slug":"Electronic","permalink":"https://chivier.github.io/tags/Electronic/"},{"name":"Circuits","slug":"Circuits","permalink":"https://chivier.github.io/tags/Circuits/"},{"name":"Web","slug":"Web","permalink":"https://chivier.github.io/tags/Web/"},{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://chivier.github.io/tags/Shadowsocks/"},{"name":"COD","slug":"COD","permalink":"https://chivier.github.io/tags/COD/"},{"name":"Verilog","slug":"Verilog","permalink":"https://chivier.github.io/tags/Verilog/"},{"name":"Maths","slug":"Maths","permalink":"https://chivier.github.io/tags/Maths/"},{"name":"Logic","slug":"Logic","permalink":"https://chivier.github.io/tags/Logic/"},{"name":"Hexo","slug":"Hexo","permalink":"https://chivier.github.io/tags/Hexo/"},{"name":"Blog","slug":"Blog","permalink":"https://chivier.github.io/tags/Blog/"},{"name":"Shell","slug":"Shell","permalink":"https://chivier.github.io/tags/Shell/"},{"name":"Git","slug":"Git","permalink":"https://chivier.github.io/tags/Git/"}]}